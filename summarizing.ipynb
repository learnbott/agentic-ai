{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update && apt-get install ffmpeg -y\n",
    "!apt install tmux vim -y\n",
    "!pip3 install moviepy openai python-dotenv pydub pytubefix openai-whisper llama-index llama-index-llms-openai llama-index-llms-ollama llama-index-embeddings-ollama \n",
    "!pip3 install flash-attn --no-build-isolation\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "# !chmod +x /usr/bin/ollama\n",
    "# !useradd -r -s /bin/false -m -d /usr/share/ollama ollama\n",
    "# !pip3 install openpyxl sentencepiece protobuf evaluate rouge_score absl-py tensorboardX bitsandbytes peft accelerate python-dotenv dspy-ai graspologic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, gc, subprocess\n",
    "from dotenv import load_dotenv\n",
    "from video_transcription import split_audio_into_chunks, video_to_audio, transcribe_audio_chunks, get_transcription_model, download_video\n",
    "from llama_index.core import Document\n",
    "# import torch\n",
    "\n",
    "load_dotenv(\"/workspace/repos/agentic-ai/.env\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "video_path=\"/workspace/data/video1512218125.mp4\"\n",
    "# video_path=\"https://www.youtube.com/watch?v=Z07Ewop7rQA\"\n",
    "audio_output_path=\"/workspace/data/video_audio.mp3\"\n",
    "transcribe_output_dir=\"/workspace/data\"\n",
    "file_save_path=\"/workspace/data/transcription.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(file_save_path):\n",
    "    transcribe_model = get_transcription_model(open_source_model=True)\n",
    "\n",
    "    print(\"Processing video...\")\n",
    "    if 'youtube' in video_path:\n",
    "        print(\"   Downloading video from youtube...\")\n",
    "        download_video(video_url=video_path, audio_output_path=audio_output_path)\n",
    "    else:\n",
    "        video_to_audio(video_path=video_path, audio_output_path=audio_output_path)\n",
    "\n",
    "    print(\"Splitting audio into chunks...\")\n",
    "    split_audio_into_chunks(audio_output_path=audio_output_path, transcribe_output_dir=transcribe_output_dir, max_chunk_size_mb=24)\n",
    "\n",
    "    print(\"Transcribing audio chunks...\")\n",
    "    transcription = transcribe_audio_chunks(model=transcribe_model, chunk_dir=\"/workspace/data\", file_save_path=file_save_path)\n",
    "\n",
    "    del transcribe_model\n",
    "    # torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "else:\n",
    "    with open(file_save_path, 'rb') as f:\n",
    "        transcription = pickle.load(f)\n",
    "    \n",
    "\n",
    "    if isinstance(transcription[0], dict):\n",
    "        documents = [Document(text=chunk[\"text\"]) for chunk in transcription]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMMetadata(context_window=128000, num_output=256, is_chat_model=True, is_function_calling_model=False, model_name='llama3.1:latest', system_role=<MessageRole.SYSTEM: 'system'>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.llms.openai import OpenAI as LOpenAI\n",
    "\n",
    "# model_name, ctx_len = \"gpt-4o\", 128000\n",
    "model_name, ctx_len = \"llama3.1:latest\", 128000\n",
    "\n",
    "if model_name == \"gpt-4o\":\n",
    "    llm = LOpenAI(model=model_name, max_tokens=4000)\n",
    "else:\n",
    "    try: sub_out = subprocess.run(['ollama', 'pull', model_name], capture_output=True, text=True)\n",
    "    except Exception as e: print(f\"Error pulling model: Is the Ollama server running?\\n{e}\")\n",
    "    addtion_kwargs = {\"max_new_tokens\": 2000}\n",
    "    system_prompt = \"You are an expert at answering questions about rules and regulations regarding Title 17—Commodity and Securities Exchanges: CHAPTER II—SECURITIES AND EXCHANGE COMMISSION. Please provide a summary of the following text, and cite any sections, rules, acts or laws (e.g. § 230.503, § 240.13a-15, Act (15 U.S.C. 781), Investment Company Act of 1940) from context that support the answer. Be detailed in your response.\"\n",
    "    llm = Ollama(model=model_name, url=\"http://127.0.0.1:11434\", context_window=ctx_len, model_type=\"chat\", is_function_calling_model=False, \n",
    "                request_timeout=1000.0, system_prompt=system_prompt, additional_kwargs=addtion_kwargs)\n",
    "    print(llm.metadata)\n",
    "\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response_synthesizers import TreeSummarize\n",
    "summarizer = TreeSummarize(llm=llm, verbose=True)\n",
    "prompt_summary = \"You are a professional executive of AlphaTrAI. Your job is to summarize this text in great detail from a video transcription. The summary will be distributed to investors and stakeholders, so give a lot of details and examples from the transcription.\"\n",
    "\n",
    "response = await summarizer.aget_response(prompt_summary, [doc.text for doc in transcription])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM direct summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_doc = \" \".join([doc.text for doc in documents])\n",
    "prompt_summary = f\"You are a professional executive at AlphaTrAI. Your job is to summarize the text from a video transcription. The summary will be a memo distributed to investors and stakeholders. Be sure it is factual, optimistic, and containing little information about change. The transcription is as follows:\\n\\n{full_doc}\"\n",
    "\n",
    "response = llm.complete(prompt_summary, max_tokens=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**MEMORANDUM**\n",
      "\n",
      "**TO:** Investors and Stakeholders\n",
      "\n",
      "**FROM:** AlphaTrAI Executive Team\n",
      "\n",
      "**SUBJECT:** Corporate Update and Strategic Initiatives\n",
      "\n",
      "We are pleased to provide a summary of our corporate update and strategic initiatives, as presented during a recent video conference.\n",
      "\n",
      "**Corporate Update:**\n",
      "\n",
      "In the face of an increasingly competitive tech startup landscape, AlphaTrAI has navigated significant challenges over the past 24-36 months. Despite this, we have not only survived but thrived, positioning ourselves for future growth and success. Our major pivot in 2022 involved transitioning from proprietary asset management to tech-enabled services, leveraging our expertise in wealth and asset management across various business areas.\n",
      "\n",
      "**Strategic Initiatives:**\n",
      "\n",
      "1. **Anchor Advisory Services Acquisition:** We are excited to announce the acquisition of Anchor Advisory Services, a leading provider of professional sales and distribution solutions. This strategic move will enhance our capabilities in serving clients across the front, middle, and back office.\n",
      "2. **Kaya AI Solution:** Our team has developed Kaya, an AI solution that automates due diligence for private real estate deals, reducing processing time from 10 days to just three days. This innovative technology has significant potential for scaling and expansion into other investment types and industries.\n",
      "3. **Talent Acquisition:** We have attracted top talent to our organization, including Rob Marsh, a seasoned industry expert with extensive experience in tech-enabled services. This influx of expertise will drive growth and innovation within AlphaTrAI.\n",
      "\n",
      "**Growth Prospects:**\n",
      "\n",
      "Our pipeline is strong, and we are poised for significant growth in the coming months. With Kaya and other AI solutions in development, we expect to expand our reach into new markets and industries, further solidifying our position as a leader in tech-enabled services.\n",
      "\n",
      "**Next Steps:**\n",
      "\n",
      "We will continue to refine and expand our product offerings, leveraging the expertise of our team and partners to drive innovation and growth. Our focus on delivering customized SaaS solutions will enable us to differentiate ourselves from competitors and provide unparalleled value to our clients.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "AlphaTrAI is well-positioned for future success, driven by our commitment to innovation, talent acquisition, and strategic partnerships. We are excited to share this journey with our investors and stakeholders and look forward to achieving significant growth in the coming months.\n",
      "\n",
      "Please do not hesitate to contact us if you have any questions or would like to discuss further.\n",
      "\n",
      "Sincerely,\n",
      "\n",
      "[Your Name]\n",
      "AlphaTrAI Executive Team\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp '/workspace/repos/agentic-ai/PPM - MCG MADISON RIDGE DST.pdf' /workspace/data\n",
    "!cp '/workspace/repos/agentic-ai/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx' /workspace/data\n",
    "!apt update\n",
    "!apt install tmux vim -y\n",
    "!pip3 install llama-index llama-parse llama-index-embeddings-huggingface llama-index-llms-ollama\n",
    "!pip3 install openpyxl sentencepiece protobuf evaluate rouge_score absl-py tensorboardX bitsandbytes peft accelerate python-dotenv graspologic\n",
    "!pip3 install flash-attn --no-build-isolation\n",
    "!curl -fsSL https://ollama.com/download/ollama-linux-amd64.tgz | tar zx -C /usr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!ollama pull llama3.1:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import (\n",
    "    Settings,\n",
    ")\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv('/workspace/repos/agentic-ai/.env')\n",
    "access_token = os.getenv('HF_TOKEN')\n",
    "llama_api_key = os.getenv('LLAMA_API_KEY')\n",
    "\n",
    "# model_name, num_ctx = \"mistral-nemo\", 128000\n",
    "model_name, num_ctx = \"llama3.1\", 128000\n",
    "\n",
    "addtion_kwargs = {\"max_new_tokens\": 3000}\n",
    "system_prompt = \"You are an expert in creating marketing materials for financial firms. You take corporate documents and turn them into marketing materials.\"\n",
    "llm = Ollama(model=model_name, url=\"http://127.0.0.1:11434\", context_window=num_ctx, model_type=\"chat\", is_function_calling_model=False, \n",
    "             request_timeout=1000.0, system_prompt=system_prompt, additional_kwargs=addtion_kwargs)\n",
    "Settings.llm = llm\n",
    "llm.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Settings.chunk_size = 200\n",
    "Settings.chunk_overlap = 50\n",
    "embed_model_name = \"Alibaba-NLP/gte-Qwen2-1.5B-instruct\"\n",
    "# embed_model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "# embed_model_name = \"hkunlp/instructor-base\"\n",
    "print(\"loading embed model...\")\n",
    "embed_model = HuggingFaceEmbedding(model_name=embed_model_name, device=\"cuda\")\n",
    "\n",
    "Settings.embed_model = embed_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamaindex_data_utils import extract_text_from_pdf\n",
    "pdf_urls = [\"/workspace/data/AIP - Capital Raise Proposal.pdf\", \"/workspace/data/Access Pre-IPOs Presentation June 2024.pdf\"] \n",
    "llamaparse_kwargs={'result_type':\"markdown\", 'split_by_page':False}\n",
    "documents = extract_text_from_pdf(pdf_urls, llama_api_key, llamaparse_kwargs=llamaparse_kwargs, save_json_path=\"/workspace/data/pdf_text.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_utils import create_llama_query_engine_rag\n",
    "persist_dir=\"/workspace/data/vector_index\"\n",
    "query_engine = create_llama_query_engine_rag(llm, embed_model, persist_dir=persist_dir, documents=documents, vector_store_kwargs={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"You have been given a documents that describe the firm's investment strategy. Highlight portions of the document that include a unique opportunity to invest in pre-IPO companies and put investors on a level playing field with VCs and big institutional investors. You need to use this information to create a marketing brochure that will attract investors to the firm's products. The brochure should be informative, engaging, and persuasive. You must disclose in fine print that there are no guarantees, and investing is risky so nothing promissory.\"\n",
    "response = query_engine.query(prompt)\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core import DocumentSummaryIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitter = SentenceSplitter(chunk_size=4000, chunk_overlap=100)\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=\"tree_summarize\", use_async=True\n",
    ")\n",
    "doc_summary_index = DocumentSummaryIndex.from_documents(\n",
    "    documents,\n",
    "    llm=llm,\n",
    "    # transformations=[splitter],\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_summary = \"Use specific details from the given documents to create a professional marketing letter that highlights portions of the context including a unique opportunity to invest in pre-IPO companies and put investors on a level playing field with VCs and big institutional investors, qualifications of the investment team, and why they should invest now. Use details from the documents, but do not make up information. Be professional and persuasive. At the end of the letter, you must disclose in fine print that there are no guarantees, and investing is risky.\"\n",
    "response = await summarizer.aget_response(prompt_summary, [doc.text for doc in documents[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in response.source_nodes:\n",
    "    print(node.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
