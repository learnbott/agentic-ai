{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update && apt-get install ffmpeg tmux vim -y\n",
    "!pip3 install moviepy openai python-dotenv pydub pytubefix openai-whisper llama-index llama-index-llms-openai llama-index-llms-ollama llama-index-embeddings-ollama \n",
    "!pip3 install flash-attn --no-build-isolation\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "# !chmod +x /usr/bin/ollama\n",
    "# !useradd -r -s /bin/false -m -d /usr/share/ollama ollama\n",
    "# !pip3 install openpyxl sentencepiece protobuf evaluate rouge_score absl-py tensorboardX bitsandbytes peft accelerate python-dotenv dspy-ai graspologic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, gc, subprocess\n",
    "from dotenv import load_dotenv\n",
    "from video_transcription import split_audio_into_chunks, video_to_audio, transcribe_audio_chunks, get_transcription_model, download_video\n",
    "from llama_index.core import Document\n",
    "# import torch\n",
    "\n",
    "load_dotenv(\"/workspace/repos/agentic-ai/.env\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "video_path=\"/workspace/data/video1512218125.mp4\"\n",
    "# video_path=\"https://www.youtube.com/watch?v=Z07Ewop7rQA\"\n",
    "audio_output_path=\"/workspace/data/video_audio.mp3\"\n",
    "transcribe_output_dir=\"/workspace/data\"\n",
    "file_save_path=\"/workspace/data/transcription.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(file_save_path):\n",
    "    print(\"Loading transcription model...\")\n",
    "    transcribe_model = get_transcription_model(open_source_model=True)\n",
    "\n",
    "    print(\"Processing video...\")\n",
    "    if 'youtube' in video_path:\n",
    "        print(\"   Downloading video from youtube...\")\n",
    "        download_video(video_url=video_path, audio_output_path=audio_output_path)\n",
    "    else:\n",
    "        video_to_audio(video_path=video_path, audio_output_path=audio_output_path)\n",
    "\n",
    "    print(\"Splitting audio into chunks...\")\n",
    "    split_audio_into_chunks(audio_output_path=audio_output_path, transcribe_output_dir=transcribe_output_dir, max_chunk_size_mb=24)\n",
    "\n",
    "    print(\"Transcribing audio chunks...\")\n",
    "    documents = transcribe_audio_chunks(model=transcribe_model, chunk_dir=\"/workspace/data\", file_save_path=file_save_path)\n",
    "\n",
    "    del transcribe_model\n",
    "    # torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "else:\n",
    "    with open(file_save_path, 'rb') as f:\n",
    "        documents = pickle.load(f)\n",
    "    \n",
    "if isinstance(documents[0], dict):\n",
    "    documents = [Document(text=chunk[\"text\"]) for chunk in documents]\n",
    "\n",
    "full_doc = \" \".join([doc.text for doc in documents])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.llms.openai import OpenAI as LOpenAI\n",
    "\n",
    "# model_name, ctx_len = \"gpt-4o\", 128000\n",
    "# model_name, ctx_len = \"llama3.1:latest\", 128000\n",
    "model_name, ctx_len = \"hermes3:8b\", 128000\n",
    "\n",
    "if model_name == \"gpt-4o\":\n",
    "    llm = LOpenAI(model=model_name, max_tokens=4000)\n",
    "else:\n",
    "    try: \n",
    "        print(\"Pulling Ollama model...\")\n",
    "        sub_out = subprocess.run(['ollama', 'pull', model_name], capture_output=True, text=True)\n",
    "    except Exception as e: \n",
    "        print(f\"Error pulling model: Is the Ollama server running?\\n{e}\")\n",
    "    \n",
    "    addtion_kwargs = {\"max_new_tokens\": 4000}\n",
    "    # system_prompt = \"You are an expert at answering questions about rules and regulations regarding Title 17—Commodity and Securities Exchanges: CHAPTER II—SECURITIES AND EXCHANGE COMMISSION. Please provide a summary of the following text, and cite any sections, rules, acts or laws (e.g. § 230.503, § 240.13a-15, Act (15 U.S.C. 781), Investment Company Act of 1940) from context that support the answer. Be detailed in your response.\"\n",
    "    llm = Ollama(model=model_name, url=\"http://127.0.0.1:11434\", context_window=ctx_len, model_type=\"chat\", is_function_calling_model=False, \n",
    "                request_timeout=1000.0, additional_kwargs=addtion_kwargs) # system_prompt=system_prompt\n",
    "    print(llm.metadata)\n",
    "\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response_synthesizers import TreeSummarize\n",
    "summarizer = TreeSummarize(llm=llm, verbose=True)\n",
    "# prompt_summary = \"You are a professional executive of AlphaTrAI. Your job is to summarize this text in great detail from a video transcription. The summary will be distributed to investors and stakeholders, so give a lot of details and examples from the transcription.\"\n",
    "prompt_summary = f\"\"\"You are a professional executive at AlphaTrAI. Your job is to summarize the text from a video transcription. The summary will be a memo distributed to investors and stakeholders. Be sure it the memo has the following items:\n",
    "1. Extract all the names of new hires and their position, and/or new advisors mentioned in the transcription.\n",
    "2. Create a section to mention the personnel new to AlphaTrAI.\n",
    "3. Include other highlights and progress made by AlphaTrAI.\n",
    "4. Ensure the memo and ensure it is factual, optimistic, and any values mention come directly from the text. \n",
    "\n",
    "The transcription is as follows:\\n{full_doc}\"\"\"\n",
    "\n",
    "response = await summarizer.aget_response(prompt_summary, [doc.text for doc in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM direct summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_summary = f\"\"\"You are a professional executive at AlphaTrAI. Your job is to summarize the text from a video transcription. The summary will be a memo distributed to investors and stakeholders. Be sure it the memo has the following items:\n",
    "1. Extract all the names of new hires and their position, and/or new advisors mentioned in the transcription.\n",
    "2. Include other highlights and progress made by AlphaTrAI.\n",
    "3. Ensure the memo is professional, fluid, factual, and optimistic. \n",
    "\n",
    "The transcription is as follows:\\n{full_doc}\"\"\"\n",
    "\n",
    "response = llm.complete(prompt_summary, max_tokens=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agentic Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install llama-index-embeddings-huggingface llama-index-vector-stores-neo4jvector llama-index-graph-stores-neo4j\n",
    "!apt install dialog apt-utils -y (done above)\n",
    "!wget -O - https://debian.neo4j.com/neotechnology.gpg.key | gpg --dearmor -o /etc/apt/keyrings/neotechnology.gpg\n",
    "!echo 'deb [signed-by=/etc/apt/keyrings/neotechnology.gpg] https://debian.neo4j.com stable latest' | tee -a /etc/apt/sources.list.d/neo4j.list\n",
    "!apt list -a neo4j\n",
    "!add-apt-repository universe -y\n",
    "!apt install neo4j=1:5.22.0 -y\n",
    "!echo \"neo4j-enterprise neo4j/question select I ACCEPT\" | debconf-set-selections\n",
    "!echo \"neo4j-enterprise neo4j/license note\" | debconf-set-selections\n",
    "!apt install openjdk-17-jre -y\n",
    "!cd /var/lib/neo4j/plugins/ && wget https://github.com/neo4j/apoc/releases/download/5.22.0/apoc-5.22.0-core.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_neo4j_password('bewaretheneo')\n",
    "add_lines_to_conf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from llama_index.core.agent import ReActAgent\n",
    "# from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from rag_utils import create_neo4j_graph_store, create_neo4j_graphrag, neo4j_query, set_neo4j_password, add_lines_to_conf\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm.is_function_calling_model = True\n",
    "\n",
    "embed_model_name = \"Alibaba-NLP/gte-Qwen2-1.5B-instruct\"\n",
    "print(\"loading embed model...\")\n",
    "embed_model = HuggingFaceEmbedding(model_name=embed_model_name)\n",
    "\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 300\n",
    "Settings.chunk_overlap = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from llama_index.core.indices.property_graph import SchemaLLMPathExtractor\n",
    "\n",
    "entities = Literal[\"PEOPLE\", \n",
    "                   \"PLACE\"\n",
    "]\n",
    "\n",
    "relations = Literal[\n",
    "    \"ROLE\",\n",
    "    \"COMPANY\"\n",
    "]\n",
    "\n",
    "validation_schema = {\n",
    "    \"People\": [\"ROLE\"],\n",
    "    \"Place\": [\"COMPANY\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.chunk_size = 300\n",
    "Settings.chunk_overlap = 50\n",
    "\n",
    "kg_extractor = SchemaLLMPathExtractor(\n",
    "    llm=llm,\n",
    "    possible_entities=entities,\n",
    "    possible_relations=relations,\n",
    "    kg_validation_schema=validation_schema,\n",
    "    strict=True,  # if false, will allow triples outside of the schema\n",
    "    num_workers=4,\n",
    "    max_triplets_per_chunk=10,\n",
    ")\n",
    "\n",
    "graph_store = create_neo4j_graph_store(neo_url=\"bolt://localhost:7687\", \n",
    "                                       password=os.getenv(\"NEO4J_PWD\"), \n",
    "                                       config={\"connection_timeout\": 240, \"connection_acquisition_timeout\": 240, \"max_connection_pool_size\": 1000})\n",
    "neo4j_query(graph_store, query=\"\"\"MATCH (n) DETACH DELETE n\"\"\")\n",
    "\n",
    "\n",
    "graph_index = create_neo4j_graphrag(documents, llm, embed_model, kg_extractor, graph_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "query_engine_tools = QueryEngineTool(\n",
    "            query_engine=graph_index,\n",
    "            metadata=ToolMetadata(\n",
    "                name=\"graph_tool\",\n",
    "                description=(\n",
    "                    \"Useful for finding people names and roles, and the company they work for.\"\n",
    "                ),\n",
    "            ),\n",
    "        ),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install llama-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_agents import (\n",
    "    AgentService,\n",
    "    ToolService,\n",
    "    MetaServiceTool,\n",
    "    ControlPlaneServer,\n",
    "    SimpleMessageQueue,\n",
    "    AgentOrchestrator,\n",
    ")\n",
    "\n",
    "from llama_index.core.agent import FunctionCallingAgentWorker\n",
    "from llama_index.core.agent import ReActAgentWorker, ReActAgent\n",
    "\n",
    "\n",
    "\n",
    "# create our multi-agent framework components\n",
    "message_queue = SimpleMessageQueue()\n",
    "control_plane = ControlPlaneServer(\n",
    "    message_queue=message_queue,\n",
    "    orchestrator=AgentOrchestrator(llm=llm),\n",
    ")\n",
    "\n",
    "# define Tool Service\n",
    "tool_service = ToolService(\n",
    "    message_queue=message_queue,\n",
    "    tools=[query_engine_tools],#, adding_tool],\n",
    "    running=True,\n",
    "    step_interval=0.5,\n",
    ")\n",
    "\n",
    "# define meta-tools here\n",
    "meta_tools = [\n",
    "    await MetaServiceTool.from_tool_service(\n",
    "        t.metadata.name,\n",
    "        message_queue=message_queue,\n",
    "        tool_service=tool_service,\n",
    "    )\n",
    "    for t in [query_engine_tools]#, adding_tool]\n",
    "]\n",
    "\n",
    "\n",
    "# define Agent and agent service\n",
    "# worker1 = FunctionCallingAgentWorker.from_tools(\n",
    "worker1 = ReActAgentWorker.from_tools(\n",
    "    meta_tools,\n",
    "    llm=llm,\n",
    ")\n",
    "agent1 = worker1.as_agent()\n",
    "agent_server_1 = AgentService(\n",
    "    agent=agent1,\n",
    "    message_queue=message_queue,\n",
    "    description=\"Summarize a transcription as a memo for investors and stakeholders.\",\n",
    "    service_name=\"summarize_transcription\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_list = [\"Vanguard Group\",\t\"BlackRock\",\t\"State Street Global\",\t\"Fidelity Investments\",\t\"BNY Mellon\",\t\"Goldman Sachs Group\",\t\"J.P. Morgan Asset & Wealth\",\t\"Legal & General Investment\",\t\"Wellington Mgmt.\",\t\"Amundi\",\t\"Prudential Financial\",\t\"Geode Capital Mgmt.\",\t\"PIMCO\",\t\"Northern Trust Asset Mgmt.\",\t\"Nuveen\",\t\"Capital Group\",\t\"T. Rowe Price Associates\",\t\"AXA Investment\",\t\"Franklin Templeton\",\t\"Federated Hermes\",\t\"Invescos\",\t\"Dimensional Fund Advisors\",\t\"MetLife Investment Mgmt.\",\t\"Morgan Stanley Inv. Mgmt.\",\t\"New York Life Investments\",\t\"Schroders\",\t\"Principal Global Investors\",\t\"KKR\",\t\"DWS\",\t\"Macquarie Asset Mgmt.\",\t\"Brookfield Asset Mgmt.\",\t\"Allspring Global Investments\",\t\"BNP Paribas Asset Mgmt.\",\t\"Asset Management One\",\t\"Mercer\",\t\"Barings\",\t\"Aegon Asset Mgmt.\",\t\"AllianceBernstein\",\t\"Neuberger Berman\",\t\"Ares Mgmt.\",\t\"Columbia Threadneedle\",\t\"NISA Investment\",\t\"Voya Investment Mgmt.\",\t\"MassMutual\",\t\"Aviva Investors\",\t\"SEI Investments\",\t\"Manulife Investment\",\t\"SLC Management\",\t\"Russell Investments\",\t\"Loomis, Sayles\",\t\"Baillie Gifford Overseas\",\t\"Dodge & Cox\",\t\"TCW Group\",\t\"MFS Investment\",\t\"RBC Global Asset Mgmt.\",\t\"Mesirow\",\t\"Guggenheim Investments\",\t\"Wilmington Trust\",\t\"WTW Investment Services\",\t\"Conning\",\t\"Empower Investments\",\t\"PFM Asset Mgmt.\",\t\"CBRE Investment Mgmt.\",\t\"TD Global Invest. Solutions\",\t\"IFM Investors\",\t\"Arrowstreet Capital\",\t\"Nomura Asset Mgmt.\",\t\"Oaktree Capital\",\t\"Payden & Rygel\",\t\"Lazard Asset Mgmt.\",\t\"Victory Capital\",\t\"Artisan Partners\",\t\"PRIMECAP\",\t\"Man Group\",\t\"Robeco\",\t\"Baird Advisors\",\t\"Hamilton Lane\",\t\"Ninety One\",\t\"Partners Group\",\t\"Starwood Capital\",\t\"AQR Capital Mgmt.\",\t\"Acadian Asset Mgmt.\",\t\"Prologis\",\t\"LSV Asset Mgmt.\",\t\"StepStone Group\",\t\"American Century\",\t\"Charles Schwab Investment\",\t\"RhumbLine Advisers\",\t\"Pathway Capital\",\t\"Boston Partners\",\t\"Record Currency Mgmt.\",\t\"Income Research & Mgmt.\",\t\"AEW Capital\",\t\"Pictet Asset Mgmt.\",\t\"First Sentier Investors\",\t\"Hines\",\t\"New England Asset Mgmt.\",\t\"Alan Biller and Associates\",\t\"PPM America\",\t\"LaSalle Investment\",\t\"GCM Grosvenor\",\t\"PineBridge Investments\",\t\"PNC Financial\",\t\"CC&L Financial Group\",\t\"Fort Washington\",\t\"Dai-ichi Life Holdings\",\t\"Oak Hill Advisors\",\t\"William Blair\",\t\"Putnam Investments\",\t\"Ashmore Group\",\t\"Heitman\",\t\"Harrison Street\",\t\"Grantham, Mayo v. Otterloo\",\t\"PAG\",\t\"Harris Associates\",\t\"Adams Street Partners\",\t\"Sterling Capital\",\t\"GoldenTree Asset Mgmt.\",\t\"Mondrian Investment\",\t\"Angelo, Gordon\",\t\"Nikko Asset Mgmt.\",\t\"Harding Loevner\",\t\"Brown Advisory\",\t\"Portfolio Advisors\",\t\"Fisher Investments\",\t\"Cohen & Steers\",\t\"Marathon-London\",\t\"Harbor Capital Advisors\",\t\"Aristotle Capital Mgmt.\",\t\"SECOR Asset Mgmt.\",\t\"Stockbridge Capital Group\",\t\"PanAgora Asset Mgmt.\",\t\"Pzena Investment\",\t\"Causeway Capital\",\t\"Colchester Global Investors\",\t\"MissionSquare Investments\",\t\"Hayfin Capital Mgmt.\",\t\"ORIX USA\",\t\"CIBC Asset Mgmt.\",\t\"Los Angeles Capital\",\t\"Shenkman Group\",\t\"Jarislowsky Fraser\",\t\"EARNEST Partners\",\t\"Knights of Columbus Asset\",\t\"Strategic Investment Group\",\t\"Commonfund\",\t\"Rockpoint Group\",\t\"Hotchkis & Wiley\",\t\"AAM\",\t\"CIM Group*\",\t\"Beutel, Goodman\",\t\"Nomura Corporate Research\",\t\"Scout Investments\",\t\"Calamos Advisors\",\t\"ACORE Capital\",\t\"PCCP\",\t\"Guardian Capital\",\t\"DuPont Capital\",\t\"Canyon Partners\",\t\"Kayne Anderson Rudnick\",\t\"Polen Capital\",\t\"TA Realty\",\t\"Sustainable Growth Advisers\",\t\"MFG Asset Mgmt.\",\t\"Unigestion\",\t\"Intech\",\t\"Eagle Capital\",\t\"Garcia Hamilton\",\t\"Sprucegrove Investment\",\t\"Longfellow Investment\",\t\"Axiom Investors\",\t\"King Street Capital\",\t\"Wasatch Global Investors\",\t\"Boyd Watterson\",\t\"Champlain Investment\",\t\"Crestline Investors\",\t\"Callan\",\t\"Pacific Asset Mgmt.\",\t\"Fuller & Thaler\",\t\"Cantillon Capital Mgmt.\",\t\"Jacobs Levy Equity\",\t\"Brandes Investment\",\t\"Fayez Sarofim\",\t\"Sit Investment\",\t\"Cliffwater\",\t\"Intercontinental Real Estate\",\t\"Walton Street Capital\",\t\"Beacon Capital\",\t\"Rockwood Capital\",\t\"Breckinridge Capital\",\t\"Beach Point Capital\",\t\"Amalgamated Bank\",\t\"American Realty Advisors\",\t\"Abbott Capital\",\t\"Eagle Asset Mgmt.\",\t\"Westfield Capital\",\t\"Driehaus Capital\",\t\"CenterSquare Investment\",\t\"Segall Bryant & Hamill\",\t\"Polaris Capital\",\t\"Grayscale Investments\",\t\"GW&K Investment\",\t\"CornerStone Partners\",\t\"Westbrook Partners\",\t\"Bahl & Gaynor\",\t\"Sage Advisory Services\",\t\"Yousif Capital\",\t\"Commerce Trust\",\t\"Zacks Investment\",\t\"Stone Harbor Investment\",\t\"Brown Capital\",\t\"Cooke & Bieler\",\t\"L&B Realty\",\t\"Jensen Investment\",\t\"Burgundy Asset Mgmt.\",\t\"Pugh Capital\",\t\"Mill Creek Residential\",\t\"Global Endowment Mgmt.\",\t\"Ullico Investment\",\t\"London Co.\",\t\"GAMCO Investors\",\t\"Matthews Asia\",\t\"Capital Fund Mgmt.\",\t\"Waterfall Asset Mgmt.\",\t\"Westwood Global\",\t\"Frontier Capital\",\t\"Christian Brothers\",\t\"Manning & Napier\",\t\"Ariel Investments\",\t\"Washington Capital\",\t\"TimesSquare Capital\",\t\"Ramirez Asset Mgmt.\",\t\"Altrinsic Global Advisors\",\t\"National Real Estate\",\t\"Advent Capital\",\t\"CS McKee\",\t\"WEDGE Capital\",\t\"Newfleet Asset Mgmt.\",\t\"National Investment\",\t\"TT International\",\t\"Prima Capital Advisors\",\t\"Alger\",\t\"Silver Creek Capital\",\t\"River Road Asset Mgmt.\",\t\"Agincourt Capital\",\t\"Diamond Hill Capital\",\t\"AGF Investments\",\t\"Sentinel Real Estate\",\t\"Ceredex Value Advisors\",\t\"CoreCommodity\",\t\"LCM Partners\",\t\"Madison Realty\",\t\"Silvercrest Asset Mgmt.\",\t\"White Oak Global Advisors\",\t\"Luther King Capital\",\t\"Equus Capital\",\t\"Hardman Johnston Global\",\t\"AFL-CIO Housing Trust\",\t\"Corbin Capital\",\t\"City of London\",\t\"Spider Mgmt.\",\t\"M3 Capital\",\t\"Davis Advisors\",\t\"Torchlight Investors\",\t\"Stephens Inv. Mgmt. Group\",\t\"Great Lakes Advisors\",\t\"Congress Asset Mgmt.\",\t\"Parnassus Investments\",\t\"Dana Investment\",\t\"Martingale Asset Mgmt.\",\t\"Madison Investments\",\t\"Richmond Capital\",\t\"Camden Asset Mgmt.\",\t\"400 Capital Mgmt.\",\t\"Glenmede Investment\",\t\"Lyrical Asset Mgmt.\",\t\"Gramercy\",\t\"D.F. Dent\",\t\"Resource Mgmt.\",\t\"DePrince, Race & Zollo\",\t\"Fiduciary Mgmt./Milwaukee\",\t\"Duff & Phelps\",\t\"AFL-CIO Building Trust\",\t\"Johnson Asset Mgmt.\",\t\"LM Capital Group\",\t\"Conestoga Capital\",\t\"Sierra Investment\",\t\"Baird Equity Asset Mgmt.\",\t\"Forest Investment\",\t\"Carmel Partners\",\t\"Atalanta Sosnoff Capital\",\t\"Jackson Square Partners\",\t\"Peregrine Capital\",\t\"Todd Asset Mgmt.\",\t\"Hoisington Investment\",\t\"GlobeFlex Capital\",\t\"Kornitzer Capital\",\t\"Patron Capital\",\t\"Emerald Advisers\",\t\"Mar Vista Investment\",\t\"Stacey Braun Associates\",\t\"Leading Edge Investment\",\t\"Kennedy Capital\",\t\"Security Capital Research\",\t\"Riverbridge Partners\",\t\"Cardinal Capital\",\t\"Granahan Investment\",\t\"Dolan McEniry\",\t\"Angel Oak Capital\",\t\"Global Forest Partners\",\t\"Channing Capital\",\t\"ClariVest Asset Mgmt.\",\t\"Twin Bridge Capital\",\t\"Evanston Capital\",\t\"Aristotle Capital Boston\",\t\"Systematic Financial\",\t\"Palisade Capital\",\t\"Algert Global\",\t\"Hillsdale Investment\",\t\"Prime Group\",\t\"3650 REIT\",\t\"GTIS Partners\",\t\"Bivium Capital\",\t\"Molpus Woodlands Group\",\t\"Winthrop Capital\",\t\"Zevenbergen Capital\",\t\"Dalton Investments\",\t\"Hood River Capital\",\t\"Trillium Asset Mgmt.\",\t\"Bowen, Hanes\",\t\"EAM Investors\",\t\"Verger Capital\",\t\"GIA Partners\",\t\"Weatherbie Capital\",\t\"Oberweis Asset Mgmt.\",\t\"Zazove Associates\",\t\"Wexford Capital\",\t\"Timberland Inv. Resources\",\t\"Sawgrass Asset Mgmt.\",\t\"SSI Investment\",\t\"NewSouth Capital\",\t\"Foundry Partners\",\t\"Sound Shore Mgmt.\",\t\"KBS\",\t\"HS Management\",\t\"Silvant Capital\",\t\"Millstreet Capital\",\t\"Redwood Investments\",\t\"Genter Capital\",\t\"Smith Group Asset Mgmt.\",\t\"Sarofim Realty\",\t\"Edgar Lomax\",\t\"Covenant Capital Group\",\t\"Heartland Advisors\",\t\"Adelante Capital\",\t\"Rice Hall James\",\t\"Cramer Rosenthal McGlynn\",\t\"Quest Investment\",\t\"Penn Capital\",\t\"Ranger Investments\",\t\"Associated Capital Group\",\t\"Cornerstone Investment\",\t\"Smith Affiliated Capital\",\t\"Logan Capital\",\t\"Wilbanks, Smith & Thomas\",\t\"Orleans Capital\",\t\"Thornburg Investment\",\t\"Karpus Investment\",\t\"StoneRidge PMG Advisors\",\t\"Tributary Capital\",\t\"Mairs & Power\",\t\"Bridgeway Capital\",\t\"Granite Investment\",\t\"Ativo Capital Mgmt.\",\t\"Nicholas Investment\",\t\"Sasco Capital\",\t\"CS Capital\",\t\"TWIN Capital\",\t\"CI Inverness\",\t\"Miller/Howard Investments\",\t\"Belle Haven Investments\",\t\"Montag & Caldwell\",\t\"Anchor Capital\",\t\"Wedgewood Partners\",\t\"Wright Investors' Service\",\t\"Phocas Financial\",\t\"TSCG Investors\",\t\"Pier Capital\",\t\"GLOBALT\",\t\"Van Hulzen Asset Mgmt.\",\t\"SKBA Capital Mgmt.\",\t\"Domain Timber Advisors\",\t\"Speece Thorson Capital\",\t\"Redstone Advisors\",\t\"Aristotle Credit Partners\",\t\"TerraCotta Group\",\t\"Farr, Miller & Washington\",\t\"SouthernSun Asset Mgmt.\",\t\"Gifford Fong Associates\",\t\"Denali Advisors\",\t\"KDP Asset Mgmt.\",\t\"AMI Asset Mgmt.\",\t\"Semper Capital\",\t\"Renaissance Investment\",\t\"ZWJ Investment Counsel\",\t\"Campbell Newman Asset\",\t\"Gateway Investment\",\t\"SMH Capital Advisors\",\t\"Argent Capital\",\t\"Chicago Capital\",\t\"Osborne Partners\",\t\"Oak Associates\",\t\"Windham Capital\",\t\"Bridge City\",\t\"Strategy Asset Managers\",\t\"Kingdon Capital\",\t\"Glovista Investments\",\t\"Winslow Asset Mgmt.\",\t\"Hahn Capital\",\t\"Affinity Investment Advisors\",\t\"Teton Advisors\",\t\"Abner, Herrman & Brock\",\t\"NovaPoint Capital\",\t\"Paradigm Capital\",\t\"Flippin, Bruce & Porter\",\t\"Kestrel Investment\",\t\"Tom Johnson Investment\",\t\"Argus Investors' Counsel\",\t\"Branson, Fowlkes/Russell\",\t\"Robinson Value Mgmt.\",\t\"Chase Investment Counsel\",\t\"Nicholas Co.\",\t\"Cadinha\",\t\"Pacific West Land\",]\n",
    "import os, re\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('/workspace/repos/agentic-ai/.env')\n",
    "from llama_index.llms.openai import OpenAI as LOpenAI\n",
    "\n",
    "model_name, ctx_len = \"gpt-4o-2024-08-06\", 128000\n",
    "openai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
    "system_prompt = f\"\"\"You are gathering information on the top asset management firms in the world. \n",
    "This information will be put in a spreadsheet. \n",
    "You need to know the CEO of each firm.\n",
    "Return the company name and CEO name in the following format: \"Company: CEO\".\n",
    "\"\"\"\n",
    "print(f\"Using OpenAI {model_name}...\")\n",
    "llm = LOpenAI(model=model_name, max_tokens=8000, system_prompt=system_prompt)\n",
    "ceos=[]\n",
    "coos=[]\n",
    "cios=[]\n",
    "presidents=[]\n",
    "execs = [ceos, coos, cios, presidents]\n",
    "exec_strs = [\"Chief Executive Officer\", \"Chief Operating Officer\", \"Chief Investment Officer\", \"President\"]\n",
    "results = []\n",
    "\n",
    "for i,a in enumerate(asset_list):\n",
    "    company_execs=[a]\n",
    "    for exec_type, exec_str in zip(execs, exec_strs):\n",
    "        system_prompt = f\"\"\"You are gathering information on the executives at top asset management firms. \n",
    "        Only output the executive's name. \n",
    "        Here are examples of properly formatted outputs: 'Larry Fink', 'Lori Heinel', 'James S. Anderson', 'Brian Carlin', 'Michael Sacks').\n",
    "        \n",
    "        Who is the {exec_str} of {a}?\n",
    "        \"\"\"\n",
    "        response = llm.complete(system_prompt)\n",
    "        # response_check = llm.complete(f\"Extract and only output the name in the following text.\\n\\n{response.text}\")\n",
    "        company_execs.append(response.text)\n",
    "        \n",
    "    # if i==10:\n",
    "    #     raise ValueError(\"Stop here.\")\n",
    "    # else:\n",
    "    #     print(company_execs)\n",
    "    if i%50==0:\n",
    "        print(f\"{i} {company_execs}...\")\n",
    "    results.append(company_execs)\n",
    "    \n",
    "header=[[\"Company Name\"]+[\"Chief Executive Officer\", \"Chief Operating Officer\", \"Chief Investment Officer\", \"President\"]]\n",
    "bads=0\n",
    "for r in results:\n",
    "    for elem in r:\n",
    "        if len(elem.split())>4:\n",
    "            bads+=1\n",
    "            print(\" \".join(elem.split()[-3:]))\n",
    "            break\n",
    "print(bads)\n",
    "results=[r[0] for r in results]\n",
    "for i in range(len(results)):\n",
    "    for j in range(1,5):\n",
    "        # results[i][j] = results[i][j].strip().replace(\"'\", \"\")\n",
    "        # if results[i][j].endswith(\".\"):\n",
    "        #     results[i][j] = results[i][j][:-1]\n",
    "        # if results[i][j].endswith(\",\"):\n",
    "        #     results[i][j] = results[i][j][:-1]\n",
    "        # if \" \".join(results[i][j].split()[-3:]).startswith(\"is\"):\n",
    "        #     results[i][j] = \" \".join(results[i][j].split()[-3:])[2:].strip()\n",
    "        # if \" \".join(results[i][j].split()[-3:]).startswith((\"is\", \"have\", \"and\", \"a different\", \"my\")):\n",
    "        #     results[i][j] = \" \".join(results[i][j].split()[-3:])[2:].strip()\n",
    "        if len(results[i][j].split())>4:\n",
    "            results[i][j] = \" \".join(results[i][j].split()[-3:])[2:].replace('\"', '').strip()\n",
    "import csv\n",
    "\n",
    "# Sample list of lists\n",
    "\n",
    "\n",
    "# Specify the file name\n",
    "filename = '/workspace/data/asset_execs.csv'\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(filename, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # Write each row to the CSV file\n",
    "    for row in header+results:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Data has been written to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
