{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent use case #1 - Financial data collection\n",
    "\n",
    "* Build dataset (possibly revisit information compression)\n",
    "  * Design targets using price data\n",
    "  * Build dataset justifying the target\n",
    "\n",
    "* Collect time series data\n",
    "  * preprocess \n",
    "  * Create features\n",
    "* Collect news\n",
    "  * Preprocess\n",
    "  * Extract trading info\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_cpp import Llama \n",
    "# SUMMARIZER_LLM_PARAMS = { 'n_ctx': 16384, 'use_mlock': True, 'n_threads': 12, 'n_gpu_layers':1 } \n",
    "# RESPONDER_LLM_PARAMS = { 'n_ctx': 4096, 'use_mlock': True, 'n_threads': 12, 'n_gpu_layers':1 } \n",
    "# summarizer_llm = Llama(model_path=\"../../Downloads/models/TheBloke/LlongOrca-13B-16K-GGUF/llongorca-13b-16k.Q8_0.gguf\", **SUMMARIZER_LLM_PARAMS) \n",
    "# responder_llm = Llama(model_path=\"../../Downloads/models/TheBloke/stablebeluga2-70b/stablebeluga2-70B.Q4_K_M.gguf\", **RESPONDER_LLM_PARAMS)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
