{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 install llama-index llama-parse llama-index-embeddings-huggingface accelerate dspy-ai openpyxl langchain chromadb\n",
    "!pip3 install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.datasets.hotpotqa import HotPotQA\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "# from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "# from llama_index.readers.file import PandasExcelReader\n",
    "# from llama_index.core.embeddings import resolve_embed_model\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "from typing import List, Any, Callable, Optional\n",
    "from pydantic import BaseModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(BaseModel):\n",
    "    name: str\n",
    "    desc: str\n",
    "    input_variable: str\n",
    "    func: Callable\n",
    "    \n",
    "# class GiveTime:\n",
    "#     name = \"GiveTime\"\n",
    "#     input_variable = \"empty\"\n",
    "#     desc = \"takes an empty string and returns the current local time\"\n",
    "\n",
    "#     def __init__(self, k=3):\n",
    "#         pass\n",
    "   \n",
    "#     def __call__(self, *args, **kwargs):\n",
    "#         return datetime.datetime.now().strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_values(input_variable: List[float])->float:\n",
    "    return sum(input_variable)\n",
    "\n",
    "adding_tool = Tool(name=\"addition\", desc=\"add a list of floats together\", input_variable=\"input_variable\", func=add_values)\n",
    "\n",
    "# test_tools = [\n",
    "    # Tool(name=\"addition\", description=\"add a list of floats together\", requires=\"values\", func=add_values)\n",
    "    # Tool(name=\"local business lookup\", description=\"Look up businesses by category\", requires=\"business category\", func=lambda x: \"Bills landscaping: 415-555-5555\")\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first model load...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting model...\n",
      "reloading model...\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
    "from llama_index.readers.file import PandasExcelReader\n",
    "CHROMA_COLLECTION_NAME = \"blockchain_and_ai\"\n",
    "CHROMADB_DIR = \"/workspace/data/db/\"\n",
    "\n",
    "access_token = \"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\"\n",
    "# model_name = \"EleutherAI/gpt-neo-125m\"\n",
    "# model_name = \"clibrain/mamba-2.8b-instruct-openhermes\"\n",
    "# model_name = \"microsoft/Phi-3-mini-128k-instruct\" # 128K context window\n",
    "# model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\" # 8K context window\n",
    "# model_name = \"mistralai/Mistral-7B-Instruct-v0.3\" # 32K context window\n",
    "# model_name = \"clibrain/mamba-2.8b-instruct-openhermes\" # 8K context window\n",
    "# embed_model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "print('first model load...')\n",
    "model_name = \"Qwen/Qwen2-1.5B-Instruct\"\n",
    "llm = dspy.HFModel(model=model_name, hf_device_map='auto', token=access_token)\n",
    "llm.kwargs['max_new_tokens']=1000\n",
    "llm.kwargs['repetition_penalty']=1.5\n",
    "# llm.kwargs['do_sample']=True\n",
    "# llm.kwargs['typical_p']=0.9\n",
    "# llm.kwargs['temperature']=0.2\n",
    "\n",
    "\n",
    "print('deleting model...')\n",
    "llm.model=None\n",
    "gc.collect\n",
    "print('reloading model...')\n",
    "llm.model=AutoModelForCausalLM.from_pretrained(model_name, quantization_config=None, \n",
    "                                               trust_remote_code=True, device_map=\"auto\", \n",
    "                                               attn_implementation=\"flash_attention_2\",  \n",
    "                                               torch_dtype=torch.float16)\n",
    "\n",
    "# llm.model.generation_config.pad_token_id = llm.tokenizer.eos_token_id\n",
    "# llm.tokenizer.pad_token_id = llm.tokenizer.eos_token_id\n",
    "\n",
    "# retriever = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
    "filepath = \"/workspace/data/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx\"\n",
    "docs = PandasExcelReader(sheet_name=\"5 - Disposition Analysis\").load_data(filepath)\n",
    "# # embed_model = HuggingFaceEmbedding(model_name=embed_model_name)\n",
    "# # vector_index = VectorStoreIndex.from_documents(documents, embed_model=embed_model)\n",
    "# # vector_index.storage_context.persist(persist_dir=\"/workspace/data/storage/alpha\")\n",
    "# # retriever = vector_index.as_retriever(top_k=2)\n",
    "\n",
    "# chroma_client = chromadb.PersistentClient(path=CHROMADB_DIR)\n",
    "# collection = chroma_client.get_or_create_collection(name=CHROMA_COLLECTION_NAME)\n",
    "# text_splitter = SentenceTransformersTokenTextSplitter()\n",
    "\n",
    "# ids = []\n",
    "# documents = []\n",
    "# metadatas = []\n",
    "# chunks = text_splitter.create_documents([docs[0].text], )\n",
    "# for chunk_no, chunk in enumerate(chunks):\n",
    "#     ids.append(f\"{chunk_no}\")\n",
    "#     documents.append(chunk.page_content)\n",
    "#     # metadatas.append({\"title\":})\n",
    "# if ids:\n",
    "#     collection.upsert(ids=ids, documents=documents)#, metadatas=metadatas)\n",
    "\n",
    "# collection.upsert(documents=[docs[0].text])\n",
    "\n",
    "\n",
    "# default_ef = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
    "# default_ef = embedding_functions.DefaultEmbeddingFunction()\n",
    "# retriever = ChromadbRM(CHROMA_COLLECTION_NAME, CHROMADB_DIR, default_ef, k=3)\n",
    "\n",
    "# dspy.settings.configure(lm=llm, rm=retriever)\n",
    "dspy.settings.configure(lm=llm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uncompiled_rag = RAG()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question='Retrieve the following values from the spreadsheet: Selling Costs, Disposition Fee, Net Operating Income, Loan Assumption/Payoff, Return of Forecasted Reserves, CF Y 11, Return of Maximum Offering Amount, Projected Terminal Cap Rate.\\nThen add Disposition Fee and Selling Cost together.'\n",
    "answer = uncompiled_rag(question).answer\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tune spreadsheet model\n",
    "# dspy module class for multiagent stuff with tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!cp /workspace/repos/agentic-ai/MASTER\\ -\\ PYTHON\\ -\\ SCORING\\ MODEL\\ -\\ MCG\\ MADISON\\ RIDGE\\ DST\\ -\\ v2.0.xlsx /workspace/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/workspace/data/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx\"\n",
    "docs = PandasExcelReader(sheet_name=\"5 - Disposition Analysis\", pandas_config={'keep_default_na':False}).load_data(filepath)\n",
    "# docs2 = PandasExcelReader(sheet_name=\"5 - Disposition Analysis\").load_data(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.functional import TypedPredictor\n",
    "import pydantic\n",
    "\n",
    "\n",
    "\n",
    "class SpreadsheetValueExtractor(dspy.Signature):\n",
    "    \"\"\"For each of the keys in the question extract its value from the data. The data is a spreadsheet that has been formatted as a string.\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    data = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"output the key value in this format: key:value \\n.\")\n",
    "\n",
    "# class KeyValidationAgent(dspy.Signature):\n",
    "#     \"\"\"Remove any keys from the question that are not found in the JSON string.\"\"\"\n",
    "    \n",
    "#     orignial_question = dspy.InputField(desc=\"the original question from the user.\")\n",
    "#     format_json = dspy.InputField(desc=\"User supplied JSON string with key value formats.\")\n",
    "#     verified_question = dspy.OutputField(desc=\"only return the orignial question with keys that are found in the format_json. Leave out the intermediary steps.\")\n",
    "\n",
    "# class ValueFormatValidationAgent(dspy.Signature):\n",
    "#     \"\"\"Given the original context and the key and value format descriptions as specified in format_json make sure the retrieved values for the specified keys are in the correct format.\n",
    "#     Collect any keys in the wrong format and return them as a string.\n",
    "#     \"\"\"\n",
    "#     format_json = dspy.InputField(desc=\"User supplied JSON string with key value formats.\")\n",
    "#     original_context = dspy.InputField(desc=\"the context from the retriever.\")\n",
    "#     reasons_for_format_failure = dspy.OutputField()\n",
    "\n",
    "class ValueFormatValidationAgent(dspy.Signature):\n",
    "    \"\"\"Given the key and value format descriptions in format_json make sure the retrieved values align with the value format description.\"\"\"\n",
    "\n",
    "    format_json = dspy.InputField(desc=\"Key and the description of the value format.\")\n",
    "    extracted_values = dspy.InputField(desc=\"The values extracted from the spreadsheet.\")\n",
    "    reason_for_format_failure = dspy.OutputField(desc=\"Concise return the keys and values that do not fit the format.\")\n",
    "\n",
    "\n",
    "# class RephraseQuestionForRetrieve(dspy.Signature):\n",
    "#     \"\"\"Given the orignal context and the reason for failure, please rephrase the question to retrieve the correct answer.\"\"\"\n",
    "#     original_context = dspy.InputField(desc=\"the context from the retriever\")\n",
    "#     reasons_for_format_failure = dspy.InputField()\n",
    "#     rephrased_question = dspy.OutputField()\n",
    "\n",
    "\n",
    "class SpreadSheetAnalyzer(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.num_passages = num_passages\n",
    "        # self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        # self.key_validation_agent = dspy.Predict(KeyValidationAgent)\n",
    "        self.value_format_validation_agent = dspy.Predict(ValueFormatValidationAgent)\n",
    "        # self.question_rephrase_agent = dspy.Predict(RephraseQuestionForRetrieve)\n",
    "        self.generate_answer = dspy.Predict(SpreadsheetValueExtractor)\n",
    "    \n",
    "    # def forward(self, data, format_json):\n",
    "    def forward(self, data, question, format_json):\n",
    "        # valid_context = False\n",
    "        # First check - validate context has all the keys\n",
    "\n",
    "        # key_validated_question = self.key_validation_agent(orignial_question=question, format_json=format_json).verified_question\n",
    "        # print(\"KEY VALIDATION\")\n",
    "        # print('---------------------------------')\n",
    "        # print(key_validated_question, len(key_validated_question), type(key_validated_question))\n",
    "        # print('---------------------------------')\n",
    "        \n",
    "        # context = str(self.retrieve(query_or_queries=question).passages)\n",
    "        # out_collect = []\n",
    "        # for key, value in format_json.items():\n",
    "        # format_counter = 0\n",
    "        # self.retrieve.k = self.num_passages\n",
    "        # while not valid_context:\n",
    "        # print('---------------------------------')\n",
    "        # print(\"Counter: \", format_counter)\n",
    "        # print(\"Key: \", key)\n",
    "        # print(\"Value: \", value)\n",
    "        # print('---------------------------------')\n",
    "        # print()\n",
    "        # key_question = f\"what is the value for {key} in the spreadsheet?\"\n",
    "        # if format_counter==0: extract_question = key_question\n",
    "        # context = str(self.retrieve(query_or_queries=key_question).passages)\n",
    "        predicted_value = self.generate_answer(data=data, question=question).answer\n",
    "        reason_for_format_failure = self.value_format_validation_agent(format_json=format_json, extracted_values=predicted_value).reason_for_format_failure\n",
    "        print('---------------------------------')\n",
    "        print('$$$$$$ Coreason_for_format_failurentext:\\n', reason_for_format_failure)\n",
    "        dspy.Suggest(\n",
    "            len(reason_for_format_failure) <= 1000,\n",
    "            \"The reason for format failure should be short and less than 1000 characters\",\n",
    "        )\n",
    "            # print(\"Predicted Value: \", predicted_value)\n",
    "            # value_format_validation = self.value_format_validation_agent(key=key, value_format_description=value, extracted_content=str(predicted_value)).reason_for_format_failure\n",
    "            # out_collect.append(predicted_value)\n",
    "            # valid_context=True\n",
    "                # if value_format_validation != 'True':\n",
    "                #     key_question = self.question_rephrase_agent(original_context=context, reasons_for_format_failure=value_format_validation).rephrased_question \n",
    "                #     print('---------------------------------')\n",
    "                #     print('$$$$$$ Context:\\n', context)\n",
    "                #     print('$$$$$$ Predicted Value:\\n', predicted_value)\n",
    "                #     print(\"$$$$$$ Value Format Validation:\\n\", value_format_validation)\n",
    "                #     print(\"$$$$$$ Rephrased Question:\\n\", key_question)\n",
    "                #     print('---------------------------------')\n",
    "                #     # context = str(self.retrieve(query_or_queries=str(rephrased_question)).passages)\n",
    "                #     # self.retrieve.k+=1\n",
    "                #     valid_context=False\n",
    "                # else:\n",
    "                #     # prediction = self.generate_answer(context=context, question=key_question)\n",
    "                #     print('---------------------------------')\n",
    "                #     print(\"Retrieved Value: \", predicted_value)\n",
    "                #     print('---------------------------------')\n",
    "                #     valid_context=True\n",
    "                \n",
    "                # format_counter+=1\n",
    "\n",
    "                # if format_counter>2:\n",
    "                #     break\n",
    "        \n",
    "        # Actually retrieve values\n",
    "        # prediction = self.generate_answer(context=context, question=question)\n",
    "        # return dspy.Prediction(context=context, answer=predicted_value.answer)\n",
    "        return predicted_value\n",
    "                               \n",
    "\n",
    "# class GoogleSearch(dspy.Signature):\n",
    "#     \"\"\"Searches Google for a query and returns the top results.\"\"\"\n",
    "\n",
    "#     query = dspy.InputField()\n",
    "#     results = dspy.OutputField(desc=\"the top search results from Google.\")\n",
    "\n",
    "# class RAG(dspy.Module):\n",
    "#     def __init__(self, num_passages=3):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "#         self.generate_answer = dspy.ChainOfThought(SpreadsheetValues)\n",
    "    \n",
    "#     def forward(self, question):\n",
    "#         context = self.retrieve(question).passages\n",
    "#         prediction = self.generate_answer(context=context, question=question)\n",
    "#         return dspy.Prediction(context=context, answer=prediction.answer)\n",
    "\n",
    "\n",
    "# agent = dspy.ReAct(RAG, tools = [adding_tool] )\n",
    "# classify = dspy.Predict(SpreadsheetValues)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEY VALUE FORMATS:###\n",
    "    # key: Selling Costs, format: float between 0 and 1\n",
    "    # key: Disposition Fee, format: float between 0 and 1\n",
    "    # key: Net Operating Income, format: float >= 0\n",
    "    # key: Loan Assumption/Payoff, format: float <= 0\n",
    "    # key: Return of Forecasted Reserves, format: float <= 0\n",
    "    # key: CF Y 11, format: float >= 0\n",
    "    # key: Return of Maximum Offering Amount, format: float <= 0\n",
    "    # key: Projected Terminal Cap Rate, format: float between 0 and 1\n",
    "\n",
    "format_json = {'Selling Costs': 'float between 0 and 1', 'Disposition Fee': 'float between 0 and 1', 'Net Operating Income': 'float >= 0', 'Loan Assumption/Payoff': 'float <= 0', 'Return of Forecasted Reserves': 'float <= 0', 'CF Y 11': 'float >= 0', 'Return of Maximum Offering Amount': 'float <= 0', 'Projected Terminal Cap Rate': 'float between 0 and 1'}\n",
    "# format_json = json.dumps(format_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:540: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:562: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "DSPySuggestionError",
     "evalue": "The reason for format failure should be short and less than 1000 characters",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDSPySuggestionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m question\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlist\u001b[39m(format_json\u001b[38;5;241m.\u001b[39mkeys()))[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;66;03m#'Selling Costs, Disposition Fee, Net Operating Income, Loan Assumption/Payoff, Return of Forecasted Reserves, CF Y 11, Return of Maximum Offering Amount, Projected Terminal Cap Rate.'\u001b[39;00m\n\u001b[1;32m      2\u001b[0m spreadsheet_agent \u001b[38;5;241m=\u001b[39m SpreadSheetAnalyzer()\n\u001b[0;32m----> 3\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mspreadsheet_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_json\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_json\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/primitives/program.py:26\u001b[0m, in \u001b[0;36mModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 82\u001b[0m, in \u001b[0;36mSpreadSheetAnalyzer.forward\u001b[0;34m(self, data, question, format_json)\u001b[0m\n\u001b[1;32m     80\u001b[0m predicted_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_answer(data\u001b[38;5;241m=\u001b[39mdata, question\u001b[38;5;241m=\u001b[39mquestion)\u001b[38;5;241m.\u001b[39manswer\n\u001b[1;32m     81\u001b[0m reason_for_format_failure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_format_validation_agent(format_json\u001b[38;5;241m=\u001b[39mformat_json, extracted_values\u001b[38;5;241m=\u001b[39mpredicted_value)\u001b[38;5;241m.\u001b[39mreason_for_format_failure\n\u001b[0;32m---> 82\u001b[0m \u001b[43mdspy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSuggest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreason_for_format_failure\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mThe reason for format failure should be short and less than 1000 characters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m---------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m$$$$$$ Coreason_for_format_failurentext:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, reason_for_format_failure)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/primitives/assertions.py:74\u001b[0m, in \u001b[0;36mConstraint.__init__\u001b[0;34m(self, result, msg, target_module, is_metric)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_module \u001b[38;5;241m=\u001b[39m target_module\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_metric \u001b[38;5;241m=\u001b[39m is_metric\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/primitives/assertions.py:112\u001b[0m, in \u001b[0;36mSuggest.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    111\u001b[0m         dspy\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuggestionFailed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 112\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m DSPySuggestionError(\n\u001b[1;32m    113\u001b[0m             \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m    114\u001b[0m             msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmsg,\n\u001b[1;32m    115\u001b[0m             target_module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_module,\n\u001b[1;32m    116\u001b[0m             state\u001b[38;5;241m=\u001b[39mdsp\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mtrace,\n\u001b[1;32m    117\u001b[0m             is_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_metric,\n\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSuggestion function should always return [bool]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mDSPySuggestionError\u001b[0m: The reason for format failure should be short and less than 1000 characters"
     ]
    }
   ],
   "source": [
    "question=str(list(format_json.keys()))[1:-1] #'Selling Costs, Disposition Fee, Net Operating Income, Loan Assumption/Payoff, Return of Forecasted Reserves, CF Y 11, Return of Maximum Offering Amount, Projected Terminal Cap Rate.'\n",
    "spreadsheet_agent = SpreadSheetAnalyzer()\n",
    "output = spreadsheet_agent(data=docs[0].text, question=question, format_json=json.dumps(format_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Selling Costs: 0.01', 'Disposition Fee: 0.025', 'Net Operating Income: 4644391.071083585', 'Loan Assumption/Payoff: 0.045', 'Return of Forecasted Reserves: 0.065', 'CF Y 11: 0.065', 'Return of Maximum Offering Amount: 0.075', 'Projected Terminal Cap Rate: 0.0525']\n"
     ]
    }
   ],
   "source": [
    "print(output.split('Answer:')[-1].strip().split('\\n')[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selling Costs: 0.01\n",
      "Disposition Fee: 0.025\n",
      "Net Operating Income: 4644391.071083585\n",
      "Loan Assumption/Payoff: 0.045\n",
      "Return of Forecasted Reserves: 0.065\n",
      "CF Y 11: 0.065\n",
      "Return of Maximum Offering Amount: 0.075\n",
      "Projected Terminal Cap Rate: 0.0525\n",
      "DST Total Gain / (Loss): 44386706.97\n",
      "Return of Forecasted Reserves: 0.057147396939723295\n",
      "Sale Proceeds: 88464591.83016352\n",
      "Proceeds from Distributions: 36688942.39872597\n",
      "Return of Maximum Offering Amount: -77670566.54709445\n",
      "Projected Sales Price (95%): 85368331.11610779\n",
      "Selling Costs: -884645.9183016353\n",
      "Disposition Fee: -2211614.795754088\n",
      "Net Operating Income: 4644391.071083585\n",
      "Loan Assumption/Payoff: 0.045\n",
      "Return of Forecasted Reserves: 0.065\n",
      "CF Y 11: 0.065\n",
      "Return of Maximum Offering Amount: 0.075\n",
      "Projected Terminal Cap Rate: 0.0525\n",
      "DST Total Gain / (Loss): 44386706.97\n",
      "Return of Forecasted Reserves: 0.057147396939723295\n",
      "Sale Proceeds: 88464591.83016352\n",
      "Proceeds from Distributions: 36688942.39872597\n",
      "Return of Maximum Offering Amount: -77670566.54709445\n",
      "Projected Sales Price (95%): 85368331.11610779\n",
      "Selling Costs: -884645.9183016353\n",
      "Disposition Fee: -2211614.795754088\n",
      "Net Operating Income: 4644391.071083585\n",
      "Loan Assumption/Payoff: 0.045\n",
      "Return of Forecasted Reserves: 0.065\n",
      "CF Y 11: 0.065\n",
      "Return of Maximum Offering Amount: 0.075\n",
      "Projected Terminal Cap Rate: 0.0525\n",
      "DST Total Gain / (Loss): 44386706.97\n",
      "Return of Forecasted Reserves: 0.057147396939723295\n",
      "Sale Proceeds: 88464591.83016352\n",
      "Proceeds from Distributions: 36688942.39872597\n",
      "Return of Maximum Offering Amount: -77670566.54709445\n",
      "Projected Sales Price (95%): 85368331.11610779\n",
      "Selling Costs: -884645.9183016353\n",
      "Disposition Fee: -2211614.795754088\n",
      "Net Operating Income: 4644391.071083585\n",
      "Loan Assumption/Payoff: 0.045\n",
      "Return of Forecasted Reserves: 0.065\n",
      "CF Y 11: 0.065\n",
      "Return of Maximum Offering Amount: 0.075\n",
      "Projected Terminal Cap Rate: 0.0525\n",
      "DST Total Gain / (Loss): 44386706.97\n",
      "Return of Forecasted Reserves: 0.05714\n"
     ]
    }
   ],
   "source": [
    "print(output.split('Answer:')[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question='Retrieve the following values from the spreadsheet: Selling Costs, Disposition Fee, Net Operating Income, Loan Assumption/Payoff, Return of Forecasted Reserves, CF Y 11, Return of Maximum Offering Amount, Projected Terminal Cap Rate.\\nThen add Disposition Fee and Selling Cost together.'\n",
    "\n",
    "# question=\"What is the Disposition Fee and Selling Cost? There may be duplicate fields. Use the one that returns a value between 0 and 1.\"\n",
    "# context=text_representation\n",
    "context=docs[0].text\n",
    "result = agent(question=question, context=context, verbose=True)\n",
    "# result = classify(question=question, context=context)\n",
    "print(f\"Final Predicted Answer:\\n\\n{result.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/workspace/data/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx\"\n",
    "data = pd.read_excel(filepath, sheet_name=\"5 - Disposition Analysis\", header=None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=1, how='all', inplace=True)\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0, how='all', inplace=True)\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_representation = \"Spreadsheet Data:\\n\\n\"\n",
    "for index, row in data.iterrows():\n",
    "    row_text = ''#f\"Record {index + 1}: \"\n",
    "    row_items = []\n",
    "    for col_name, value in row.items():\n",
    "        # Handle NaN values explicitly if needed\n",
    "        value_text = 'None' if pd.isna(value) else str(value)\n",
    "        row_items.append(f\"{col_name}: {value_text}\")\n",
    "    row_text += \", \".join(row_items)\n",
    "    text_representation += row_text + \"\\n\"\n",
    "\n",
    "# print(text_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from llama_index.core.query_pipeline import QueryPipeline as QP, InputComponent, FnComponent\n",
    "from dspy.predict.llamaindex import DSPyComponent, LlamaIndexModule\n",
    "\n",
    "dspy_component = DSPyComponent(\n",
    "    dspy.ChainOfThought(GenerateAnswer),\n",
    "    # dspy.ReAct(\"question -> answer\", tools=[dspy.Retrieve(k=1), adding_tool] )\n",
    ")\n",
    "\n",
    "retriever_post = FnComponent(\n",
    "    lambda contexts: \"\\n\\n\".join([n.get_content() for n in contexts])\n",
    ")\n",
    "\n",
    "\n",
    "p = QP(verbose=True)\n",
    "p.add_modules(\n",
    "    {\n",
    "        \"input\": InputComponent(),\n",
    "        \"retriever\": retriever,\n",
    "        \"retriever_post\": retriever_post,\n",
    "        \"synthesizer\": dspy_component,\n",
    "    }\n",
    ")\n",
    "p.add_link(\"input\", \"retriever\")\n",
    "p.add_link(\"retriever\", \"retriever_post\")\n",
    "p.add_link(\"input\", \"synthesizer\", dest_key=\"query_str\")\n",
    "p.add_link(\"retriever_post\", \"synthesizer\", dest_key=\"context_str\")\n",
    "\n",
    "\n",
    "dspy_qp = LlamaIndexModule(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "out = dspy_qp(query_str=\"What is the Disposition Fee and Selling Cost? Add them together.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(out.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = dspy.ReAct(\"question -> answer\", tools=[dspy.Retrieve(k=1), adding_tool] )\n",
    "agent(question=\"What is the Disposition Fee and Selling Cost?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any, Callable, Optional\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plan(dspy.Signature):\n",
    "    \"\"\"Produce a step by step plan to perform the task. \n",
    "The plan needs to be in markdown format and should be broken down into big steps (with ## headings) and sub-steps beneath those.\n",
    "When thinking about your plan, be sure to think about the tools at your disposal and include them in your plan.\n",
    "    \"\"\"\n",
    "    task = dspy.InputField(prefix=\"Task\", desc=\"The task\")\n",
    "    context = dspy.InputField(format=str, desc=\"The context around the plan\")\n",
    "    proposed_plan = dspy.OutputField(desc=\"The proposed, step by step execution plan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker(dspy.Module):\n",
    "    def __init__(self, role:str, tools:List):\n",
    "        self.role = role\n",
    "        self.tools = tools\n",
    "        self.tool_descriptions = \"\\n\".join([f\"- {t.name}: {t.description}. To use this tool please provide: `{t.requires}`\" for t in tools])\n",
    "        self.plan = dspy.ChainOfThought(Plan)\n",
    "    def forward(self, task:str):\n",
    "        context = f\"{self.role}\\n{self.tool_descriptions}\"\n",
    "        input_args = dict(\n",
    "            context = context,\n",
    "            task = task\n",
    "        ) # just did args for printing for debugging\n",
    "        result = self.plan(**input_args)\n",
    "        print(result.proposed_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    requires: str\n",
    "    func: Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tools = [\n",
    "    Tool(name=\"phone\", description=\"a way of making phone calls\", requires=\"phone_number\", func=lambda x: \"they've got time\"),\n",
    "    Tool(name=\"local business lookup\", description=\"Look up businesses by category\", requires=\"business category\", func=lambda x: \"Bills landscaping: 415-555-5555\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dspy.context(lm=wrkr):\n",
    "    Worker(\"assistant\", test_tools).forward(\"get this yard cleaned up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker2(dspy.Module):\n",
    "    def __init__(self, role:str, tools:List):\n",
    "        self.role = role\n",
    "        self.tools = dict([(t.name, t) for t in tools])\n",
    "        self.tool_descriptions = \"\\n\".join([f\"- {t.name}: {t.description}. To use this tool please provide: `{t.requires}`\" for t in tools])\n",
    "        self._plan = dspy.ChainOfThought(Plan)\n",
    "        self._tool = dspy.ChainOfThought(\"task, context -> tool_name, tool_argument\")\n",
    "        \n",
    "        print(self.tool_descriptions)\n",
    "    def plan(self, task:str, feedback:Optional[str]=None):\n",
    "        context = f\"Your role:{self.role}\\n Tools at your disposal:\\n{self.tool_descriptions}\"\n",
    "        if feedback:\n",
    "            context += f\"\\nPrevious feedback on your prior plan {feedback}\"\n",
    "        input_args = dict(\n",
    "            task=task,\n",
    "            context=context\n",
    "        )    \n",
    "        result = self._plan(**input_args)\n",
    "        return result.proposed_plan\n",
    "    def execute(self, task:str, use_tool:bool):\n",
    "        print(f\"executing {task}\")\n",
    "        if not use_tool:\n",
    "            return f\"{task} completed successfully\"\n",
    "            \n",
    "        res = self._tool(task=task, context=self.tool_descriptions)\n",
    "        t = res.tool_name\n",
    "        arg = res.tool_argument\n",
    "        if t in self.tools:\n",
    "            complete = self.tools[t].func(arg)\n",
    "            return complete\n",
    "        return \"Not done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicGuardrails(dspy.Signature):\n",
    "    \"\"\"Please assess whether this generated topic list is properly formatted as a comma-separated list.\"\"\"\n",
    "    \n",
    "    topic_str = dspy.InputField()\n",
    "    properly_formatted = dspy.OutputField(desc = \"only output True or False\")\n",
    "    reason_for_properly_formatted_decision = dspy.OutputField()\n",
    "\n",
    "class RetryTopic(dspy.Signature):\n",
    "    \"\"\"Given the original output and the reason for it's failure, please correct it. \n",
    "    Please also remove any extra text before the topics begin such as something lik `A list of topics the blog will cover:`\"\"\"\n",
    "    \n",
    "    original_output = dspy.InputField()\n",
    "    reason_for_failure = dspy.InputField()\n",
    "    corrected_output = dspy.OutputField()\n",
    "\n",
    "class Blog2OutlineWithCustomGuardrails(dspy.Module):\n",
    "    def __init__(self, weaviate_rm, you_rm):\n",
    "        self.question_to_blog_outline = dspy.Predict(Question2BlogOutline)\n",
    "        self.topic_guardrails = dspy.Predict(TopicGuardrails)\n",
    "        self.retry_topic = dspy.Predict(RetryTopic)\n",
    "        self.weaviate_rm = weaviate_rm\n",
    "        self.you_rm = you_rm\n",
    "\n",
    "    def forward(self, question):\n",
    "        blog_contexts = self.weaviate_rm(question)\n",
    "        web_contexts = self.you_rm(question)\n",
    "        blog_contexts, web_contexts = format_weaviate_and_you_contexts(blog_contexts, web_contexts)\n",
    "        question_to_blog_outline_outputs = self.question_to_blog_outline(question=question, blog_context=blog_contexts, web_context=web_contexts)\n",
    "        blog_outline = question_to_blog_outline_outputs.blog_outline\n",
    "        counter = 0\n",
    "        while True:\n",
    "            with dspy.context(lm=gpt4):\n",
    "                guardrails_outputs = self.topic_guardrails(topic_str=blog_outline)\n",
    "            print(f\"\\n Guardrails Outputs {guardrails_outputs}\")\n",
    "            if guardrails_outputs.properly_formatted == 'True':\n",
    "                break\n",
    "            reason_for_failure = guardrails_outputs.reason_for_properly_formatted_decision\n",
    "            blog_outline = self.retry_topic(original_output=blog_outline, reason_for_failure=reason_for_failure).corrected_output\n",
    "            print(f\"\\n Retried Blog Outline: {blog_outline}\\n\")\n",
    "            counter += 1\n",
    "            if counter >= 3:\n",
    "                print(\"Exceeded Retry Limit, exiting.\")\n",
    "                break\n",
    "        return blog_outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Functions and subfuctions\n",
    "\n",
    "from dspy.functional import TypedPredictor\n",
    "import pydantic\n",
    "from typing import List\n",
    "\n",
    "# defining what a Topic is\n",
    "class Topic(pydantic.BaseModel):\n",
    "    topic: str\n",
    "    topic_description: str\n",
    "\n",
    "\n",
    "class Topics(pydantic.BaseModel):\n",
    "    topics: List[Topic]\n",
    "\n",
    "class TypedQuestion2BlogOutline(dspy.Signature):\n",
    "    \"\"\"Your task is to write a Weaviate blog post that will help answer the given question.\\nPlease use the contexts from a web search and published Weaviate blog posts to evaluate the structure of the blog post.\"\"\"\n",
    "    \n",
    "    question: str = dspy.InputField()\n",
    "    blog_context: str = dspy.InputField()\n",
    "    web_context: str = dspy.InputField()\n",
    "    # Notice here how the class Topics is used to specify the output type. Brilliant.\n",
    "    blog_outline: Topics = dspy.OutputField(desc=\"A list of topics the blog will cover. IMPORTANT!! This must follow a comma separated list of values!\")\n",
    "\n",
    "\n",
    "\n",
    "############ Putting it all together\n",
    "import functools\n",
    "\n",
    "class TypedBlog2Outline(dspy.Module):\n",
    "    def __init__(self, weaviate_rm, you_rm):\n",
    "        self.question_to_blog_outline = dspy.functional.TypedPredictor(TypedQuestion2BlogOutline)\n",
    "        self.weaviate_rm = weaviate_rm\n",
    "        self.you_rm = you_rm\n",
    "\n",
    "    def forward(self, question):\n",
    "        blog_contexts = self.weaviate_rm(question)\n",
    "        web_contexts = self.you_rm(question)\n",
    "        blog_contexts, web_contexts = format_weaviate_and_you_contexts(blog_contexts, web_contexts)\n",
    "        question_to_blog_outline_outputs = self.question_to_blog_outline(question=question, blog_context=blog_contexts, web_context=web_contexts)\n",
    "        return question_to_blog_outline_outputs.blog_outline\n",
    "\n",
    "                                                                         \n",
    "blog2outline = TypedBlog2Outline(weaviate_rm, you_rm)\n",
    "        \n",
    "toy_question = \"What are cross encoders?\"\n",
    "\n",
    "for lm_dict in lms:\n",
    "    lm, name = lm_dict[\"lm\"], lm_dict[\"name\"]\n",
    "    with dspy.context(lm=lm):\n",
    "        print(f\"\\033[91mResult for {name}\\n\")\n",
    "        print(f\"\\033[0m{blog2outline(question=toy_question)} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### This might be the better way to do it\n",
    "\n",
    "class TopicGuardrails(dspy.Signature):\n",
    "    \"\"\"Please assess whether this generated topic list is properly formatted as a comma-separated list.\"\"\"\n",
    "    \n",
    "    topic_str = dspy.InputField()\n",
    "    properly_formatted = dspy.OutputField(desc = \"only output True or False\")\n",
    "    reason_for_properly_formatted_decision = dspy.OutputField()\n",
    "\n",
    "class RetryTopic(dspy.Signature):\n",
    "    \"\"\"Given the original output and the reason for it's failure, please correct it. \n",
    "    Please also remove any extra text before the topics begin such as something lik `A list of topics the blog will cover:`\"\"\"\n",
    "    \n",
    "    original_output = dspy.InputField()\n",
    "    reason_for_failure = dspy.InputField()\n",
    "    corrected_output = dspy.OutputField()\n",
    "\n",
    "class Blog2OutlineWithCustomGuardrails(dspy.Module):\n",
    "    def __init__(self, weaviate_rm, you_rm):\n",
    "        self.question_to_blog_outline = dspy.Predict(Question2BlogOutline)\n",
    "        self.topic_guardrails = dspy.Predict(TopicGuardrails)\n",
    "        self.retry_topic = dspy.Predict(RetryTopic)\n",
    "        self.weaviate_rm = weaviate_rm\n",
    "        self.you_rm = you_rm\n",
    "\n",
    "    def forward(self, question):\n",
    "        blog_contexts = self.weaviate_rm(question)\n",
    "        web_contexts = self.you_rm(question)\n",
    "        blog_contexts, web_contexts = format_weaviate_and_you_contexts(blog_contexts, web_contexts)\n",
    "        question_to_blog_outline_outputs = self.question_to_blog_outline(question=question, blog_context=blog_contexts, web_context=web_contexts)\n",
    "        blog_outline = question_to_blog_outline_outputs.blog_outline\n",
    "        counter = 0\n",
    "        while True:\n",
    "            with dspy.context(lm=gpt4):\n",
    "                guardrails_outputs = self.topic_guardrails(topic_str=blog_outline)\n",
    "            print(f\"\\n Guardrails Outputs {guardrails_outputs}\")\n",
    "            if guardrails_outputs.properly_formatted == 'True':\n",
    "                break\n",
    "            reason_for_failure = guardrails_outputs.reason_for_properly_formatted_decision\n",
    "            blog_outline = self.retry_topic(original_output=blog_outline, reason_for_failure=reason_for_failure).corrected_output\n",
    "            print(f\"\\n Retried Blog Outline: {blog_outline}\\n\")\n",
    "            counter += 1\n",
    "            if counter >= 3:\n",
    "                print(\"Exceeded Retry Limit, exiting.\")\n",
    "                break\n",
    "        return blog_outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.utils import flatten, deduplicate\n",
    "\n",
    "AGENTS = [x[-1] for x in optimized_react.candidate_programs[:5]]\n",
    "\n",
    "class Aggregator(dspy.Module):\n",
    "\tdef __init__(self, temperature=0.0):\n",
    "\t\tself.aggregate = dspy.ChainOfThought('context, question -> answer')\n",
    "\t\tself.temperature = temperature\n",
    "\n",
    "\tdef forward(self, question):\n",
    "\t\t# Run all five agents with high temperature, then extract and deduplicate their observed contexts\n",
    "\t\twith dspy.context(lm=gpt3.copy(temperature=self.temperature)):\n",
    "\t\t\tpreds = [agent(question=question) for agent in AGENTS]\n",
    "\t\t\tcontext = deduplicate(flatten([flatten(p.observations) for p in preds]))\n",
    "\n",
    "\t\t# Run the aggregation step to produce a final answer\n",
    "\t\treturn self.aggregate(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from typing import List, Literal\n",
    "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.base.llms.types import (\n",
    "    ChatMessage,\n",
    "    MessageRole,\n",
    ")\n",
    "\n",
    "\n",
    "query_engine_tools = QueryEngineTool(\n",
    "    query_engine=query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"spreadsheet_value_retriever\",\n",
    "        description=\"contains the information of a spreadsheet, and is useful for retrieving specific values from a spreadsheet\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "def adding_values(values: List[float]):\n",
    "    return sum(values)\n",
    "\n",
    "\n",
    "class AddingArgs(BaseModel):\n",
    "    values: List = Field(\n",
    "        description=\"A list of values to add together.\"\n",
    "    )\n",
    "\n",
    "adding_tool = FunctionTool.from_defaults(\n",
    "    fn=adding_values,\n",
    "    name=\"sum_values\",\n",
    "    description=\"Add a list of values together\",\n",
    "    fn_schema=AddingArgs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = ['Selling Costs',\n",
    "  'Disposition Fee',\n",
    "  'Net Operating Income',\n",
    "  'Loan Assumption/Payoff',\n",
    "  'Return of Forecasted Reserves',\n",
    "  'CF Y 11',\n",
    "  'Return of Maximum Offering Amount',\n",
    "  'Projected Terminal Cap Rate',\n",
    "  'Cash Flows']\n",
    "content='Retrieve the following values from the spreadsheet: Selling Costs, Disposition Fee, Net Operating Income, Loan Assumption/Payoff, Return of Forecasted Reserves, CF Y 11, Return of Maximum Offering Amount, Projected Terminal Cap Rate, Cash Flows (categories 1 through 9)\\nThen add Disposition Fee and Selling Cost together.'\n",
    "\n",
    "usr_msg = ChatMessage(\n",
    "    role=MessageRole.ASSISTANT,\n",
    "    content=content\n",
    ")\n",
    "response = agent1.chat(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content='Retrieve the following values from the spreadsheet: Selling Costs, Disposition Fee, Net Operating Income, Loan Assumption/Payoff, Return of Forecasted Reserves, CF Y 11, Return of Maximum Offering Amount, Projected Terminal Cap Rate, Cash Flows (categories 1 through 9)\\nThen add Disposition Fee and Selling Cost together.'\n",
    "\n",
    "messages = [\n",
    "        {\"role\": \"user\", \"content\": content},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
