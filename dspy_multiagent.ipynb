{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 install llama-index llama-parse llama-index-embeddings-huggingface accelerate dspy-ai openpyxl langchain chromadb\n",
    "!pip3 install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.datasets.hotpotqa import HotPotQA\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "# from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "# from llama_index.readers.file import PandasExcelReader\n",
    "# from llama_index.core.embeddings import resolve_embed_model\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "from typing import List, Any, Callable, Optional\n",
    "from pydantic import BaseModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(BaseModel):\n",
    "    name: str\n",
    "    desc: str\n",
    "    input_variable: str\n",
    "    func: Callable\n",
    "    \n",
    "# class GiveTime:\n",
    "#     name = \"GiveTime\"\n",
    "#     input_variable = \"empty\"\n",
    "#     desc = \"takes an empty string and returns the current local time\"\n",
    "\n",
    "#     def __init__(self, k=3):\n",
    "#         pass\n",
    "   \n",
    "#     def __call__(self, *args, **kwargs):\n",
    "#         return datetime.datetime.now().strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_values(input_variable: List[float])->float:\n",
    "    return sum(input_variable)\n",
    "\n",
    "adding_tool = Tool(name=\"addition\", desc=\"add a list of floats together\", input_variable=\"input_variable\", func=add_values)\n",
    "\n",
    "# test_tools = [\n",
    "    # Tool(name=\"addition\", description=\"add a list of floats together\", requires=\"values\", func=add_values)\n",
    "    # Tool(name=\"local business lookup\", description=\"Look up businesses by category\", requires=\"business category\", func=lambda x: \"Bills landscaping: 415-555-5555\")\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first model load...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting model...\n",
      "reloading model...\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
    "from llama_index.readers.file import PandasExcelReader\n",
    "CHROMA_COLLECTION_NAME = \"blockchain_and_ai\"\n",
    "CHROMADB_DIR = \"/workspace/data/db/\"\n",
    "\n",
    "access_token = \"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\"\n",
    "# model_name = \"EleutherAI/gpt-neo-125m\"\n",
    "# model_name = \"clibrain/mamba-2.8b-instruct-openhermes\"\n",
    "# model_name = \"microsoft/Phi-3-mini-128k-instruct\" # 128K context window\n",
    "# model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\" # 8K context window\n",
    "# model_name = \"mistralai/Mistral-7B-Instruct-v0.3\" # 32K context window\n",
    "# model_name = \"clibrain/mamba-2.8b-instruct-openhermes\" # 8K context window\n",
    "# embed_model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "print('first model load...')\n",
    "model_name = \"Qwen/Qwen2-1.5B-Instruct\"\n",
    "llm = dspy.HFModel(model=model_name, hf_device_map='auto', token=access_token)\n",
    "llm.kwargs['max_new_tokens']=1000\n",
    "llm.kwargs['do_sample']=True\n",
    "# llm.kwargs['typical_p']=0.9\n",
    "# llm.kwargs['temperature']=0.0\n",
    "\n",
    "\n",
    "print('deleting model...')\n",
    "llm.model=None\n",
    "gc.collect\n",
    "print('reloading model...')\n",
    "llm.model=AutoModelForCausalLM.from_pretrained(model_name, quantization_config=None, \n",
    "                                               trust_remote_code=True, device_map=\"auto\", \n",
    "                                               attn_implementation=\"flash_attention_2\",  \n",
    "                                               torch_dtype=torch.float16)\n",
    "\n",
    "# llm.model.generation_config.pad_token_id = llm.tokenizer.eos_token_id\n",
    "# llm.tokenizer.pad_token_id = llm.tokenizer.eos_token_id\n",
    "\n",
    "# retriever = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
    "filepath = \"/workspace/data/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx\"\n",
    "docs = PandasExcelReader(sheet_name=\"5 - Disposition Analysis\").load_data(filepath)\n",
    "# # embed_model = HuggingFaceEmbedding(model_name=embed_model_name)\n",
    "# # vector_index = VectorStoreIndex.from_documents(documents, embed_model=embed_model)\n",
    "# # vector_index.storage_context.persist(persist_dir=\"/workspace/data/storage/alpha\")\n",
    "# # retriever = vector_index.as_retriever(top_k=2)\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=CHROMADB_DIR)\n",
    "collection = chroma_client.get_or_create_collection(name=CHROMA_COLLECTION_NAME)\n",
    "text_splitter = SentenceTransformersTokenTextSplitter()\n",
    "\n",
    "ids = []\n",
    "documents = []\n",
    "metadatas = []\n",
    "chunks = text_splitter.create_documents([docs[0].text], )\n",
    "for chunk_no, chunk in enumerate(chunks):\n",
    "    ids.append(f\"{chunk_no}\")\n",
    "    documents.append(chunk.page_content)\n",
    "    # metadatas.append({\"title\":})\n",
    "if ids:\n",
    "    collection.upsert(ids=ids, documents=documents)#, metadatas=metadatas)\n",
    "\n",
    "# collection.upsert(documents=[docs[0].text])\n",
    "\n",
    "\n",
    "# default_ef = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
    "default_ef = embedding_functions.DefaultEmbeddingFunction()\n",
    "retriever = ChromadbRM(CHROMA_COLLECTION_NAME, CHROMADB_DIR, default_ef, k=3)\n",
    "\n",
    "dspy.settings.configure(lm=llm, rm=retriever)\n",
    "# dspy.settings.configure(lm=llm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uncompiled_rag = RAG()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question='Retrieve the following values from the spreadsheet: Selling Costs, Disposition Fee, Net Operating Income, Loan Assumption/Payoff, Return of Forecasted Reserves, CF Y 11, Return of Maximum Offering Amount, Projected Terminal Cap Rate.\\nThen add Disposition Fee and Selling Cost together.'\n",
    "answer = uncompiled_rag(question).answer\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tune spreadsheet model\n",
    "# dspy module class for multiagent stuff with tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!cp /workspace/repos/agentic-ai/MASTER\\ -\\ PYTHON\\ -\\ SCORING\\ MODEL\\ -\\ MCG\\ MADISON\\ RIDGE\\ DST\\ -\\ v2.0.xlsx /workspace/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/workspace/data/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx\"\n",
    "docs = PandasExcelReader(sheet_name=\"5 - Disposition Analysis\", pandas_config={'keep_default_na':False}).load_data(filepath)\n",
    "# docs2 = PandasExcelReader(sheet_name=\"5 - Disposition Analysis\").load_data(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mdspy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m      <no docstring>\n",
      "\u001b[0;31mFile:\u001b[0m           /usr/local/lib/python3.10/dist-packages/dspy/predict/predict.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     ChainOfThought, ChainOfThoughtWithHint, Retry"
     ]
    }
   ],
   "source": [
    "dspy.Predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__class_vars__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__fields_set__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__get_pydantic_core_schema__',\n",
       " '__get_pydantic_json_schema__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pretty__',\n",
       " '__private_attributes__',\n",
       " '__pydantic_complete__',\n",
       " '__pydantic_core_schema__',\n",
       " '__pydantic_custom_init__',\n",
       " '__pydantic_decorators__',\n",
       " '__pydantic_extra__',\n",
       " '__pydantic_fields_set__',\n",
       " '__pydantic_generic_metadata__',\n",
       " '__pydantic_init_subclass__',\n",
       " '__pydantic_parent_namespace__',\n",
       " '__pydantic_post_init__',\n",
       " '__pydantic_private__',\n",
       " '__pydantic_root_model__',\n",
       " '__pydantic_serializer__',\n",
       " '__pydantic_validator__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__repr_args__',\n",
       " '__repr_name__',\n",
       " '__repr_str__',\n",
       " '__rich_repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__signature__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_calculate_keys',\n",
       " '_check_frozen',\n",
       " '_copy_and_set_values',\n",
       " '_get_value',\n",
       " '_iter',\n",
       " 'construct',\n",
       " 'copy',\n",
       " 'dict',\n",
       " 'from_orm',\n",
       " 'json',\n",
       " 'model_computed_fields',\n",
       " 'model_config',\n",
       " 'model_construct',\n",
       " 'model_copy',\n",
       " 'model_dump',\n",
       " 'model_dump_json',\n",
       " 'model_extra',\n",
       " 'model_fields',\n",
       " 'model_fields_set',\n",
       " 'model_json_schema',\n",
       " 'model_parametrized_name',\n",
       " 'model_post_init',\n",
       " 'model_rebuild',\n",
       " 'model_validate',\n",
       " 'model_validate_json',\n",
       " 'model_validate_strings',\n",
       " 'parse_file',\n",
       " 'parse_obj',\n",
       " 'parse_raw',\n",
       " 'replace',\n",
       " 'schema',\n",
       " 'schema_json',\n",
       " 'update_forward_refs',\n",
       " 'validate']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dspy.Signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpreadsheetValues(dspy.Signature):\n",
    "    \"\"\"Parses through spreadsheet information and returns requested values.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"data in spreadsheet format.\")\n",
    "    question = dspy.InputField(desc=\"the question containing values to be extracted from the context.\")\n",
    "    answer = dspy.OutputField(desc=\"the float value or values from the spreadsheet.\")\n",
    "\n",
    "class RagValidationAgent(dspy.Signature):\n",
    "    \"\"\"Ensure the context from the retriever contains the key specified in the question with the correct format as described in key_value_formats. If the output is correct, return True, otherwise return False.\n",
    "    \n",
    "    KEY VALUE FORMATS:###\n",
    "    key: Selling Costs, format: float between 0 and 1\n",
    "    key: Disposition Fee, format: float between 0 and 1\n",
    "    key: Net Operating Income, format: float >= 0\n",
    "    key: Loan Assumption/Payoff, format: float <= 0\n",
    "    key: Return of Forecasted Reserves, format: float <= 0\n",
    "    key: CF Y 11, format: float >= 0\n",
    "    key: Return of Maximum Offering Amount, format: float <= 0\n",
    "    key: Projected Terminal Cap Rate, format: float between 0 and 1\n",
    "    \"\"\"\n",
    "\n",
    "    question = dspy.InputField(desc=\"the question regarding values in a spreadsheet\")\n",
    "    context = dspy.InputField(desc=\"The output from a retriever model.\")\n",
    "    verify = dspy.OutputField(desc=\"If the context contains the correct values, output True, otherwise output the {key} and {format} needing to be corrected.\")\n",
    "\n",
    "\n",
    "\n",
    "class SpreadSheetAnalyzer(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.validation_agent = RagValidationAgent()\n",
    "        self.generate_answer = dspy.ChainOfThought(SpreadsheetValues)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        valid_context = False\n",
    "        counter = 0\n",
    "        while not valid_context:\n",
    "            print('counter:', counter)\n",
    "            context = self.retrieve(question=question).passages\n",
    "            validation = self.validation_agent(context=context, question=question).verify\n",
    "            if  validation!= 'True':\n",
    "                question = \"Wrong key(s) retrieved in the wrong format(s). The key(s) and format(s) needed is \" + validation\n",
    "                valid_context=False\n",
    "            else:\n",
    "                valid_context=True\n",
    "            counter+=1\n",
    "            \n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)\n",
    "                               \n",
    "\n",
    "# class GoogleSearch(dspy.Signature):\n",
    "#     \"\"\"Searches Google for a query and returns the top results.\"\"\"\n",
    "\n",
    "#     query = dspy.InputField()\n",
    "#     results = dspy.OutputField(desc=\"the top search results from Google.\")\n",
    "\n",
    "# class RAG(dspy.Module):\n",
    "#     def __init__(self, num_passages=3):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "#         self.generate_answer = dspy.ChainOfThought(SpreadsheetValues)\n",
    "    \n",
    "#     def forward(self, question):\n",
    "#         context = self.retrieve(question).passages\n",
    "#         prediction = self.generate_answer(context=context, question=question)\n",
    "#         return dspy.Prediction(context=context, answer=prediction.answer)\n",
    "\n",
    "\n",
    "# agent = dspy.ReAct(RAG, tools = [adding_tool] )\n",
    "# classify = dspy.Predict(SpreadsheetValues)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "3 validation errors for RagValidationAgent\nquestion\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing\ncontext\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing\nverify\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m question\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetrieve the following values from the spreadsheet: Selling Costs, Disposition Fee, Net Operating Income, Loan Assumption/Payoff, Return of Forecasted Reserves, CF Y 11, Return of Maximum Offering Amount, Projected Terminal Cap Rate.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThen add Disposition Fee and Selling Cost together.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m spreadsheet_agent \u001b[38;5;241m=\u001b[39m \u001b[43mSpreadSheetAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m output \u001b[38;5;241m=\u001b[39m spreadsheet_agent(question\u001b[38;5;241m=\u001b[39mquestion)\n",
      "Cell \u001b[0;32mIn[15], line 33\u001b[0m, in \u001b[0;36mSpreadSheetAnalyzer.__init__\u001b[0;34m(self, num_passages)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve \u001b[38;5;241m=\u001b[39m dspy\u001b[38;5;241m.\u001b[39mRetrieve(k\u001b[38;5;241m=\u001b[39mnum_passages)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_agent \u001b[38;5;241m=\u001b[39m \u001b[43mRagValidationAgent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_answer \u001b[38;5;241m=\u001b[39m dspy\u001b[38;5;241m.\u001b[39mChainOfThought(SpreadsheetValues)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dspy/signatures/signature.py:35\u001b[0m, in \u001b[0;36mSignatureMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Signature:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m make_signature(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/main.py:193\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    192\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 3 validation errors for RagValidationAgent\nquestion\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing\ncontext\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing\nverify\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.8/v/missing"
     ]
    }
   ],
   "source": [
    "question='Retrieve the following values from the spreadsheet: Selling Costs, Disposition Fee, Net Operating Income, Loan Assumption/Payoff, Return of Forecasted Reserves, CF Y 11, Return of Maximum Offering Amount, Projected Terminal Cap Rate.\\nThen add Disposition Fee and Selling Cost together.'\n",
    "spreadsheet_agent = SpreadSheetAnalyzer()\n",
    "output = spreadsheet_agent(question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question='Retrieve the following values from the spreadsheet: Selling Costs, Disposition Fee, Net Operating Income, Loan Assumption/Payoff, Return of Forecasted Reserves, CF Y 11, Return of Maximum Offering Amount, Projected Terminal Cap Rate.\\nThen add Disposition Fee and Selling Cost together.'\n",
    "\n",
    "# question=\"What is the Disposition Fee and Selling Cost? There may be duplicate fields. Use the one that returns a value between 0 and 1.\"\n",
    "# context=text_representation\n",
    "context=docs[0].text\n",
    "result = agent(question=question, context=context, verbose=True)\n",
    "# result = classify(question=question, context=context)\n",
    "print(f\"Final Predicted Answer:\\n\\n{result.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/workspace/data/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx\"\n",
    "data = pd.read_excel(filepath, sheet_name=\"5 - Disposition Analysis\", header=None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=1, how='all', inplace=True)\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0, how='all', inplace=True)\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_representation = \"Spreadsheet Data:\\n\\n\"\n",
    "for index, row in data.iterrows():\n",
    "    row_text = ''#f\"Record {index + 1}: \"\n",
    "    row_items = []\n",
    "    for col_name, value in row.items():\n",
    "        # Handle NaN values explicitly if needed\n",
    "        value_text = 'None' if pd.isna(value) else str(value)\n",
    "        row_items.append(f\"{col_name}: {value_text}\")\n",
    "    row_text += \", \".join(row_items)\n",
    "    text_representation += row_text + \"\\n\"\n",
    "\n",
    "# print(text_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from llama_index.core.query_pipeline import QueryPipeline as QP, InputComponent, FnComponent\n",
    "from dspy.predict.llamaindex import DSPyComponent, LlamaIndexModule\n",
    "\n",
    "dspy_component = DSPyComponent(\n",
    "    dspy.ChainOfThought(GenerateAnswer),\n",
    "    # dspy.ReAct(\"question -> answer\", tools=[dspy.Retrieve(k=1), adding_tool] )\n",
    ")\n",
    "\n",
    "retriever_post = FnComponent(\n",
    "    lambda contexts: \"\\n\\n\".join([n.get_content() for n in contexts])\n",
    ")\n",
    "\n",
    "\n",
    "p = QP(verbose=True)\n",
    "p.add_modules(\n",
    "    {\n",
    "        \"input\": InputComponent(),\n",
    "        \"retriever\": retriever,\n",
    "        \"retriever_post\": retriever_post,\n",
    "        \"synthesizer\": dspy_component,\n",
    "    }\n",
    ")\n",
    "p.add_link(\"input\", \"retriever\")\n",
    "p.add_link(\"retriever\", \"retriever_post\")\n",
    "p.add_link(\"input\", \"synthesizer\", dest_key=\"query_str\")\n",
    "p.add_link(\"retriever_post\", \"synthesizer\", dest_key=\"context_str\")\n",
    "\n",
    "\n",
    "dspy_qp = LlamaIndexModule(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "out = dspy_qp(query_str=\"What is the Disposition Fee and Selling Cost? Add them together.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(out.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = dspy.ReAct(\"question -> answer\", tools=[dspy.Retrieve(k=1), adding_tool] )\n",
    "agent(question=\"What is the Disposition Fee and Selling Cost?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any, Callable, Optional\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plan(dspy.Signature):\n",
    "    \"\"\"Produce a step by step plan to perform the task. \n",
    "The plan needs to be in markdown format and should be broken down into big steps (with ## headings) and sub-steps beneath those.\n",
    "When thinking about your plan, be sure to think about the tools at your disposal and include them in your plan.\n",
    "    \"\"\"\n",
    "    task = dspy.InputField(prefix=\"Task\", desc=\"The task\")\n",
    "    context = dspy.InputField(format=str, desc=\"The context around the plan\")\n",
    "    proposed_plan = dspy.OutputField(desc=\"The proposed, step by step execution plan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker(dspy.Module):\n",
    "    def __init__(self, role:str, tools:List):\n",
    "        self.role = role\n",
    "        self.tools = tools\n",
    "        self.tool_descriptions = \"\\n\".join([f\"- {t.name}: {t.description}. To use this tool please provide: `{t.requires}`\" for t in tools])\n",
    "        self.plan = dspy.ChainOfThought(Plan)\n",
    "    def forward(self, task:str):\n",
    "        context = f\"{self.role}\\n{self.tool_descriptions}\"\n",
    "        input_args = dict(\n",
    "            context = context,\n",
    "            task = task\n",
    "        ) # just did args for printing for debugging\n",
    "        result = self.plan(**input_args)\n",
    "        print(result.proposed_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    requires: str\n",
    "    func: Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tools = [\n",
    "    Tool(name=\"phone\", description=\"a way of making phone calls\", requires=\"phone_number\", func=lambda x: \"they've got time\"),\n",
    "    Tool(name=\"local business lookup\", description=\"Look up businesses by category\", requires=\"business category\", func=lambda x: \"Bills landscaping: 415-555-5555\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dspy.context(lm=wrkr):\n",
    "    Worker(\"assistant\", test_tools).forward(\"get this yard cleaned up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker2(dspy.Module):\n",
    "    def __init__(self, role:str, tools:List):\n",
    "        self.role = role\n",
    "        self.tools = dict([(t.name, t) for t in tools])\n",
    "        self.tool_descriptions = \"\\n\".join([f\"- {t.name}: {t.description}. To use this tool please provide: `{t.requires}`\" for t in tools])\n",
    "        self._plan = dspy.ChainOfThought(Plan)\n",
    "        self._tool = dspy.ChainOfThought(\"task, context -> tool_name, tool_argument\")\n",
    "        \n",
    "        print(self.tool_descriptions)\n",
    "    def plan(self, task:str, feedback:Optional[str]=None):\n",
    "        context = f\"Your role:{self.role}\\n Tools at your disposal:\\n{self.tool_descriptions}\"\n",
    "        if feedback:\n",
    "            context += f\"\\nPrevious feedback on your prior plan {feedback}\"\n",
    "        input_args = dict(\n",
    "            task=task,\n",
    "            context=context\n",
    "        )    \n",
    "        result = self._plan(**input_args)\n",
    "        return result.proposed_plan\n",
    "    def execute(self, task:str, use_tool:bool):\n",
    "        print(f\"executing {task}\")\n",
    "        if not use_tool:\n",
    "            return f\"{task} completed successfully\"\n",
    "            \n",
    "        res = self._tool(task=task, context=self.tool_descriptions)\n",
    "        t = res.tool_name\n",
    "        arg = res.tool_argument\n",
    "        if t in self.tools:\n",
    "            complete = self.tools[t].func(arg)\n",
    "            return complete\n",
    "        return \"Not done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.utils import flatten, deduplicate\n",
    "\n",
    "AGENTS = [x[-1] for x in optimized_react.candidate_programs[:5]]\n",
    "\n",
    "class Aggregator(dspy.Module):\n",
    "\tdef __init__(self, temperature=0.0):\n",
    "\t\tself.aggregate = dspy.ChainOfThought('context, question -> answer')\n",
    "\t\tself.temperature = temperature\n",
    "\n",
    "\tdef forward(self, question):\n",
    "\t\t# Run all five agents with high temperature, then extract and deduplicate their observed contexts\n",
    "\t\twith dspy.context(lm=gpt3.copy(temperature=self.temperature)):\n",
    "\t\t\tpreds = [agent(question=question) for agent in AGENTS]\n",
    "\t\t\tcontext = deduplicate(flatten([flatten(p.observations) for p in preds]))\n",
    "\n",
    "\t\t# Run the aggregation step to produce a final answer\n",
    "\t\treturn self.aggregate(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from typing import List, Literal\n",
    "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.base.llms.types import (\n",
    "    ChatMessage,\n",
    "    MessageRole,\n",
    ")\n",
    "\n",
    "\n",
    "query_engine_tools = QueryEngineTool(\n",
    "    query_engine=query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"spreadsheet_value_retriever\",\n",
    "        description=\"contains the information of a spreadsheet, and is useful for retrieving specific values from a spreadsheet\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "def adding_values(values: List[float]):\n",
    "    return sum(values)\n",
    "\n",
    "\n",
    "class AddingArgs(BaseModel):\n",
    "    values: List = Field(\n",
    "        description=\"A list of values to add together.\"\n",
    "    )\n",
    "\n",
    "adding_tool = FunctionTool.from_defaults(\n",
    "    fn=adding_values,\n",
    "    name=\"sum_values\",\n",
    "    description=\"Add a list of values together\",\n",
    "    fn_schema=AddingArgs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = ['Selling Costs',\n",
    "  'Disposition Fee',\n",
    "  'Net Operating Income',\n",
    "  'Loan Assumption/Payoff',\n",
    "  'Return of Forecasted Reserves',\n",
    "  'CF Y 11',\n",
    "  'Return of Maximum Offering Amount',\n",
    "  'Projected Terminal Cap Rate',\n",
    "  'Cash Flows']\n",
    "content='Retrieve the following values from the spreadsheet: Selling Costs, Disposition Fee, Net Operating Income, Loan Assumption/Payoff, Return of Forecasted Reserves, CF Y 11, Return of Maximum Offering Amount, Projected Terminal Cap Rate, Cash Flows (categories 1 through 9)\\nThen add Disposition Fee and Selling Cost together.'\n",
    "\n",
    "usr_msg = ChatMessage(\n",
    "    role=MessageRole.ASSISTANT,\n",
    "    content=content\n",
    ")\n",
    "response = agent1.chat(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content='Retrieve the following values from the spreadsheet: Selling Costs, Disposition Fee, Net Operating Income, Loan Assumption/Payoff, Return of Forecasted Reserves, CF Y 11, Return of Maximum Offering Amount, Projected Terminal Cap Rate, Cash Flows (categories 1 through 9)\\nThen add Disposition Fee and Selling Cost together.'\n",
    "\n",
    "messages = [\n",
    "        {\"role\": \"user\", \"content\": content},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
