{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 install llama-index llama-parse llama-index-embeddings-huggingface accelerate dspy-ai openpyxl langchain chromadb\n",
    "!pip3 install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 install sentencepiece protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.datasets.hotpotqa import HotPotQA\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "# from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "# from llama_index.readers.file import PandasExcelReader\n",
    "# from llama_index.core.embeddings import resolve_embed_model\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "from typing import List, Any, Callable, Optional\n",
    "from pydantic import BaseModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(BaseModel):\n",
    "    name: str\n",
    "    desc: str\n",
    "    input_variable: str\n",
    "    func: Callable\n",
    "    \n",
    "# class GiveTime:\n",
    "#     name = \"GiveTime\"\n",
    "#     input_variable = \"empty\"\n",
    "#     desc = \"takes an empty string and returns the current local time\"\n",
    "\n",
    "#     def __init__(self, k=3):\n",
    "#         pass\n",
    "   \n",
    "#     def __call__(self, *args, **kwargs):\n",
    "#         return datetime.datetime.now().strftime(\"%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_values(input_variable: List[float])->float:\n",
    "    return sum(input_variable)\n",
    "\n",
    "adding_tool = Tool(name=\"addition\", desc=\"add a list of floats together\", input_variable=\"input_variable\", func=add_values)\n",
    "\n",
    "# test_tools = [\n",
    "    # Tool(name=\"addition\", description=\"add a list of floats together\", requires=\"values\", func=add_values)\n",
    "    # Tool(name=\"local business lookup\", description=\"Look up businesses by category\", requires=\"business category\", func=lambda x: \"Bills landscaping: 415-555-5555\")\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
    "from llama_index.readers.file import PandasExcelReader\n",
    "CHROMA_COLLECTION_NAME = \"blockchain_and_ai\"\n",
    "CHROMADB_DIR = \"/workspace/data/db/\"\n",
    "\n",
    "# model_name = \"EleutherAI/gpt-neo-125m\"\n",
    "# model_name = \"clibrain/mamba-2.8b-instruct-openhermes\"\n",
    "# model_name = \"microsoft/Phi-3-mini-128k-instruct\" # 128K context window\n",
    "# model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\" # 8K context window\n",
    "# model_name = \"clibrain/mamba-2.8b-instruct-openhermes\" # 8K context window\n",
    "# embed_model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "print('first model load...')\n",
    "# model_name = \"Qwen/Qwen2-1.5B-Instruct\"\n",
    "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\" # 32K context window\n",
    "llm = dspy.HFModel(model=model_name, hf_device_map='auto', token=access_token)\n",
    "llm.kwargs['max_new_tokens']=100\n",
    "# llm.kwargs['repetition_penalty']=1.5\n",
    "# llm.kwargs['do_sample']=True\n",
    "# llm.kwargs['typical_p']=0.9\n",
    "# llm.kwargs['temperature']=0.2\n",
    "\n",
    "\n",
    "print('deleting model...')\n",
    "llm.model=None\n",
    "gc.collect\n",
    "print('reloading model...')\n",
    "llm.model=AutoModelForCausalLM.from_pretrained(model_name, quantization_config=None, \n",
    "                                               trust_remote_code=True, device_map=\"auto\", \n",
    "                                               attn_implementation=\"flash_attention_2\",  \n",
    "                                               torch_dtype=torch.float16)\n",
    "\n",
    "# llm.model.generation_config.pad_token_id = llm.tokenizer.eos_token_id\n",
    "# llm.tokenizer.pad_token_id = llm.tokenizer.eos_token_id\n",
    "\n",
    "# retriever = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
    "filepath = \"/workspace/data/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx\"\n",
    "docs = PandasExcelReader(sheet_name=\"5 - Disposition Analysis\").load_data(filepath)\n",
    "# # embed_model = HuggingFaceEmbedding(model_name=embed_model_name)\n",
    "# # vector_index = VectorStoreIndex.from_documents(documents, embed_model=embed_model)\n",
    "# # vector_index.storage_context.persist(persist_dir=\"/workspace/data/storage/alpha\")\n",
    "# # retriever = vector_index.as_retriever(top_k=2)\n",
    "\n",
    "# chroma_client = chromadb.PersistentClient(path=CHROMADB_DIR)\n",
    "# collection = chroma_client.get_or_create_collection(name=CHROMA_COLLECTION_NAME)\n",
    "# text_splitter = SentenceTransformersTokenTextSplitter()\n",
    "\n",
    "# ids = []\n",
    "# documents = []\n",
    "# metadatas = []\n",
    "# chunks = text_splitter.create_documents([docs[0].text], )\n",
    "# for chunk_no, chunk in enumerate(chunks):\n",
    "#     ids.append(f\"{chunk_no}\")\n",
    "#     documents.append(chunk.page_content)\n",
    "#     # metadatas.append({\"title\":})\n",
    "# if ids:\n",
    "#     collection.upsert(ids=ids, documents=documents)#, metadatas=metadatas)\n",
    "\n",
    "# collection.upsert(documents=[docs[0].text])\n",
    "\n",
    "\n",
    "# default_ef = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\n",
    "# default_ef = embedding_functions.DefaultEmbeddingFunction()\n",
    "# retriever = ChromadbRM(CHROMA_COLLECTION_NAME, CHROMADB_DIR, default_ef, k=3)\n",
    "\n",
    "# dspy.settings.configure(lm=llm, rm=retriever)\n",
    "dspy.settings.configure(lm=llm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uncompiled_rag = RAG()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question='Retrieve the following values from the spreadsheet: Selling Costs, Disposition Fee, Net Operating Income, Loan Assumption/Payoff, Return of Forecasted Reserves, CF Y 11, Return of Maximum Offering Amount, Projected Terminal Cap Rate.\\nThen add Disposition Fee and Selling Cost together.'\n",
    "answer = uncompiled_rag(question).answer\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fine tune spreadsheet model\n",
    "# dspy module class for multiagent stuff with tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!cp /workspace/repos/agentic-ai/MASTER\\ -\\ PYTHON\\ -\\ SCORING\\ MODEL\\ -\\ MCG\\ MADISON\\ RIDGE\\ DST\\ -\\ v2.0.xlsx /workspace/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/workspace/data/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx\"\n",
    "docs = PandasExcelReader(sheet_name=\"5 - Disposition Analysis\", pandas_config={'keep_default_na':False}).load_data(filepath)\n",
    "# docs2 = PandasExcelReader(sheet_name=\"5 - Disposition Analysis\").load_data(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.functional import TypedPredictor\n",
    "import pydantic\n",
    "\n",
    "\n",
    "\n",
    "# class SpreadsheetValueExtractor(dspy.Signature):\n",
    "#     \"\"\"For each of the keys in the question extract its value from the data. The data is a spreadsheet that has been formatted as a string.\"\"\"\n",
    "\n",
    "#     question = dspy.InputField()\n",
    "#     data = dspy.InputField()\n",
    "#     answer = dspy.OutputField(desc=\"output the key (string) and value (float) in this format: key:value \\n.\")\n",
    "\n",
    "class ExtractionCleanup(dspy.Signature):\n",
    "    \"\"\"Please clean up the extracted values. \n",
    "    Extract only the variables and values that are contained in the keys in the format_json.\"\"\"\n",
    "    format_json = dspy.InputField()\n",
    "    extracted_values = dspy.InputField(desc=\"Contains too much information.\")\n",
    "    clean_list_of_variables_and_values = dspy.OutputField(desc=\"Only return the variables and values that are contained in the keys in the format_json.\")\n",
    "\n",
    "\n",
    "class OutputFormatVerification(dspy.Signature):\n",
    "    # \"\"\"For each variable name in the extracted values string, compare its format to the format_json and return the variable name and value if the format matches.\"\"\"\n",
    "    \"\"\"Please assess the format of the variable names and values in the extracted values string. \n",
    "    If the format matches the variable description in format_json, return True and the variable names and values that match the format. \n",
    "    If the format does not match, return False and an empty string.\"\"\"\n",
    "    format_json = dspy.InputField(desc=\"The format of the variable names and values.\")\n",
    "    extracted_values = dspy.InputField(desc=\"The string of variable names and values extracted from the spreadsheet separated by a comma.\")\n",
    "    verification = dspy.OutputField(desc=\"Only return True or False.\")\n",
    "    verified_values = dspy.OutputField(desc=\"Output a string of variable names and values.\")\n",
    "\n",
    "# class VariableNameAndValue(pydantic.BaseModel):\n",
    "#     variable_names: str\n",
    "#     variable_names_description: str\n",
    "\n",
    "# class VariableNameAndValues(pydantic.BaseModel):\n",
    "#     topics: List[VariableNameAndValue]\n",
    "\n",
    "# class FormatOutput(dspy.Signature):\n",
    "#     \"\"\"For each variable name in the extracted values list, compare its format to the format_json and return the variable name and value if the format matches.\"\"\"\n",
    "#     format_json: str = dspy.InputField(desc=\"The format of the variable names and values.\")\n",
    "#     extracted_values: VariableNameAndValues = dspy.InputField(desc=\"The list of variable names and values extracted from the spreadsheet.\")\n",
    "#     verified_values: str = dspy.OutputField(desc=\"The list of variable names and values that match the format_json.\")\n",
    "    \n",
    "\n",
    "class SpreadsheetValueExtractor(dspy.Signature):\n",
    "    \"\"\"For each of the variable name in the question extract a single value from the data. Exact variable name matches only.\"\"\"\n",
    "    # \"\"\"Extract the value for a variable names contained in the json string from the data.\"\"\"\n",
    "\n",
    "    question = dspy.InputField(desc=\"the question from the user will specify multiple variable names.\")\n",
    "    data = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"only return the variable name and its value in this format: variable_name: value.\")\n",
    "\n",
    "\n",
    "# class KeyValidationAgent(dspy.Signature):\n",
    "#     \"\"\"Remove any keys from the question that are not found in the JSON string.\"\"\"\n",
    "    \n",
    "#     orignial_question = dspy.InputField(desc=\"the original question from the user.\")\n",
    "#     format_json = dspy.InputField(desc=\"User supplied JSON string with key value formats.\")\n",
    "#     verified_question = dspy.OutputField(desc=\"only return the orignial question with keys that are found in the format_json. Leave out the intermediary steps.\")\n",
    "\n",
    "# class ValueFormatValidationAgent(dspy.Signature):\n",
    "#     \"\"\"Given the original context and the key and value format descriptions as specified in format_json make sure the retrieved values for the specified keys are in the correct format.\n",
    "#     Collect any keys in the wrong format and return them as a string.\n",
    "#     \"\"\"\n",
    "#     format_json = dspy.InputField(desc=\"User supplied JSON string with key value formats.\")\n",
    "#     original_context = dspy.InputField(desc=\"the context from the retriever.\")\n",
    "#     reasons_for_format_failure = dspy.OutputField()\n",
    "\n",
    "# class ValueFormatValidationAgent(dspy.Signature):\n",
    "#     \"\"\"Given the key and string value format descriptions in format_json make sure the retrieved string values align with the value format description.\"\"\"\n",
    "\n",
    "#     format_json = dspy.InputField(desc=\"Key and the description of the value format.\")\n",
    "#     extracted_values = dspy.InputField(desc=\"The values extracted from the spreadsheet.\")\n",
    "#     reason_for_format_failure = dspy.OutputField(desc=\"Concise return the keys and values that do not fit the format.\")\n",
    "\n",
    "\n",
    "# class RephraseQuestionForRetrieve(dspy.Signature):\n",
    "#     \"\"\"Given the orignal context and the reason for failure, please rephrase the question to retrieve the correct answer.\"\"\"\n",
    "#     original_context = dspy.InputField(desc=\"the context from the retriever\")\n",
    "#     reasons_for_format_failure = dspy.InputField()\n",
    "#     rephrased_question = dspy.OutputField()\n",
    "\n",
    "\n",
    "class SpreadSheetAnalyzer(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.num_passages = num_passages\n",
    "        # self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        # self.key_validation_agent = dspy.Predict(KeyValidationAgent)\n",
    "        # self.value_format_validation_agent = dspy.Predict(ValueFormatValidationAgent)\n",
    "        self.format_validation = dspy.Predict(OutputFormatVerification)\n",
    "        self.extraction_cleanup = dspy.Predict(ExtractionCleanup)\n",
    "        # self.question_rephrase_agent = dspy.Predict(RephraseQuestionForRetrieve)\n",
    "        self.generate_answer = dspy.Predict(SpreadsheetValueExtractor)\n",
    "    \n",
    "    # def forward(self, data, format_json):\n",
    "    def forward(self, data, question, format_json):\n",
    "        # valid_context = False\n",
    "        # First check - validate context has all the keys\n",
    "\n",
    "        # key_validated_question = self.key_validation_agent(orignial_question=question, format_json=format_json).verified_question\n",
    "        # print(\"KEY VALIDATION\")\n",
    "        # print('---------------------------------')\n",
    "        # print(key_validated_question, len(key_validated_question), type(key_validated_question))\n",
    "        # print('---------------------------------')\n",
    "        \n",
    "        # context = str(self.retrieve(query_or_queries=question).passages)\n",
    "        # out_collect = []\n",
    "        # for key, value in format_json.items():\n",
    "        # format_counter = 0\n",
    "        # self.retrieve.k = self.num_passages\n",
    "        # while not valid_context:\n",
    "        # print('---------------------------------')\n",
    "        # print(\"Counter: \", format_counter)\n",
    "        # print(\"Key: \", key)\n",
    "        # print(\"Value: \", value)\n",
    "        # print('---------------------------------')\n",
    "        # print()\n",
    "        # key_question = f\"what is the value for {key} in the spreadsheet?\"\n",
    "        # if format_counter==0: extract_question = key_question\n",
    "        # context = str(self.retrieve(query_or_queries=key_question).passages)\n",
    "        predicted_value = self.generate_answer(data=data, question=question).answer\n",
    "        list_of_predicted_values = self.extraction_cleanup(format_json=format_json, extracted_values=predicted_value).clean_list_of_variables_and_values\n",
    "        print('---------------------------------')\n",
    "        print(dspy.Prediction(list_of_predicted_values))\n",
    "        aasdfasdfasdfasdf\n",
    "        # list_of_predicted_values = str(predicted_value.split('Answer: ')[-1].split(',')[:len(question.split(','))])[1:-1]\n",
    "        value_verification_output = self.format_validation(format_json=format_json, extracted_values=list_of_predicted_values)\n",
    "        # reason_for_format_failure = self.value_format_validation_agent(format_json=format_json, extracted_values=predicted_value).reason_for_format_failure\n",
    "        print('---------------------------------')\n",
    "        print('$$$$$$ predicted value:\\n', predicted_value)\n",
    "        print('$$$$$$ verification:\\n', value_verification_output.verification)\n",
    "        print('$$$$$$ validated values:\\n', value_verification_output.verified_values)\n",
    "        # out_collect.append(predicted_value)\n",
    "            # print()\n",
    "            # print('$$$$$$ reason_for_format_failure:\\n', reason_for_format_failure)\n",
    "            # dspy.Suggest(\n",
    "            #     len(reason_for_format_failure) <= 1000,\n",
    "            #     \"The reason for format failure should be short and less than 1000 characters\",\n",
    "            # )\n",
    "            # print(\"Predicted Value: \", predicted_value)\n",
    "            # value_format_validation = self.value_format_validation_agent(key=key, value_format_description=value, extracted_content=str(predicted_value)).reason_for_format_failure\n",
    "            # out_collect.append(predicted_value)\n",
    "            # valid_context=True\n",
    "                # if value_format_validation != 'True':\n",
    "                #     key_question = self.question_rephrase_agent(original_context=context, reasons_for_format_failure=value_format_validation).rephrased_question \n",
    "                #     print('---------------------------------')\n",
    "                #     print('$$$$$$ Context:\\n', context)\n",
    "                #     print('$$$$$$ Predicted Value:\\n', predicted_value)\n",
    "                #     print(\"$$$$$$ Value Format Validation:\\n\", value_format_validation)\n",
    "                #     print(\"$$$$$$ Rephrased Question:\\n\", key_question)\n",
    "                #     print('---------------------------------')\n",
    "                #     # context = str(self.retrieve(query_or_queries=str(rephrased_question)).passages)\n",
    "                #     # self.retrieve.k+=1\n",
    "                #     valid_context=False\n",
    "                # else:\n",
    "                #     # prediction = self.generate_answer(context=context, question=key_question)\n",
    "                #     print('---------------------------------')\n",
    "                #     print(\"Retrieved Value: \", predicted_value)\n",
    "                #     print('---------------------------------')\n",
    "                #     valid_context=True\n",
    "                \n",
    "                # format_counter+=1\n",
    "\n",
    "                # if format_counter>2:\n",
    "                #     break\n",
    "        \n",
    "        # Actually retrieve values\n",
    "        # prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=data, answer=predicted_value.answer)\n",
    "        # return predicted_value, value_verification_output.verified_values, value_verification_output.verification\n",
    "        # return value_verification_output\n",
    "                               \n",
    "\n",
    "# class GoogleSearch(dspy.Signature):\n",
    "#     \"\"\"Searches Google for a query and returns the top results.\"\"\"\n",
    "\n",
    "#     query = dspy.InputField()\n",
    "#     results = dspy.OutputField(desc=\"the top search results from Google.\")\n",
    "\n",
    "# class RAG(dspy.Module):\n",
    "#     def __init__(self, num_passages=3):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "#         self.generate_answer = dspy.ChainOfThought(SpreadsheetValues)\n",
    "    \n",
    "#     def forward(self, question):\n",
    "#         context = self.retrieve(question).passages\n",
    "#         prediction = self.generate_answer(context=context, question=question)\n",
    "#         return dspy.Prediction(context=context, answer=prediction.answer)\n",
    "\n",
    "\n",
    "# agent = dspy.ReAct(RAG, tools = [adding_tool] )\n",
    "# classify = dspy.Predict(SpreadsheetValues)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpreadsheetValueExtractor(dspy.Signature):\n",
    "    # \"\"\"Extract the value for a variable names contained in the question from the context.\"\"\"\n",
    "    \"\"\"Extract the value for a variable names contained in the context.\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    context = dspy.InputField(desc=\"json string representation of a spreadsheet.\")\n",
    "    answer = dspy.OutputField(desc=\"only return the variable name and its value in this format: variable_name: value.\")\n",
    "\n",
    "class CheckValueFormat(dspy.Signature):\n",
    "    \"\"\"Check the format of the extracted values against its format description.\"\"\"\n",
    "    value = dspy.InputField(desc=\"String representation of the value.\")\n",
    "    format_description = dspy.InputField()\n",
    "    verified = dspy.OutputField(desc=\"Only return one word, True or False.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_dict = {k.split(': ')[0]:k.split(': ')[1] for k in collect}\n",
    "verify_collect=[]\n",
    "for k, v in format_json.items():\n",
    "    print(k)\n",
    "    format_description=v\n",
    "    value = collect_dict[k]\n",
    "    formatter = dspy.ChainOfThought(CheckValueFormat)\n",
    "    outtest = formatter(value=value, format_description=format_description)\n",
    "    verify_collect.append(outtest.verified.split(\"Verified: \")[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "format_json = {'Selling Costs': 'float between 0 and 1', 'Disposition Fee': 'float between 0 and 1', 'Net Operating Income': 'float >= 0', 'Loan Assumption/Payoff': 'float <= 0', 'Return of Forecasted Reserves': 'float <= 0', 'CF Y 11': 'float >= 0', 'Return of Maximum Offering Amount': 'float <= 0', 'Projected Terminal Cap Rate': 'float between 0 and 1'}\n",
    "\n",
    "collect=[]\n",
    "for key, value in format_json.items():\n",
    "    print(key)\n",
    "    question=f'Extract the value for {key}. {key} is a {value}.'\n",
    "    print(question)\n",
    "    print()\n",
    "    spreadtest = dspy.Predict(SpreadsheetValueExtractor)\n",
    "    outtest = spreadtest(context=docs[0].text, question=question)\n",
    "    collect.append(outtest.answer.split('Answer: ')[-1].strip())\n",
    "# outtest = dspy.Prediction(spreadtest(data=docs[0].text, question=question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outtest.answer.split('Answer: ')[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outtest.answer.split('Answer: ')[-1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEY VALUE FORMATS:###\n",
    "    # key: Selling Costs, format: float between 0 and 1\n",
    "    # key: Disposition Fee, format: float between 0 and 1\n",
    "    # key: Net Operating Income, format: float >= 0\n",
    "    # key: Loan Assumption/Payoff, format: float <= 0\n",
    "    # key: Return of Forecasted Reserves, format: float <= 0\n",
    "    # key: CF Y 11, format: float >= 0\n",
    "    # key: Return of Maximum Offering Amount, format: float <= 0\n",
    "    # key: Projected Terminal Cap Rate, format: float between 0 and 1\n",
    "\n",
    "format_json = {'Selling Costs': 'float between 0 and 1', 'Disposition Fee': 'float between 0 and 1', 'Net Operating Income': 'float >= 0', 'Loan Assumption/Payoff': 'float <= 0', 'Return of Forecasted Reserves': 'float <= 0', 'CF Y 11': 'float >= 0', 'Return of Maximum Offering Amount': 'float <= 0', 'Projected Terminal Cap Rate': 'float between 0 and 1'}\n",
    "# format_json = json.dumps(format_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question='Selling Costs, Disposition Fee, Net Operating Income, Loan Assumption/Payoff, Return of Forecasted Reserves, CF Y 11, Return of Maximum Offering Amount, Projected Terminal Cap Rate.'\n",
    "spreadsheet_agent = SpreadSheetAnalyzer()\n",
    "output = spreadsheet_agent(data=docs[0].text, question=question, format_json=json.dumps(format_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from llama_index.core.query_pipeline import QueryPipeline as QP, InputComponent, FnComponent\n",
    "from dspy.predict.llamaindex import DSPyComponent, LlamaIndexModule\n",
    "\n",
    "dspy_component = DSPyComponent(\n",
    "    dspy.ChainOfThought(GenerateAnswer),\n",
    "    # dspy.ReAct(\"question -> answer\", tools=[dspy.Retrieve(k=1), adding_tool] )\n",
    ")\n",
    "\n",
    "retriever_post = FnComponent(\n",
    "    lambda contexts: \"\\n\\n\".join([n.get_content() for n in contexts])\n",
    ")\n",
    "\n",
    "\n",
    "p = QP(verbose=True)\n",
    "p.add_modules(\n",
    "    {\n",
    "        \"input\": InputComponent(),\n",
    "        \"retriever\": retriever,\n",
    "        \"retriever_post\": retriever_post,\n",
    "        \"synthesizer\": dspy_component,\n",
    "    }\n",
    ")\n",
    "p.add_link(\"input\", \"retriever\")\n",
    "p.add_link(\"retriever\", \"retriever_post\")\n",
    "p.add_link(\"input\", \"synthesizer\", dest_key=\"query_str\")\n",
    "p.add_link(\"retriever_post\", \"synthesizer\", dest_key=\"context_str\")\n",
    "\n",
    "\n",
    "dspy_qp = LlamaIndexModule(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "out = dspy_qp(query_str=\"What is the Disposition Fee and Selling Cost? Add them together.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(out.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = dspy.ReAct(\"question -> answer\", tools=[dspy.Retrieve(k=1), adding_tool] )\n",
    "agent(question=\"What is the Disposition Fee and Selling Cost?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any, Callable, Optional\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plan(dspy.Signature):\n",
    "    \"\"\"Produce a step by step plan to perform the task. \n",
    "The plan needs to be in markdown format and should be broken down into big steps (with ## headings) and sub-steps beneath those.\n",
    "When thinking about your plan, be sure to think about the tools at your disposal and include them in your plan.\n",
    "    \"\"\"\n",
    "    task = dspy.InputField(prefix=\"Task\", desc=\"The task\")\n",
    "    context = dspy.InputField(format=str, desc=\"The context around the plan\")\n",
    "    proposed_plan = dspy.OutputField(desc=\"The proposed, step by step execution plan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker(dspy.Module):\n",
    "    def __init__(self, role:str, tools:List):\n",
    "        self.role = role\n",
    "        self.tools = tools\n",
    "        self.tool_descriptions = \"\\n\".join([f\"- {t.name}: {t.description}. To use this tool please provide: `{t.requires}`\" for t in tools])\n",
    "        self.plan = dspy.ChainOfThought(Plan)\n",
    "    def forward(self, task:str):\n",
    "        context = f\"{self.role}\\n{self.tool_descriptions}\"\n",
    "        input_args = dict(\n",
    "            context = context,\n",
    "            task = task\n",
    "        ) # just did args for printing for debugging\n",
    "        result = self.plan(**input_args)\n",
    "        print(result.proposed_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    requires: str\n",
    "    func: Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tools = [\n",
    "    Tool(name=\"phone\", description=\"a way of making phone calls\", requires=\"phone_number\", func=lambda x: \"they've got time\"),\n",
    "    Tool(name=\"local business lookup\", description=\"Look up businesses by category\", requires=\"business category\", func=lambda x: \"Bills landscaping: 415-555-5555\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dspy.context(lm=wrkr):\n",
    "    Worker(\"assistant\", test_tools).forward(\"get this yard cleaned up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker2(dspy.Module):\n",
    "    def __init__(self, role:str, tools:List):\n",
    "        self.role = role\n",
    "        self.tools = dict([(t.name, t) for t in tools])\n",
    "        self.tool_descriptions = \"\\n\".join([f\"- {t.name}: {t.description}. To use this tool please provide: `{t.requires}`\" for t in tools])\n",
    "        self._plan = dspy.ChainOfThought(Plan)\n",
    "        self._tool = dspy.ChainOfThought(\"task, context -> tool_name, tool_argument\")\n",
    "        \n",
    "        print(self.tool_descriptions)\n",
    "    def plan(self, task:str, feedback:Optional[str]=None):\n",
    "        context = f\"Your role:{self.role}\\n Tools at your disposal:\\n{self.tool_descriptions}\"\n",
    "        if feedback:\n",
    "            context += f\"\\nPrevious feedback on your prior plan {feedback}\"\n",
    "        input_args = dict(\n",
    "            task=task,\n",
    "            context=context\n",
    "        )    \n",
    "        result = self._plan(**input_args)\n",
    "        return result.proposed_plan\n",
    "    def execute(self, task:str, use_tool:bool):\n",
    "        print(f\"executing {task}\")\n",
    "        if not use_tool:\n",
    "            return f\"{task} completed successfully\"\n",
    "            \n",
    "        res = self._tool(task=task, context=self.tool_descriptions)\n",
    "        t = res.tool_name\n",
    "        arg = res.tool_argument\n",
    "        if t in self.tools:\n",
    "            complete = self.tools[t].func(arg)\n",
    "            return complete\n",
    "        return \"Not done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicGuardrails(dspy.Signature):\n",
    "    \"\"\"Please assess whether this generated topic list is properly formatted as a comma-separated list.\"\"\"\n",
    "    \n",
    "    topic_str = dspy.InputField()\n",
    "    properly_formatted = dspy.OutputField(desc = \"only output True or False\")\n",
    "    reason_for_properly_formatted_decision = dspy.OutputField()\n",
    "\n",
    "class RetryTopic(dspy.Signature):\n",
    "    \"\"\"Given the original output and the reason for it's failure, please correct it. \n",
    "    Please also remove any extra text before the topics begin such as something lik `A list of topics the blog will cover:`\"\"\"\n",
    "    \n",
    "    original_output = dspy.InputField()\n",
    "    reason_for_failure = dspy.InputField()\n",
    "    corrected_output = dspy.OutputField()\n",
    "\n",
    "class Blog2OutlineWithCustomGuardrails(dspy.Module):\n",
    "    def __init__(self, weaviate_rm, you_rm):\n",
    "        self.question_to_blog_outline = dspy.Predict(Question2BlogOutline)\n",
    "        self.topic_guardrails = dspy.Predict(TopicGuardrails)\n",
    "        self.retry_topic = dspy.Predict(RetryTopic)\n",
    "        self.weaviate_rm = weaviate_rm\n",
    "        self.you_rm = you_rm\n",
    "\n",
    "    def forward(self, question):\n",
    "        blog_contexts = self.weaviate_rm(question)\n",
    "        web_contexts = self.you_rm(question)\n",
    "        blog_contexts, web_contexts = format_weaviate_and_you_contexts(blog_contexts, web_contexts)\n",
    "        question_to_blog_outline_outputs = self.question_to_blog_outline(question=question, blog_context=blog_contexts, web_context=web_contexts)\n",
    "        blog_outline = question_to_blog_outline_outputs.blog_outline\n",
    "        counter = 0\n",
    "        while True:\n",
    "            with dspy.context(lm=gpt4):\n",
    "                guardrails_outputs = self.topic_guardrails(topic_str=blog_outline)\n",
    "            print(f\"\\n Guardrails Outputs {guardrails_outputs}\")\n",
    "            if guardrails_outputs.properly_formatted == 'True':\n",
    "                break\n",
    "            reason_for_failure = guardrails_outputs.reason_for_properly_formatted_decision\n",
    "            blog_outline = self.retry_topic(original_output=blog_outline, reason_for_failure=reason_for_failure).corrected_output\n",
    "            print(f\"\\n Retried Blog Outline: {blog_outline}\\n\")\n",
    "            counter += 1\n",
    "            if counter >= 3:\n",
    "                print(\"Exceeded Retry Limit, exiting.\")\n",
    "                break\n",
    "        return blog_outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Functions and subfuctions\n",
    "\n",
    "from dspy.functional import TypedPredictor\n",
    "import pydantic\n",
    "from typing import List\n",
    "\n",
    "# defining what a Topic is\n",
    "class Topic(pydantic.BaseModel):\n",
    "    topic: str\n",
    "    topic_description: str\n",
    "\n",
    "\n",
    "class Topics(pydantic.BaseModel):\n",
    "    topics: List[Topic]\n",
    "\n",
    "class TypedQuestion2BlogOutline(dspy.Signature):\n",
    "    \"\"\"Your task is to write a Weaviate blog post that will help answer the given question.\\nPlease use the contexts from a web search and published Weaviate blog posts to evaluate the structure of the blog post.\"\"\"\n",
    "    \n",
    "    question: str = dspy.InputField()\n",
    "    blog_context: str = dspy.InputField()\n",
    "    web_context: str = dspy.InputField()\n",
    "    # Notice here how the class Topics is used to specify the output type. Brilliant.\n",
    "    blog_outline: Topics = dspy.OutputField(desc=\"A list of topics the blog will cover. IMPORTANT!! This must follow a comma separated list of values!\")\n",
    "\n",
    "\n",
    "\n",
    "############ Putting it all together\n",
    "import functools\n",
    "\n",
    "class TypedBlog2Outline(dspy.Module):\n",
    "    def __init__(self, weaviate_rm, you_rm):\n",
    "        self.question_to_blog_outline = dspy.functional.TypedPredictor(TypedQuestion2BlogOutline)\n",
    "        self.weaviate_rm = weaviate_rm\n",
    "        self.you_rm = you_rm\n",
    "\n",
    "    def forward(self, question):\n",
    "        blog_contexts = self.weaviate_rm(question)\n",
    "        web_contexts = self.you_rm(question)\n",
    "        blog_contexts, web_contexts = format_weaviate_and_you_contexts(blog_contexts, web_contexts)\n",
    "        question_to_blog_outline_outputs = self.question_to_blog_outline(question=question, blog_context=blog_contexts, web_context=web_contexts)\n",
    "        return question_to_blog_outline_outputs.blog_outline\n",
    "\n",
    "                                                                         \n",
    "blog2outline = TypedBlog2Outline(weaviate_rm, you_rm)\n",
    "        \n",
    "toy_question = \"What are cross encoders?\"\n",
    "\n",
    "for lm_dict in lms:\n",
    "    lm, name = lm_dict[\"lm\"], lm_dict[\"name\"]\n",
    "    with dspy.context(lm=lm):\n",
    "        print(f\"\\033[91mResult for {name}\\n\")\n",
    "        print(f\"\\033[0m{blog2outline(question=toy_question)} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### This might be the better way to do it\n",
    "\n",
    "class TopicGuardrails(dspy.Signature):\n",
    "    \"\"\"Please assess whether this generated topic list is properly formatted as a comma-separated list.\"\"\"\n",
    "    \n",
    "    topic_str = dspy.InputField()\n",
    "    properly_formatted = dspy.OutputField(desc = \"only output True or False\")\n",
    "    reason_for_properly_formatted_decision = dspy.OutputField()\n",
    "\n",
    "class RetryTopic(dspy.Signature):\n",
    "    \"\"\"Given the original output and the reason for it's failure, please correct it. \n",
    "    Please also remove any extra text before the topics begin such as something lik `A list of topics the blog will cover:`\"\"\"\n",
    "    \n",
    "    original_output = dspy.InputField()\n",
    "    reason_for_failure = dspy.InputField()\n",
    "    corrected_output = dspy.OutputField()\n",
    "\n",
    "class Blog2OutlineWithCustomGuardrails(dspy.Module):\n",
    "    def __init__(self, weaviate_rm, you_rm):\n",
    "        self.question_to_blog_outline = dspy.Predict(Question2BlogOutline)\n",
    "        self.topic_guardrails = dspy.Predict(TopicGuardrails)\n",
    "        self.retry_topic = dspy.Predict(RetryTopic)\n",
    "        self.weaviate_rm = weaviate_rm\n",
    "        self.you_rm = you_rm\n",
    "\n",
    "    def forward(self, question):\n",
    "        blog_contexts = self.weaviate_rm(question)\n",
    "        web_contexts = self.you_rm(question)\n",
    "        blog_contexts, web_contexts = format_weaviate_and_you_contexts(blog_contexts, web_contexts)\n",
    "        question_to_blog_outline_outputs = self.question_to_blog_outline(question=question, blog_context=blog_contexts, web_context=web_contexts)\n",
    "        blog_outline = question_to_blog_outline_outputs.blog_outline\n",
    "        counter = 0\n",
    "        while True:\n",
    "            with dspy.context(lm=gpt4):\n",
    "                guardrails_outputs = self.topic_guardrails(topic_str=blog_outline)\n",
    "            print(f\"\\n Guardrails Outputs {guardrails_outputs}\")\n",
    "            if guardrails_outputs.properly_formatted == 'True':\n",
    "                break\n",
    "            reason_for_failure = guardrails_outputs.reason_for_properly_formatted_decision\n",
    "            blog_outline = self.retry_topic(original_output=blog_outline, reason_for_failure=reason_for_failure).corrected_output\n",
    "            print(f\"\\n Retried Blog Outline: {blog_outline}\\n\")\n",
    "            counter += 1\n",
    "            if counter >= 3:\n",
    "                print(\"Exceeded Retry Limit, exiting.\")\n",
    "                break\n",
    "        return blog_outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsp.utils import flatten, deduplicate\n",
    "\n",
    "AGENTS = [x[-1] for x in optimized_react.candidate_programs[:5]]\n",
    "\n",
    "class Aggregator(dspy.Module):\n",
    "\tdef __init__(self, temperature=0.0):\n",
    "\t\tself.aggregate = dspy.ChainOfThought('context, question -> answer')\n",
    "\t\tself.temperature = temperature\n",
    "\n",
    "\tdef forward(self, question):\n",
    "\t\t# Run all five agents with high temperature, then extract and deduplicate their observed contexts\n",
    "\t\twith dspy.context(lm=gpt3.copy(temperature=self.temperature)):\n",
    "\t\t\tpreds = [agent(question=question) for agent in AGENTS]\n",
    "\t\t\tcontext = deduplicate(flatten([flatten(p.observations) for p in preds]))\n",
    "\n",
    "\t\t# Run the aggregation step to produce a final answer\n",
    "\t\treturn self.aggregate(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from typing import List, Literal\n",
    "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.base.llms.types import (\n",
    "    ChatMessage,\n",
    "    MessageRole,\n",
    ")\n",
    "\n",
    "\n",
    "query_engine_tools = QueryEngineTool(\n",
    "    query_engine=query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"spreadsheet_value_retriever\",\n",
    "        description=\"contains the information of a spreadsheet, and is useful for retrieving specific values from a spreadsheet\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "def adding_values(values: List[float]):\n",
    "    return sum(values)\n",
    "\n",
    "\n",
    "class AddingArgs(BaseModel):\n",
    "    values: List = Field(\n",
    "        description=\"A list of values to add together.\"\n",
    "    )\n",
    "\n",
    "adding_tool = FunctionTool.from_defaults(\n",
    "    fn=adding_values,\n",
    "    name=\"sum_values\",\n",
    "    description=\"Add a list of values together\",\n",
    "    fn_schema=AddingArgs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = ['Selling Costs',\n",
    "  'Disposition Fee',\n",
    "  'Net Operating Income',\n",
    "  'Loan Assumption/Payoff',\n",
    "  'Return of Forecasted Reserves',\n",
    "  'CF Y 11',\n",
    "  'Return of Maximum Offering Amount',\n",
    "  'Projected Terminal Cap Rate',\n",
    "  'Cash Flows']\n",
    "content='Retrieve the following values from the spreadsheet: Selling Costs, Disposition Fee, Net Operating Income, Loan Assumption/Payoff, Return of Forecasted Reserves, CF Y 11, Return of Maximum Offering Amount, Projected Terminal Cap Rate, Cash Flows (categories 1 through 9)\\nThen add Disposition Fee and Selling Cost together.'\n",
    "\n",
    "usr_msg = ChatMessage(\n",
    "    role=MessageRole.ASSISTANT,\n",
    "    content=content\n",
    ")\n",
    "response = agent1.chat(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content='Retrieve the following values from the spreadsheet: Selling Costs, Disposition Fee, Net Operating Income, Loan Assumption/Payoff, Return of Forecasted Reserves, CF Y 11, Return of Maximum Offering Amount, Projected Terminal Cap Rate, Cash Flows (categories 1 through 9)\\nThen add Disposition Fee and Selling Cost together.'\n",
    "\n",
    "messages = [\n",
    "        {\"role\": \"user\", \"content\": content},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/workspace/data/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx\"\n",
    "data = pd.read_excel(filepath, sheet_name=\"5 - Disposition Analysis\", header=None)\n",
    "data.shape\n",
    "data.dropna(axis=1, how='all', inplace=True)\n",
    "data.shape\n",
    "\n",
    "data.dropna(axis=0, how='all', inplace=True)\n",
    "data.shape\n",
    "\n",
    "text_representation = \"Spreadsheet Data:\\n\\n\"\n",
    "for index, row in data.iterrows():\n",
    "    row_text = ''#f\"Record {index + 1}: \"\n",
    "    row_items = []\n",
    "    for col_name, value in row.items():\n",
    "        # Handle NaN values explicitly if needed\n",
    "        value_text = 'None' if pd.isna(value) else str(value)\n",
    "        row_items.append(f\"{col_name}: {value_text}\")\n",
    "    row_text += \", \".join(row_items)\n",
    "    text_representation += row_text + \"\\n\"\n",
    "\n",
    "# print(text_representation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
