{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install llama-index llama-parse llama-index-embeddings-huggingface accelerate dspy-ai openpyxl langchain chromadb\n",
    "!pip3 install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 install sentencepiece protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.datasets.hotpotqa import HotPotQA\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "# from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "# from llama_index.core.embeddings import resolve_embed_model\n",
    "\n",
    "from typing import List, Any, Callable, Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "import gc\n",
    "import load_env\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
    "from llama_index.readers.file import PandasExcelReader\n",
    "# CHROMA_COLLECTION_NAME = \"blockchain_and_ai\"\n",
    "# CHROMADB_DIR = \"/workspace/data/db/\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv('/workspace/repos/agentic-ai/.env')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/workspace/data/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx\"\n",
    "disposition_inputs = [\n",
    "  \"Selling Costs\",\n",
    "  \"Disposition Fee\",\n",
    "  \"Net Operating Income\",\n",
    "  \"Loan Assumption/Payoff\",\n",
    "  \"Return of Forecasted Reserves\",\n",
    "  \"CF Y 11\",\n",
    "  \"Return of Maximum Offering Amount\",\n",
    "  \"Projected Terminal Cap Rate\",\n",
    "  \"Cash Flows\"\n",
    "]\n",
    "dfs = pd.read_excel(filepath, sheet_name=\"5 - Disposition Analysis\", header=None)\n",
    "dfs.dropna(axis=0, how='all', inplace=True)\n",
    "dfs.dropna(axis=1, how='all', inplace=True)\n",
    "fee_columns = ['Disposition Fee', 'Selling Costs']\n",
    "cashflow_columns = [1,2,3,4,5,6,7,8,9]\n",
    "ground_truth = dfs[dfs[1].isin(disposition_inputs+cashflow_columns)].iloc[:, :2] # Get only the necessary columns\n",
    "ground_truth.drop(labels=[16, 17], axis=0, inplace=True) # drop the duplicate Selling and Disposition Costs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def randomize_row_values(dfs: pd.DataFrame, ground_truth: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Randomly placing values in a dataframe\n",
    "    \"\"\"\n",
    "    dfs_copy = dfs.copy()\n",
    "    n_samples = np.random.randint(1,len(ground_truth),1)[0]\n",
    "    testvalues = ground_truth.sample(n=n_samples)\n",
    "    testidx = testvalues.index\n",
    "\n",
    "    dfscolumns = dfs_copy.columns\n",
    "    for row in testvalues.loc[testidx].iterrows():\n",
    "        random_row = np.random.choice(dfs_copy.index,1)[0]\n",
    "        random_col = np.random.choice(np.arange(len(dfscolumns)-1)[2:],1)[0]\n",
    "        random_col1 = dfscolumns[random_col]\n",
    "        random_col2 = dfscolumns[random_col+1]\n",
    "        dfs_copy.loc[testidx, :2]=np.nan\n",
    "        dfs_copy.loc[random_row, [random_col1, random_col2]] = row[1].values\n",
    "    return dfs_copy, testvalues\n",
    "\n",
    "\n",
    "def get_csv_string(dfs: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Convert a DataFrame to a CSV formatted string\n",
    "    \"\"\"\n",
    "    # Create a string buffer\n",
    "    buffer = io.StringIO()\n",
    "\n",
    "    # Convert the DataFrame to CSV format and write to the buffer\n",
    "    dfs.to_csv(buffer, index=False)\n",
    "\n",
    "    # Get the CSV as a string\n",
    "    csv_string = buffer.getvalue()\n",
    "\n",
    "    return csv_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_618/693264574.py:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Net Operating Income' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  dfs_copy.loc[random_row, [random_col1, random_col2]] = row[1].values\n"
     ]
    }
   ],
   "source": [
    "out = randomize_row_values(dfs, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"EleutherAI/gpt-neo-125m\"\n",
    "# model_name = \"clibrain/mamba-2.8b-instruct-openhermes\"\n",
    "# model_name = \"microsoft/Phi-3-mini-128k-instruct\" # 128K context window\n",
    "# model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\" # 8K context window\n",
    "# model_name = \"clibrain/mamba-2.8b-instruct-openhermes\" # 8K context window\n",
    "print('first model load...')\n",
    "model_name = \"Qwen/Qwen2-1.5B-Instruct\"\n",
    "access_token = os.getenv('HF_TOKEN')\n",
    "# model_name = \"mistralai/Mistral-7B-Instruct-v0.3\" # 32K context window\n",
    "llm = dspy.HFModel(model=model_name, hf_device_map='auto', token=access_token)\n",
    "llm.kwargs['max_new_tokens']=100\n",
    "# llm.kwargs['repetition_penalty']=1.5\n",
    "# llm.kwargs['do_sample']=True\n",
    "# llm.kwargs['typical_p']=0.9\n",
    "# llm.kwargs['temperature']=0.2\n",
    "\n",
    "\n",
    "print('deleting model...')\n",
    "llm.model=None\n",
    "gc.collect\n",
    "print('reloading model...')\n",
    "llm.model=AutoModelForCausalLM.from_pretrained(model_name, quantization_config=None, \n",
    "                                               trust_remote_code=True, device_map=\"auto\", \n",
    "                                               attn_implementation=\"flash_attention_2\",  \n",
    "                                               torch_dtype=torch.float16)\n",
    "\n",
    "# llm.model.generation_config.pad_token_id = llm.tokenizer.eos_token_id\n",
    "# llm.tokenizer.pad_token_id = llm.tokenizer.eos_token_id\n",
    "\n",
    "filepath = \"/workspace/data/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx\"\n",
    "docs = PandasExcelReader(sheet_name=\"5 - Disposition Analysis\").load_data(filepath)\n",
    "\n",
    "dspy.settings.configure(lm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!cp /workspace/repos/agentic-ai/MASTER\\ -\\ PYTHON\\ -\\ SCORING\\ MODEL\\ -\\ MCG\\ MADISON\\ RIDGE\\ DST\\ -\\ v2.0.xlsx /workspace/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from llama_index.readers.file import PandasExcelReader\n",
    "filepath = \"/workspace/data/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx\"\n",
    "docs = PandasExcelReader(sheet_name=\"5 - Disposition Analysis\", pandas_config={'keep_default_na':False}).load_data(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic\n",
    "\n",
    "class SpreadsheetValueExtractor(dspy.Signature):\n",
    "    \"\"\"For each of the variable name in the question extract a single value from the data. Exact variable name matches only.\"\"\"\n",
    "\n",
    "    question = dspy.InputField(desc=\"the question from the user will specify multiple variable names.\")\n",
    "    data = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"only return the variable name and its value in this format: variable_name: value.\")\n",
    "\n",
    "class ExtractionCleanup(dspy.Signature):\n",
    "    \"\"\"Please clean up the extracted values. \n",
    "    Extract only the variables and values that are contained in the keys in the format_json.\"\"\"\n",
    "    format_json = dspy.InputField()\n",
    "    extracted_values = dspy.InputField(desc=\"Contains too much information.\")\n",
    "    clean_list_of_variables_and_values = dspy.OutputField(desc=\"Only return the variables and values that are contained in the keys in the format_json.\")\n",
    "\n",
    "\n",
    "class OutputFormatVerification(dspy.Signature):\n",
    "    # \"\"\"For each variable name in the extracted values string, compare its format to the format_json and return the variable name and value if the format matches.\"\"\"\n",
    "    \"\"\"Please assess the format of the variable names and values in the extracted values string. \n",
    "    If the format matches the variable description in format_json, return True and the variable names and values that match the format. \n",
    "    If the format does not match, return False and an empty string.\"\"\"\n",
    "    format_json = dspy.InputField(desc=\"The format of the variable names and values.\")\n",
    "    extracted_values = dspy.InputField(desc=\"The string of variable names and values extracted from the spreadsheet separated by a comma.\")\n",
    "    verification = dspy.OutputField(desc=\"Only return True or False.\")\n",
    "    verified_values = dspy.OutputField(desc=\"Output a string of variable names and values.\")\n",
    "\n",
    "# class VariableNameAndValue(pydantic.BaseModel):\n",
    "#     variable_names: str\n",
    "#     variable_names_description: str\n",
    "\n",
    "# class VariableNameAndValues(pydantic.BaseModel):\n",
    "#     topics: List[VariableNameAndValue]\n",
    "\n",
    "# class FormatOutput(dspy.Signature):\n",
    "#     \"\"\"For each variable name in the extracted values list, compare its format to the format_json and return the variable name and value if the format matches.\"\"\"\n",
    "#     format_json: str = dspy.InputField(desc=\"The format of the variable names and values.\")\n",
    "#     extracted_values: VariableNameAndValues = dspy.InputField(desc=\"The list of variable names and values extracted from the spreadsheet.\")\n",
    "#     verified_values: str = dspy.OutputField(desc=\"The list of variable names and values that match the format_json.\")\n",
    "    \n",
    "\n",
    "\n",
    "class SpreadSheetAnalyzer(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.format_validation = dspy.Predict(OutputFormatVerification)\n",
    "        self.extraction_cleanup = dspy.Predict(ExtractionCleanup)\n",
    "        self.generate_answer = dspy.Predict(SpreadsheetValueExtractor)\n",
    "    \n",
    "    def forward(self, data, question, format_json):\n",
    "        predicted_value = self.generate_answer(data=data, question=question).answer\n",
    "        list_of_predicted_values = self.extraction_cleanup(format_json=format_json, extracted_values=predicted_value).clean_list_of_variables_and_values\n",
    "        print('---------------------------------')\n",
    "        print(dspy.Prediction(list_of_predicted_values))\n",
    "        # list_of_predicted_values = str(predicted_value.split('Answer: ')[-1].split(',')[:len(question.split(','))])[1:-1]\n",
    "        value_verification_output = self.format_validation(format_json=format_json, extracted_values=list_of_predicted_values)\n",
    "        # reason_for_format_failure = self.value_format_validation_agent(format_json=format_json, extracted_values=predicted_value).reason_for_format_failure\n",
    "        print('---------------------------------')\n",
    "        print('$$$$$$ predicted value:\\n', predicted_value)\n",
    "        print('$$$$$$ verification:\\n', value_verification_output.verification)\n",
    "        print('$$$$$$ validated values:\\n', value_verification_output.verified_values)\n",
    "        return dspy.Prediction(context=data, answer=predicted_value.answer)\n",
    "        # return predicted_value, value_verification_output.verified_values, value_verification_output.verification\n",
    "        # return value_verification_output\n",
    "                               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SpreadsheetValueExtractor(dspy.Signature):\n",
    "#     \"\"\"For each of the variable name in the question extract a single value from the data. Exact variable name matches only.\"\"\"\n",
    "\n",
    "#     question = dspy.InputField(desc=\"the question from the user will specify multiple variable names.\")\n",
    "#     data = dspy.InputField()\n",
    "#     answer = dspy.OutputField(desc=\"only return the variable name and its value in this format: variable_name: value.\")\n",
    "\n",
    "# class ExtractionCleanup(dspy.Signature):\n",
    "#     \"\"\"Please clean up the extracted values. \n",
    "#     Extract only the variables and values that are contained in the keys in the format_json.\"\"\"\n",
    "#     format_json = dspy.InputField()\n",
    "#     extracted_values = dspy.InputField(desc=\"Contains too much information.\")\n",
    "#     clean_list_of_variables_and_values = dspy.OutputField(desc=\"Only return the variables and values that are contained in the keys in the format_json.\")\n",
    "\n",
    "class SpreadsheetValueExtractor(dspy.Signature):\n",
    "    \"\"\"Extract the value for a variable names contained in the context.\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    context = dspy.InputField(desc=\"json string representation of a spreadsheet.\")\n",
    "    answer = dspy.OutputField(desc=\"only return the variable name and its value in this format: variable_name: value.\")\n",
    "\n",
    "class CheckValueFormat(dspy.Signature):\n",
    "    \"\"\"Check the format of the extracted values against its format description.\"\"\"\n",
    "    value = dspy.InputField(desc=\"String representation of the value.\")\n",
    "    format_description = dspy.InputField()\n",
    "    verified = dspy.OutputField(desc=\"Only return one word, True or False.\")\n",
    "\n",
    "format_json = {'Selling Costs': 'float between 0 and 1', 'Disposition Fee': 'float between 0 and 1', 'Net Operating Income': 'float >= 0', 'Loan Assumption/Payoff': 'float <= 0', 'Return of Forecasted Reserves': 'float <= 0', 'CF Y 11': 'float >= 0', 'Return of Maximum Offering Amount': 'float <= 0', 'Projected Terminal Cap Rate': 'float between 0 and 1'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_dict = {k.split(': ')[0]:k.split(': ')[1] for k in collect}\n",
    "verify_collect=[]\n",
    "for k, v in format_json.items():\n",
    "    print(k)\n",
    "    format_description=v\n",
    "    value = collect_dict[k]\n",
    "    formatter = dspy.ChainOfThought(CheckValueFormat)\n",
    "    outtest = formatter(value=value, format_description=format_description)\n",
    "    verify_collect.append(outtest.verified.split(\"Verified: \")[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "collect=[]\n",
    "for key, value in format_json.items():\n",
    "    print(key)\n",
    "    question=f'Extract the value for {key}. {key} is a {value}.'\n",
    "    print(question)\n",
    "    print()\n",
    "    spreadtest = dspy.Predict(SpreadsheetValueExtractor)\n",
    "    outtest = spreadtest(context=docs[0].text, question=question)\n",
    "    collect.append(outtest.answer.split('Answer: ')[-1].strip())\n",
    "# outtest = dspy.Prediction(spreadtest(data=docs[0].text, question=question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "format_json = {'Selling Costs': 'float between 0 and 1', 'Disposition Fee': 'float between 0 and 1', 'Net Operating Income': 'float >= 0', 'Loan Assumption/Payoff': 'float <= 0', 'Return of Forecasted Reserves': 'float <= 0', 'CF Y 11': 'float >= 0', 'Return of Maximum Offering Amount': 'float <= 0', 'Projected Terminal Cap Rate': 'float between 0 and 1'}\n",
    "# format_json = json.dumps(format_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question='Selling Costs, Disposition Fee, Net Operating Income, Loan Assumption/Payoff, Return of Forecasted Reserves, CF Y 11, Return of Maximum Offering Amount, Projected Terminal Cap Rate.'\n",
    "spreadsheet_agent = SpreadSheetAnalyzer()\n",
    "output = spreadsheet_agent(data=docs[0].text, question=question, format_json=json.dumps(format_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
