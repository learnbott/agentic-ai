{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 install llama-index llama-parse llama-index-embeddings-huggingface accelerate dspy-ai openpyxl langchain chromadb\n",
    "!pip3 install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 install sentencepiece protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!cp /workspace/repos/agentic-ai/MASTER\\ -\\ PYTHON\\ -\\ SCORING\\ MODEL\\ -\\ MCG\\ MADISON\\ RIDGE\\ DST\\ -\\ v2.0.xlsx /workspace/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gc\n",
    "import io\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.datasets.hotpotqa import HotPotQA\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "# from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "# from llama_index.core.embeddings import resolve_embed_model\n",
    "# import chromadb\n",
    "# from chromadb.utils import embedding_functions\n",
    "# from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
    "# from llama_index.readers.file import PandasExcelReader\n",
    "# CHROMA_COLLECTION_NAME = \"blockchain_and_ai\"\n",
    "# CHROMADB_DIR = \"/workspace/data/db/\"\n",
    "\n",
    "from typing import List, Any, Callable, Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv('/workspace/repos/agentic-ai/.env')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_row_values(dfs: pd.DataFrame, ground_truth: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Randomly placing values in a dataframe\n",
    "    \"\"\"\n",
    "    dfs_copy = dfs.copy()\n",
    "    n_samples = np.random.randint(1,len(ground_truth),1)[0]\n",
    "    testvalues = ground_truth.sample(n=n_samples)\n",
    "    testidx = testvalues.index\n",
    "\n",
    "    dfscolumns = dfs_copy.columns\n",
    "    for row in testvalues.loc[testidx].iterrows():\n",
    "        random_row = np.random.choice(dfs_copy.index,1)[0]\n",
    "        random_col = np.random.choice(np.arange(len(dfscolumns)-1)[2:],1)[0]\n",
    "        random_col1 = dfscolumns[random_col]\n",
    "        random_col2 = dfscolumns[random_col+1]\n",
    "        dfs_copy.loc[testidx, :2]=np.nan\n",
    "        dfs_copy.loc[random_row, [random_col1, random_col2]] = row[1].values\n",
    "    return dfs_copy\n",
    "\n",
    "\n",
    "def get_csv_string(dfs: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Convert a DataFrame to a CSV formatted string\n",
    "    \"\"\"\n",
    "    # Create a string buffer\n",
    "    buffer = io.StringIO()\n",
    "\n",
    "    # Convert the DataFrame to CSV format and write to the buffer\n",
    "    dfs.to_csv(buffer, index=False)\n",
    "\n",
    "    # Get the CSV as a string\n",
    "    csv_string = buffer.getvalue()\n",
    "\n",
    "    return csv_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"EleutherAI/gpt-neo-125m\"\n",
    "# model_name = \"clibrain/mamba-2.8b-instruct-openhermes\"\n",
    "# model_name = \"microsoft/Phi-3-mini-128k-instruct\" # 128K context window\n",
    "# model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\" # 8K context window\n",
    "# model_name = \"clibrain/mamba-2.8b-instruct-openhermes\" # 8K context window\n",
    "print('first model load...')\n",
    "model_name = \"Qwen/Qwen2-1.5B-Instruct\"\n",
    "access_token = os.getenv('HF_TOKEN')\n",
    "# model_name = \"mistralai/Mistral-7B-Instruct-v0.3\" # 32K context window\n",
    "llm = dspy.HFModel(model=model_name, hf_device_map='auto', token=access_token)\n",
    "llm.kwargs['max_new_tokens']=100\n",
    "llm.kwargs['repetition_penalty']=1.1\n",
    "# llm.kwargs['do_sample']=True\n",
    "# llm.kwargs['typical_p']=0.9\n",
    "# llm.kwargs['temperature']=0.9\n",
    "# llm.tokenizer.return_full_text = False\n",
    "\n",
    "\n",
    "print('deleting model...')\n",
    "llm.model=None\n",
    "gc.collect()\n",
    "print('reloading model...')\n",
    "llm.model=AutoModelForCausalLM.from_pretrained(model_name, quantization_config=None, \n",
    "                                               trust_remote_code=True, device_map=\"auto\", \n",
    "                                               attn_implementation=\"flash_attention_2\",  \n",
    "                                               torch_dtype=torch.float16)\n",
    "\n",
    "# llm.model.generation_config.pad_token_id = llm.tokenizer.eos_token_id\n",
    "# llm.tokenizer.pad_token_id = llm.tokenizer.eos_token_id\n",
    "\n",
    "dspy.settings.configure(lm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/workspace/data/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx\"\n",
    "disposition_inputs = [\n",
    "  \"Selling Costs\",\n",
    "  \"Disposition Fee\",\n",
    "  \"Net Operating Income\",\n",
    "  \"Loan Assumption/Payoff\",\n",
    "  \"Return of Forecasted Reserves\",\n",
    "  \"CF Y 11\",\n",
    "  \"Return of Maximum Offering Amount\",\n",
    "  \"Projected Terminal Cap Rate\",\n",
    "  \"Cash Flows\"\n",
    "]\n",
    "dfs = pd.read_excel(filepath, sheet_name=\"5 - Disposition Analysis\", header=None)\n",
    "dfs.dropna(axis=0, how='all', inplace=True)\n",
    "dfs.dropna(axis=1, how='all', inplace=True)\n",
    "fee_columns = ['Disposition Fee', 'Selling Costs']\n",
    "cashflow_columns = [1,2,3,4,5,6,7,8,9]\n",
    "ground_truth = dfs[dfs[1].isin(disposition_inputs+cashflow_columns)].iloc[:, :2] # Get only the necessary columns\n",
    "ground_truth.drop(labels=[16, 17], axis=0, inplace=True) # drop the duplicate Selling and Disposition Costs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from llama_index.readers.file import PandasExcelReader\n",
    "filepath = \"/workspace/data/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx\"\n",
    "docs = PandasExcelReader(sheet_name=\"5 - Disposition Analysis\", pandas_config={'keep_default_na':False}).load_data(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic\n",
    "\n",
    "class SpreadsheetValueExtractor(dspy.Signature):\n",
    "    \"\"\"For each of the variable name in the question extract a single value from the data. Exact variable name matches only.\"\"\"\n",
    "\n",
    "    question = dspy.InputField(desc=\"the question from the user will specify multiple variable names.\")\n",
    "    data = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"only return the variable name and its value in this format: variable_name: value.\")\n",
    "\n",
    "class ExtractionCleanup(dspy.Signature):\n",
    "    \"\"\"Please clean up the extracted values. \n",
    "    Extract only the variables and values that are contained in the keys in the format_json.\"\"\"\n",
    "    format_json = dspy.InputField()\n",
    "    extracted_values = dspy.InputField(desc=\"Contains too much information.\")\n",
    "    clean_list_of_variables_and_values = dspy.OutputField(desc=\"Only return the variables and values that are contained in the keys in the format_json.\")\n",
    "\n",
    "\n",
    "class OutputFormatVerification(dspy.Signature):\n",
    "    # \"\"\"For each variable name in the extracted values string, compare its format to the format_json and return the variable name and value if the format matches.\"\"\"\n",
    "    \"\"\"Please assess the format of the variable names and values in the extracted values string. \n",
    "    If the format matches the variable description in format_json, return True and the variable names and values that match the format. \n",
    "    If the format does not match, return False and an empty string.\"\"\"\n",
    "    format_json = dspy.InputField(desc=\"The format of the variable names and values.\")\n",
    "    extracted_values = dspy.InputField(desc=\"The string of variable names and values extracted from the spreadsheet separated by a comma.\")\n",
    "    verification = dspy.OutputField(desc=\"Only return True or False.\")\n",
    "    verified_values = dspy.OutputField(desc=\"Output a string of variable names and values.\")\n",
    "\n",
    "# class VariableNameAndValue(pydantic.BaseModel):\n",
    "#     variable_names: str\n",
    "#     variable_names_description: str\n",
    "\n",
    "# class VariableNameAndValues(pydantic.BaseModel):\n",
    "#     topics: List[VariableNameAndValue]\n",
    "\n",
    "# class FormatOutput(dspy.Signature):\n",
    "#     \"\"\"For each variable name in the extracted values list, compare its format to the format_json and return the variable name and value if the format matches.\"\"\"\n",
    "#     format_json: str = dspy.InputField(desc=\"The format of the variable names and values.\")\n",
    "#     extracted_values: VariableNameAndValues = dspy.InputField(desc=\"The list of variable names and values extracted from the spreadsheet.\")\n",
    "#     verified_values: str = dspy.OutputField(desc=\"The list of variable names and values that match the format_json.\")\n",
    "    \n",
    "\n",
    "\n",
    "class SpreadSheetAnalyzer(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.format_validation = dspy.Predict(OutputFormatVerification)\n",
    "        self.extraction_cleanup = dspy.Predict(ExtractionCleanup)\n",
    "        self.generate_answer = dspy.Predict(SpreadsheetValueExtractor)\n",
    "    \n",
    "    def forward(self, data, question, format_json):\n",
    "        predicted_value = self.generate_answer(data=data, question=question).answer\n",
    "        list_of_predicted_values = self.extraction_cleanup(format_json=format_json, extracted_values=predicted_value).clean_list_of_variables_and_values\n",
    "        print('---------------------------------')\n",
    "        print(dspy.Prediction(list_of_predicted_values))\n",
    "        # list_of_predicted_values = str(predicted_value.split('Answer: ')[-1].split(',')[:len(question.split(','))])[1:-1]\n",
    "        value_verification_output = self.format_validation(format_json=format_json, extracted_values=list_of_predicted_values)\n",
    "        # reason_for_format_failure = self.value_format_validation_agent(format_json=format_json, extracted_values=predicted_value).reason_for_format_failure\n",
    "        print('---------------------------------')\n",
    "        print('$$$$$$ predicted value:\\n', predicted_value)\n",
    "        print('$$$$$$ verification:\\n', value_verification_output.verification)\n",
    "        print('$$$$$$ validated values:\\n', value_verification_output.verified_values)\n",
    "        return dspy.Prediction(context=data, answer=predicted_value.answer)\n",
    "        # return predicted_value, value_verification_output.verified_values, value_verification_output.verification\n",
    "        # return value_verification_output\n",
    "                               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SpreadsheetValueExtractor(dspy.Signature):\n",
    "#     \"\"\"For each of the variable name in the question extract a single value from the data. Exact variable name matches only.\"\"\"\n",
    "\n",
    "#     question = dspy.InputField(desc=\"the question from the user will specify multiple variable names.\")\n",
    "#     data = dspy.InputField()\n",
    "#     answer = dspy.OutputField(desc=\"only return the variable name and its value in this format: variable_name: value.\")\n",
    "\n",
    "# class CorrectQuestion(dspy.Signature):\n",
    "#     \"\"\"Given the original extracted value and format description, \n",
    "#     modify the original question so that the .\"\"\"\n",
    "#     question = dspy.InputField(format=str, desc=\"The original question.\")\n",
    "#     extracted_values = dspy.InputField(format=str)\n",
    "#     reason_for_failure = dspy.InputField(format=str)\n",
    "#     corrected_question = dspy.OutputField(format=str)\n",
    "\n",
    "# class ExtractionCleanup(dspy.Signature):\n",
    "#     \"\"\"Please clean up the extracted values. \n",
    "#     Extract only the variables and values that are contained in the keys in the format_json.\"\"\"\n",
    "#     format_json = dspy.InputField()\n",
    "#     extracted_values = dspy.InputField(desc=\"Contains too much information.\")\n",
    "#     clean_list_of_variables_and_values = dspy.OutputField(desc=\"Only return the variables and values that are contained in the keys in the format_json.\")\n",
    "\n",
    "# class CheckValueFormat(dspy.Signature):\n",
    "#     \"\"\"Check that the extracted float value in string format matches its format description.\"\"\"\n",
    "#     value = dspy.InputField(format=str, desc=\"String representation of a float.\")\n",
    "#     format_description = dspy.InputField(format=str, desc=\"JSON string with format descriptions of the values.\")\n",
    "#     value_fits_description = dspy.OutputField(format=str, desc=\"Only return True or False.\")\n",
    "#     reason_for_failure = dspy.OutputField(format=str)#, desc=\"Reason the value did not match the given format description.\")\n",
    "\n",
    "\n",
    "def parse_output(output: str, field: str) -> str:\n",
    "    field = field+': '\n",
    "    parsed_out = output.split(field)[-1]\n",
    "    if '---' in parsed_out:\n",
    "        return parsed_out.split('---')[0].strip()\n",
    "    else:\n",
    "        return parsed_out.split('\\n')[0].strip()\n",
    "    \n",
    "def is_in_range(value, bounds, ops=(operator.ge, operator.le)):\n",
    "    \"\"\"\n",
    "    Check if a value falls within a range based on the provided operators.\n",
    "    \n",
    "    Parameters:\n",
    "    - value: The float value to check.\n",
    "    - lower: The lower and upper bounds limit of the range.\n",
    "    - ops: A tuple of two functions from the operator module, where\n",
    "           ops[0] is used for comparing the value with the lower limit,\n",
    "           and ops[1], if upper is not None, for comparing the value with the upper limit.\n",
    "           Defaults to greater than or equal to for lower and less than or equal to for upper.\n",
    "           \n",
    "    Returns:\n",
    "    - True if the value is within the range based on the operators; False otherwise.\n",
    "    \"\"\"\n",
    "    if len(bounds)==2: lower, upper = bounds\n",
    "    else: lower, upper = bounds[0], None\n",
    "    if upper is None:\n",
    "        return ops[0](value, lower)\n",
    "    else:\n",
    "        return ops[0](value, lower) and ops[1](value, upper)\n",
    "\n",
    "\n",
    "class SpreadsheetValueExtractor(dspy.Signature):\n",
    "    # \"\"\"Extract the values for variable names contained in the context. Only return the variable name and its value in this format: variable name: value.\"\"\"\n",
    "    \"\"\"Extract the values for variable names contained in the context.\"\"\"\n",
    "\n",
    "    question = dspy.InputField(format=str)\n",
    "    context = dspy.InputField(format=str, desc=\"json string representation of a spreadsheet.\")\n",
    "    answer = dspy.OutputField(desc='variable name: extracted value.')\n",
    "    # answer = dspy.OutputField(desc=\"only return the variable name and its value in this format: variable_name: value.\")\n",
    "\n",
    "class CorrectQuestion(dspy.Signature):\n",
    "    # \"\"\"Given the original extracted value and its format description, \n",
    "    # modify the original question so that a language model will extract the correct value.\n",
    "    # Include specifics about the format of the value in the question.\"\"\"\n",
    "    \"\"\"Explain the extracted value is wrong. Rewrite question to extract the correct value using the format description.\"\"\"\n",
    "    question = dspy.InputField(format=str, desc=\"The original question.\")\n",
    "    extracted_value = dspy.InputField(format=str)\n",
    "    format_description = dspy.InputField(format=str)\n",
    "    # reason_for_failure = dspy.InputField(format=str)\n",
    "    corrected_question = dspy.OutputField(format=str)\n",
    "\n",
    "class SpreadSheetAnalyzer(dspy.Module):\n",
    "    def __init__(self, format_description_json, operators_dict):\n",
    "        super().__init__()\n",
    "        self.format_description_json = format_description_json\n",
    "        self.operators_dict = operators_dict\n",
    "        self.extraction = dspy.Predict(SpreadsheetValueExtractor)\n",
    "        self.question_rewriter = dspy.Predict(CorrectQuestion)\n",
    "\n",
    "    \n",
    "    def forward(self, data, question):\n",
    "        extracted_out = self.extraction(question=question, context=data)\n",
    "        extrated_value = parse_output(extracted_out.answer, 'Answer')\n",
    "        parsed_output = extrated_value.split(': ')\n",
    "        parsed_values = float(parsed_output[-1])\n",
    "        parsed_name = parsed_output[0]\n",
    "        valid_value = is_in_range(parsed_values, \n",
    "                                  bounds=self.operators_dict[parsed_name]['bounds'], \n",
    "                                  ops=self.operators_dict[parsed_name]['operators'])\n",
    "        while not valid_value:\n",
    "            print('Question:', question)\n",
    "            rewritten_question_out = self.question_rewriter(question=question, \n",
    "                                                            extracted_value=extrated_value, \n",
    "                                                            format_description=self.format_description_json[parsed_name])\n",
    "            extracted_out = self.extraction(question=question, context=data)\n",
    "            question = parse_output(rewritten_question_out.corrected_question, 'Corrected Question')\n",
    "            extracted_value = parse_output(extracted_out.answer, 'Answer')\n",
    "            print('Extracted values:',extracted_value)\n",
    "            parsed_output = extracted_value.split(': ')\n",
    "            parsed_values = float(parsed_output[-1])\n",
    "            parsed_name = parsed_output[0]\n",
    "            valid_value = is_in_range(parsed_values, bounds=operators_dict[parsed_name]['bounds'], ops=operators_dict[parsed_name]['operators'])\n",
    "\n",
    "        return parsed_name, parsed_values, valid_value, question\n",
    "\n",
    "operators_dict = {'Selling Costs': {'operators':(operator.ge, operator.le), 'bounds':(0,1)}, \n",
    "                  'Disposition Fee': {'operators':(operator.ge, operator.le), 'bounds':(0,1)}, \n",
    "                  'Net Operating Income': {'operators':(operator.ge,), 'bounds':(0,)}, \n",
    "                  'Loan Assumption/Payoff': {'operators':(operator.le,), 'bounds':(0,)}, \n",
    "                  'Return of Forecasted Reserves': {'operators':(operator.le,), 'bounds':(0,)}, \n",
    "                  'CF Y 11': {'operators':(operator.ge,), 'bounds':(0,)}, \n",
    "                  'Return of Maximum Offering Amount': {'operators':(operator.le,), 'bounds':(0,)}, \n",
    "                  'Projected Terminal Cap Rate': {'operators':(operator.ge, operator.le), 'bounds':(0,1)}}\n",
    "\n",
    "format_description_json = {'Selling Costs': 'float greater than 0 and less than 1', \n",
    "                           'Disposition Fee': 'float greater than 0 and less than 1', \n",
    "                           'Net Operating Income': 'float greater than 0', \n",
    "                           'Loan Assumption/Payoff': 'float less than 0', \n",
    "                           'Return of Forecasted Reserves': 'float less than 0', \n",
    "                           'CF Y 11': 'float greater than 0', \n",
    "                           'Return of Maximum Offering Amount': 'float less than 0', \n",
    "                           'Projected Terminal Cap Rate': 'float greater than 0 and less than 1'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreadsheeet_ananalyst = SpreadSheetAnalyzer(format_description_json, operators_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value_to_extract = 'Disposition Fee'\n",
    "for value_to_extract in format_description_json:\n",
    "    print('Extracting value for:', value_to_extract)\n",
    "    question = f\"Get the value for {value_to_extract}.\"\n",
    "    dfs_str = get_csv_string(dfs)\n",
    "\n",
    "    parsed_name, parsed_values, valid_value, question = spreadsheeet_ananalyst(dfs_str, question)\n",
    "    print(parsed_name, parsed_values, valid_value, question, format_description_json[value_to_extract])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with getting the correct value, then move values around in the spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction = dspy.Predict(SpreadsheetValueExtractor)\n",
    "question_rewriter = dspy.Predict(CorrectQuestion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(extrated_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extrated_value = f'{value_to_extract}: -3.025'\n",
    "parsed_output = extrated_value.split(': ')\n",
    "parsed_values = float(parsed_output[-1])\n",
    "parsed_name = parsed_output[0]\n",
    "valid_value = is_in_range(parsed_values, bounds=operators_dict[parsed_name]['bounds'], ops=operators_dict[parsed_name]['operators'])\n",
    "print(valid_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not valid_value:\n",
    "    rewritten_question_out = question_rewriter(question=question, extracted_value=extrated_value, format_description=format_description_json[parsed_name])\n",
    "    parsed_rewritten_question = parse_output(rewritten_question_out.corrected_question, 'Corrected Question')\n",
    "    print(parsed_rewritten_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
