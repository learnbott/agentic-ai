{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 install llama-index llama-parse llama-index-embeddings-huggingface accelerate dspy-ai openpyxl langchain chromadb\n",
    "!pip3 install flash-attn --no-build-isolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 install sentencepiece protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!cp /workspace/repos/agentic-ai/MASTER\\ -\\ PYTHON\\ -\\ SCORING\\ MODEL\\ -\\ MCG\\ MADISON\\ RIDGE\\ DST\\ -\\ v2.0.xlsx /workspace/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gc\n",
    "import io\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "import dspy\n",
    "from dspy.evaluate import Evaluate\n",
    "from dspy.datasets.hotpotqa import HotPotQA\n",
    "from dspy.teleprompt import BootstrapFewShotWithRandomSearch\n",
    "\n",
    "# from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "# from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "# from llama_index.core.embeddings import resolve_embed_model\n",
    "# import chromadb\n",
    "# from chromadb.utils import embedding_functions\n",
    "# from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
    "# from llama_index.readers.file import PandasExcelReader\n",
    "# CHROMA_COLLECTION_NAME = \"blockchain_and_ai\"\n",
    "# CHROMADB_DIR = \"/workspace/data/db/\"\n",
    "\n",
    "from typing import List, Any, Callable, Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('/workspace/repos/agentic-ai/.env')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize_row_values(dfs: pd.DataFrame, ground_truth: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Randomly placing values in a dataframe\n",
    "    \"\"\"\n",
    "    dfs_copy = dfs.copy()\n",
    "    n_samples = np.random.randint(1,len(ground_truth),1)[0]\n",
    "    testvalues = ground_truth.sample(n=n_samples)\n",
    "    testidx = testvalues.index\n",
    "\n",
    "    dfscolumns = dfs_copy.columns\n",
    "    for row in testvalues.loc[testidx].iterrows():\n",
    "        random_row = np.random.choice(dfs_copy.index,1)[0]\n",
    "        random_col = np.random.choice(np.arange(len(dfscolumns)-1)[2:],1)[0]\n",
    "        random_col1 = dfscolumns[random_col]\n",
    "        random_col2 = dfscolumns[random_col+1]\n",
    "        dfs_copy.loc[testidx, :2]=np.nan\n",
    "        dfs_copy.loc[random_row, [random_col1, random_col2]] = row[1].values\n",
    "    return dfs_copy\n",
    "\n",
    "\n",
    "def get_csv_string(dfs: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Convert a DataFrame to a CSV formatted string\n",
    "    \"\"\"\n",
    "    # Create a string buffer\n",
    "    buffer = io.StringIO()\n",
    "\n",
    "    # Convert the DataFrame to CSV format and write to the buffer\n",
    "    dfs.to_csv(buffer, index=False)\n",
    "\n",
    "    # Get the CSV as a string\n",
    "    csv_string = buffer.getvalue()\n",
    "\n",
    "    return csv_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"EleutherAI/gpt-neo-125m\"\n",
    "# model_name = \"clibrain/mamba-2.8b-instruct-openhermes\"\n",
    "# model_name = \"microsoft/Phi-3-mini-128k-instruct\" # 128K context window\n",
    "# model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\" # 8K context window\n",
    "# model_name = \"clibrain/mamba-2.8b-instruct-openhermes\" # 8K context window\n",
    "print('first model load...')\n",
    "model_name = \"Qwen/Qwen2-1.5B-Instruct\"\n",
    "access_token = os.getenv('HF_TOKEN')\n",
    "# model_name = \"mistralai/Mistral-7B-Instruct-v0.3\" # 32K context window\n",
    "llm = dspy.HFModel(model=model_name, hf_device_map='auto', token=access_token)\n",
    "llm.kwargs['max_new_tokens']=100\n",
    "llm.kwargs['repetition_penalty']=1.1\n",
    "llm.kwargs['do_sample']=False\n",
    "# llm.kwargs['typical_p']=0.9\n",
    "llm.kwargs['temperature']=0.9\n",
    "# llm.tokenizer.return_full_text = False\n",
    "\n",
    "\n",
    "print('deleting model...')\n",
    "llm.model=None\n",
    "gc.collect()\n",
    "print('reloading model...')\n",
    "llm.model=AutoModelForCausalLM.from_pretrained(model_name, quantization_config=None, \n",
    "                                               trust_remote_code=True, device_map=\"auto\", \n",
    "                                               attn_implementation=\"flash_attention_2\",  \n",
    "                                               torch_dtype=torch.float16)\n",
    "\n",
    "# llm.model.generation_config.pad_token_id = llm.tokenizer.eos_token_id\n",
    "# llm.tokenizer.pad_token_id = llm.tokenizer.eos_token_id\n",
    "\n",
    "dspy.settings.configure(lm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"/workspace/data/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx\"\n",
    "disposition_inputs = [\n",
    "  \"Selling Costs\",\n",
    "  \"Disposition Fee\",\n",
    "  \"Net Operating Income\",\n",
    "  \"Loan Assumption/Payoff\",\n",
    "  \"Return of Forecasted Reserves\",\n",
    "  \"CF Y 11\",\n",
    "  \"Return of Maximum Offering Amount\",\n",
    "  \"Projected Terminal Cap Rate\",\n",
    "  \"Cash Flows\"\n",
    "]\n",
    "dfs = pd.read_excel(filepath, sheet_name=\"5 - Disposition Analysis\", header=None)\n",
    "dfs.dropna(axis=0, how='all', inplace=True)\n",
    "dfs.dropna(axis=1, how='all', inplace=True)\n",
    "fee_columns = ['Disposition Fee', 'Selling Costs']\n",
    "cashflow_columns = [1,2,3,4,5,6,7,8,9]\n",
    "ground_truth = dfs[dfs[1].isin(disposition_inputs+cashflow_columns)].iloc[:, :2] # Get only the necessary columns\n",
    "ground_truth.drop(labels=[16, 17], axis=0, inplace=True) # drop the duplicate Selling and Disposition Costs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from llama_index.readers.file import PandasExcelReader\n",
    "filepath = \"/workspace/data/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx\"\n",
    "docs = PandasExcelReader(sheet_name=\"5 - Disposition Analysis\", pandas_config={'keep_default_na':False}).load_data(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(s):\n",
    "    s=s.replace('$', '')\n",
    "    s=s.replace('%', '')\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def parse_output(output: str, field: str) -> str:\n",
    "    field = field+': '\n",
    "    parsed_out = output.split(field)[-1]\n",
    "    if '---' in parsed_out:\n",
    "        return parsed_out.split('---')[0].strip()\n",
    "    else:\n",
    "        return parsed_out.split('\\n')[0].strip()\n",
    "    \n",
    "def is_in_range(value, bounds, ops=(operator.ge, operator.le)):\n",
    "    \"\"\"\n",
    "    Check if a value falls within a range based on the provided operators.\n",
    "    \n",
    "    Parameters:\n",
    "    - value: The float value to check.\n",
    "    - lower: The lower and upper bounds limit of the range.\n",
    "    - ops: A tuple of two functions from the operator module, where\n",
    "           ops[0] is used for comparing the value with the lower limit,\n",
    "           and ops[1], if upper is not None, for comparing the value with the upper limit.\n",
    "           Defaults to greater than or equal to for lower and less than or equal to for upper.\n",
    "           \n",
    "    Returns:\n",
    "    - True if the value is within the range based on the operators; False otherwise.\n",
    "    \"\"\"\n",
    "    if len(bounds)==2: lower, upper = bounds\n",
    "    else: lower, upper = bounds[0], None\n",
    "    if upper is None:\n",
    "        return ops[0](value, lower)\n",
    "    else:\n",
    "        return ops[0](value, lower) and ops[1](value, upper)\n",
    "\n",
    "class SpreadsheetValueExtractor(dspy.Signature):\n",
    "    \"\"\"Extract the values for variable names contained in the context.\"\"\"\n",
    "\n",
    "    question = dspy.InputField(format=str)\n",
    "    context = dspy.InputField(format=str, desc=\"json string representation of a spreadsheet.\")\n",
    "    answer = dspy.OutputField(desc='{variable name}: {extracted value}.')\n",
    "\n",
    "class FormatCorrectQuestion(dspy.Signature):\n",
    "    \"\"\"The extracted value for the given variable name is in the wrong format range.\n",
    "    Rephrase the question and include the format description.\"\"\"\n",
    "\n",
    "    question = dspy.InputField(format=str, desc=\"The original question.\")\n",
    "    extracted_value = dspy.InputField(format=str)\n",
    "    format_description = dspy.InputField(format=str)\n",
    "    corrected_question = dspy.OutputField(format=str)\n",
    "\n",
    "class FloatQuestionCorrector(dspy.Signature):\n",
    "    \"\"\"The extracted value for the given variable name cannot be converted to a float. \n",
    "    Rephrase the question to focus on extracting a float value for the variable name \n",
    "    given in the question.\"\"\"\n",
    "\n",
    "    question = dspy.InputField(format=str, desc=\"The original question.\")\n",
    "    extracted_value = dspy.InputField(format=str)\n",
    "    corrected_float_question = dspy.OutputField(format=str)\n",
    "\n",
    "class SpreadSheetAnalyzer(dspy.Module):\n",
    "    def __init__(self, range_description_json, operators_dict):\n",
    "        super().__init__()\n",
    "        self.range_description_json = range_description_json\n",
    "        self.operators_dict = operators_dict\n",
    "        self.extraction = dspy.Predict(SpreadsheetValueExtractor)\n",
    "        self.question_rewriter = dspy.Predict(FormatCorrectQuestion)\n",
    "        self.float_question_corrector = dspy.Predict(FloatQuestionCorrector)\n",
    "\n",
    "    def correct_float_question(self, question, extracted_value, data, max_attempts=3, verbose=False):\n",
    "        for _ in range(max_attempts):\n",
    "            if verbose: print('Float Question Failed:', question)\n",
    "            rewritten_out = self.float_question_corrector(question=question, extracted_value=extracted_value)\n",
    "            question = parse_output(rewritten_out.corrected_float_question, 'Corrected Float Question')\n",
    "            if verbose: print('Float Question Corrected:', question)\n",
    "            extracted_out = self.extraction(question=question, context=data)\n",
    "            extracted_value = parse_output(extracted_out.answer, 'Answer')\n",
    "            if is_float(extracted_value.split(': ')[-1]):\n",
    "                return extracted_value, question\n",
    "        return extracted_value, question\n",
    "\n",
    "    def correct_format_question(self, question, data, parsed_name, extracted_value, max_attempts=3, verbose=False):\n",
    "        for _ in range(max_attempts):\n",
    "            if verbose: print('Format Question Failed:', question)\n",
    "            rewritten_out = self.question_rewriter(question=question, extracted_value=extracted_value, format_description=self.range_description_json[parsed_name])\n",
    "            question = parse_output(rewritten_out.corrected_question, 'Corrected Question')\n",
    "            if verbose: print('Format Question Corrected:', question)\n",
    "            extracted_out = self.extraction(question=question, context=data)\n",
    "            extracted_value = parse_output(extracted_out.answer, 'Answer')\n",
    "            parsed_values = float(extracted_value.split(': ')[-1])\n",
    "            if is_in_range(parsed_values, bounds=self.operators_dict[parsed_name]['bounds'], ops=self.operators_dict[parsed_name]['operators']):\n",
    "                return parsed_values, question\n",
    "        return parsed_values, question\n",
    "\n",
    "    def forward(self, data, question, verbose=False):\n",
    "        extracted_out = self.extraction(question=question, context=data)\n",
    "        extracted_value = parse_output(extracted_out.answer, 'Answer')\n",
    "        parsed_output = extracted_value.split(': ')\n",
    "        parsed_values, parsed_name = parsed_output[-1], parsed_output[0]\n",
    "        if verbose: print(f'Parsed Name: {parsed_name}, Parsed Values: {parsed_values}')\n",
    "        # Safeguard - check if the extracted value can be converted to a float\n",
    "        valid_float_tf = is_float(parsed_values)\n",
    "        if not valid_float_tf:\n",
    "            extracted_value, question = self.correct_float_question(question,\n",
    "                                                                    extracted_value, \n",
    "                                                                    data,\n",
    "                                                                    verbose=verbose)\n",
    "        else:\n",
    "            parsed_values = float(parsed_values)\n",
    "\n",
    "        # Safeguard - check if the extracted value falls within the expected range\n",
    "        valid_format_tf = is_in_range(parsed_values, \n",
    "                                      bounds=self.operators_dict[parsed_name]['bounds'], \n",
    "                                      ops=self.operators_dict[parsed_name]['operators'])\n",
    "        if not valid_format_tf:\n",
    "            parsed_values, question = self.correct_format_question(question, \n",
    "                                                                   data, \n",
    "                                                                   parsed_name, \n",
    "                                                                   extracted_value,\n",
    "                                                                   verbose=verbose)\n",
    "\n",
    "        return parsed_name, parsed_values, valid_format_tf, question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators_dict = {'Selling Costs': {'operators':(operator.ge, operator.le), 'bounds':(0,1)}, \n",
    "                  'Disposition Fee': {'operators':(operator.ge, operator.le), 'bounds':(0,1)}, \n",
    "                  'Net Operating Income': {'operators':(operator.ge,), 'bounds':(0,)}, \n",
    "                  'Loan Assumption/Payoff': {'operators':(operator.le,), 'bounds':(0,)}, \n",
    "                  'Return of Forecasted Reserves': {'operators':(operator.le,), 'bounds':(0,)}, \n",
    "                  'CF Y 11': {'operators':(operator.ge,), 'bounds':(0,)}, \n",
    "                  'Return of Maximum Offering Amount': {'operators':(operator.le,), 'bounds':(0,)}, \n",
    "                  'Projected Terminal Cap Rate': {'operators':(operator.ge, operator.le), 'bounds':(0,1)},\n",
    "                  'Cash Flows 1': {'operators':(operator.ge,), 'bounds':(1,)},\n",
    "                  'Cash Flows 2': {'operators':(operator.ge,), 'bounds':(1,)},\n",
    "                  'Cash Flows 3': {'operators':(operator.ge,), 'bounds':(1,)},\n",
    "                  'Cash Flows 4': {'operators':(operator.ge,), 'bounds':(1,)},\n",
    "                  'Cash Flows 5': {'operators':(operator.ge,), 'bounds':(1,)},\n",
    "                  'Cash Flows 6': {'operators':(operator.ge,), 'bounds':(1,)},\n",
    "                  'Cash Flows 7': {'operators':(operator.ge,), 'bounds':(1,)},\n",
    "                  'Cash Flows 8': {'operators':(operator.ge,), 'bounds':(1,)},\n",
    "                  'Cash Flows 9': {'operators':(operator.ge,), 'bounds':(1,)}}\n",
    "\n",
    "\n",
    "range_description_json = {'Selling Costs': 'float greater than 0 and less than 1', \n",
    "                           'Disposition Fee': 'float greater than 0 and less than 1', \n",
    "                           'Net Operating Income': 'float greater than 0', \n",
    "                           'Loan Assumption/Payoff': 'float less than 0', \n",
    "                           'Return of Forecasted Reserves': 'float less than 0', \n",
    "                           'CF Y 11': 'float greater than 0', \n",
    "                           'Return of Maximum Offering Amount': 'float less than 0', \n",
    "                           'Projected Terminal Cap Rate': 'float greater than 0 and less than 1',\n",
    "                           'Cash Flows 1': 'float greater than 1',\n",
    "                           'Cash Flows 2': 'float greater than 1',\n",
    "                           'Cash Flows 3': 'float greater than 1',\n",
    "                           'Cash Flows 4': 'float greater than 1',\n",
    "                           'Cash Flows 5': 'float greater than 1',\n",
    "                           'Cash Flows 6': 'float greater than 1',\n",
    "                           'Cash Flows 7': 'float greater than 1',\n",
    "                           'Cash Flows 8': 'float greater than 1',\n",
    "                           'Cash Flows 9': 'float greater than 1'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spreadsheeet_ananalyst = SpreadSheetAnalyzer(range_description_json, operators_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_str = get_csv_string(dfs)\n",
    "collection = []\n",
    "for value_to_extract in range_description_json:\n",
    "    if 'Cash Flows' not in value_to_extract:\n",
    "        continue\n",
    "    # value_to_extract = 'Return of Maximum Offering Amount'\n",
    "    print('Extracting value for:', value_to_extract)\n",
    "    question = f\"Get the value for {value_to_extract}.\"\n",
    "\n",
    "    parsed_name, parsed_values, valid_value, question = spreadsheeet_ananalyst(dfs_str, question, verbose=True)\n",
    "    collection.append((parsed_name, parsed_values, valid_value, question))\n",
    "    print(range_description_json[value_to_extract])\n",
    "    print(parsed_name, parsed_values, valid_value, question)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with getting the correct value, then move values around in the spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: Get the value for Return of Maximum Offering Amount.\n",
    "# Extracted values: Return of Maximum Offering Amount: 44386706.96773932\n",
    "# Question: What is the return on maximum offering amount? Please provide a floating point number less than zero.\n",
    "# Extracted values: Return of Maximum Offering Amount: -77670566.54709445"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
