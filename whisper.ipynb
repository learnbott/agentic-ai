{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update && apt-get install -y ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pytubefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "model = whisper.load_model(\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytubefix as pt\n",
    "yt = pt.YouTube(\"https://www.youtube.com/watch?v=Z07Ewop7rQA\")\n",
    "stream = yt.streams.filter(only_audio=True)[0]\n",
    "stream.download(filename=\"aip.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = model.transcribe(\"aip.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"aip.json\", \"w\") as f:\n",
    "    json.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get update && apt-get install ffmpeg -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install moviepy openai python-dotenv pydub llama-index llama-index-llms-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /workspace/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from moviepy.editor import VideoFileClip\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"/workspace/repos/agentic-ai/.env\")\n",
    "\n",
    "def video_to_audio(video_path, output_audio_path):\n",
    "    \"\"\"\n",
    "    Convert a video to audio and save it to the output path.\n",
    "\n",
    "    Parameters:\n",
    "    video_path (str): The path to the video file.\n",
    "    output_audio_path (str): The path to save the audio to.\n",
    "\n",
    "    \"\"\"\n",
    "    clip = VideoFileClip(video_path)\n",
    "    audio = clip.audio\n",
    "    audio.write_audiofile(output_audio_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_to_audio(\"/workspace/data/video1512218125.mp4\", \"/workspace/data/video_audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def split_audio_into_chunks(file_path, output_dir, max_chunk_size_mb=24):\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_mp3(file_path)\n",
    "    \n",
    "    # Calculate the maximum duration for each chunk based on the size limit\n",
    "    max_chunk_size_bytes = max_chunk_size_mb * 1024 * 1024 * 10\n",
    "    max_chunk_duration = (max_chunk_size_bytes / len(audio.raw_data)) * len(audio)\n",
    "    \n",
    "    # Split and export the audio file into chunks\n",
    "    start_time = 0\n",
    "    chunk_index = 1\n",
    "    while start_time < len(audio):\n",
    "        print(f\"Exporting chunk {chunk_index}/{len(audio)/max_chunk_duration}\")\n",
    "        end_time = min(start_time + max_chunk_duration, len(audio))\n",
    "        chunk = audio[start_time:end_time]\n",
    "        chunk.export(f\"{output_dir}/chunk_{chunk_index}.mp3\", format=\"mp3\")\n",
    "        start_time = end_time\n",
    "        chunk_index += 1\n",
    "\n",
    "# Example usage\n",
    "split_audio_into_chunks(\"/workspace/data/video_audio.mp3\", \"/workspace/data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "transcription = []\n",
    "chunk_list = [chunk for chunk in os.listdir(\"/workspace/data\") if chunk.startswith(\"chunk\")]\n",
    "chunk_list=sorted(chunk_list)\n",
    "print(chunk_list)\n",
    "\n",
    "for chunk in chunk_list:\n",
    "      print(f\"Transcribing {chunk}...\")\n",
    "      audio_file = open(f\"/workspace/data/{chunk}\", \"rb\")\n",
    "      transcription.append(client.audio.transcriptions.create(\n",
    "          model=\"whisper-1\",\n",
    "          file=audio_file\n",
    "      ))\n",
    "# print(transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/workspace/data/transcription.pkl\", \"wb\") as f:\n",
    "    pickle.dump(transcription, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "from llama_index.core.response_synthesizers import TreeSummarize\n",
    "from llama_index.core import (\n",
    "    Settings,\n",
    ")\n",
    "\n",
    "\n",
    "with open(\"/workspace/data/transcription.pkl\", \"rb\") as f:\n",
    "    transcription = pickle.load(f)\n",
    "summarizer = TreeSummarize(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    Settings,\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI as LOpenAI\n",
    "\n",
    "llm = LOpenAI(model=\"gpt-4o\", max_tokens=4000)\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_summary = \"You are a professional executive of AlphaTrAI. Your job is to summarize this text in great detail from a video transcription. The summary will be distributed to investors and stakeholders, so give a lot of details and examples from the transcription.\"\n",
    "response = await summarizer.aget_response(prompt_summary, [doc.text for doc in transcription])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_doc = \" \".join([doc.text for doc in transcription])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_summary = f\"You are a professional executive at AlphaTrAI. Your job is to summarize the text from a video transcription. The summary will be a memo distributed to investors and stakeholders. Be sure it is factual, optimistic, and containing little information about change. The transcription is as follows:\\n\\n{full_doc}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.complete(prompt_summary, max_tokens=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp '/workspace/repos/agentic-ai/PPM - MCG MADISON RIDGE DST.pdf' /workspace/data\n",
    "# !cp '/workspace/repos/agentic-ai/MASTER - PYTHON - SCORING MODEL - MCG MADISON RIDGE DST - v2.0.xlsx' /workspace/data\n",
    "# !apt update\n",
    "# !apt install tmux vim -y\n",
    "!pip3 install llama-index llama-parse llama-index-llms-huggingface llama-index-embeddings-huggingface llama-index-llms-ollama llama-index-finetuning\n",
    "!pip3 install openpyxl sentencepiece protobuf evaluate rouge_score absl-py tensorboardX bitsandbytes peft accelerate python-dotenv graspologic\n",
    "# !pip3 install flash-attn --no-build-isolation\n",
    "# !curl -fsSL https://ollama.com/download/ollama-linux-amd64.tgz | tar zx -C /usr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!ollama pull llama3.1:latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    "    PropertyGraphIndex,\n",
    "    Settings,\n",
    "    Document\n",
    ")\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "load_dotenv('/workspace/repos/agentic-ai/.env')\n",
    "access_token = os.getenv('HF_TOKEN')\n",
    "llama_api_key = os.getenv('LLAMA_API_KEY')\n",
    "\n",
    "# model_name, num_ctx = \"mistral-nemo\", 128000\n",
    "model_name, num_ctx = \"llama3.1\", 128000\n",
    "\n",
    "addtion_kwargs = {\"max_new_tokens\": 3000}\n",
    "system_prompt = \"You are an expert in creating marketing materials for financial firms. You take corporate documents and turn them into marketing materials.\"\n",
    "# system_prompt = \"You are an expert in marketing for financial firms. You take corporate documents and turn them into marketing materials. You are working on a project for a financial firm that is looking to market their products to investors.\"\n",
    "# llm = Ollama(model=model_name, url=\"http://127.0.0.1:11434\", system_prompt=system_prompt, context_window=num_ctx, model_type=\"chat\", is_function_calling_model=False)\n",
    "llm = Ollama(model=model_name, url=\"http://127.0.0.1:11434\", context_window=num_ctx, model_type=\"chat\", is_function_calling_model=False, \n",
    "             request_timeout=1000.0, system_prompt=system_prompt, additional_kwargs=addtion_kwargs)\n",
    "            #  request_timeout=1000.0, additional_kwargs=addtion_kwargs)\n",
    "Settings.llm = llm\n",
    "llm.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Settings.chunk_size = 200\n",
    "Settings.chunk_overlap = 50\n",
    "embed_model_name = \"Alibaba-NLP/gte-Qwen2-1.5B-instruct\"\n",
    "# embed_model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "# embed_model_name = \"hkunlp/instructor-base\"\n",
    "print(\"loading embed model...\")\n",
    "embed_model = HuggingFaceEmbedding(model_name=embed_model_name, device=\"cuda\")\n",
    "\n",
    "Settings.embed_model = embed_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 install llama-parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = LlamaParse(api_key=llama_api_key, result_type=\"markdown\", split_by_page=False)\n",
    "# pdf_urls = [\"/workspace/data/AIP - Capital Raise Proposal.pdf\", \"/workspace/data/Access Pre-IPOs Presentation June 2024.pdf\"] \n",
    "pdf_urls = [\"/workspace/data/Access Pre-IPOs Presentation June 2024.pdf\"] \n",
    "documents = []\n",
    "for pdf in pdf_urls:\n",
    "    print('processing pdf:', pdf)\n",
    "    documents += parser.load_data(pdf)\n",
    "\n",
    "with open(\"aip.json\", \"r\") as f:\n",
    "    result = json.load(f)\n",
    "    documents.append(Document(text=result['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "persist_dir=\"/workspace/data/vector_index\"\n",
    "from llama_index.core import VectorStoreIndex\n",
    "vector_index = VectorStoreIndex.from_documents(documents, \n",
    "                                               llm=llm,\n",
    "                                               embed_model=embed_model, \n",
    "                                               show_progress=True)\n",
    "vector_index.storage_context.persist(persist_dir=persist_dir)\n",
    "query_engine = vector_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt = \"You have been given a documents that describe the firm's investment strategy. Highlight portions of the document that include a unique opportunity to invest in pre-IPO companies and put investors on a level playing field with VCs and big institutional investors. You need to use this information to create a marketing brochure that will attract investors to the firm's products. The brochure should be informative, engaging, and persuasive. You must disclose in fine print that there are no guarantees, and investing is risky so nothing promissory.\"\n",
    "response = query_engine.query(prompt)\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from llama_index.core import get_response_synthesizer\n",
    "from llama_index.core import DocumentSummaryIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitter = SentenceSplitter(chunk_size=4000, chunk_overlap=100)\n",
    "response_synthesizer = get_response_synthesizer(\n",
    "    response_mode=\"tree_summarize\", use_async=True\n",
    ")\n",
    "doc_summary_index = DocumentSummaryIndex.from_documents(\n",
    "    documents,\n",
    "    llm=llm,\n",
    "    # transformations=[splitter],\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "query_engine = doc_summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\", use_async=True, top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prompt = \"You are a marketing agent for financial firms. From the given context, create a marketing letter that highlights portions of the context including a unique opportunity to invest in pre-IPO companies and put investors on a level playing field with VCs and big institutional investors, qualifications of the investment team, and why they should invest now. Use exerpts from the context. At the end of the letter, you must disclose in fine print that there are no guarantees, and investing is risky.\"\n",
    "response = query_engine.query(prompt)\n",
    "print(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for node in response.source_nodes:\n",
    "    print(node.text)\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response_synthesizers import TreeSummarize\n",
    "summarizer = TreeSummarize(verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_summary = \"Use specific details from the given documents to create a professional marketing letter that highlights portions of the context including a unique opportunity to invest in pre-IPO companies and put investors on a level playing field with VCs and big institutional investors, qualifications of the investment team, and why they should invest now. Use details from the documents, but do not make up information. Be professional and persuasive. At the end of the letter, you must disclose in fine print that there are no guarantees, and investing is risky.\"\n",
    "response = await summarizer.aget_response(prompt_summary, [doc.text for doc in documents[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in response.source_nodes:\n",
    "    print(node.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
